{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating ML Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN) #INFO, WARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ray\n",
    "# from ray import air, tune\n",
    "# from ray.air import session\n",
    "# from ray.tune import CLIReporter\n",
    "# from ray.tune.schedulers import (ASHAScheduler,\n",
    "#                                  PopulationBasedTraining,\n",
    "#                                  HyperBandScheduler)\n",
    "# from ray.tune.integration.pytorch_lightning import (TuneReportCallback,\n",
    "#                                                     TuneReportCheckpointCallback)\n",
    "\n",
    "# from ray.tune.search import ConcurrencyLimiter\n",
    "# from ray.tune.search.optuna import OptunaSearch\n",
    "# from ray.air import CheckpointConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "import re\n",
    "import gc\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests as r\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import typing\n",
    "from typing import Mapping, Literal, Callable, List, ClassVar, Any, Tuple, Type\n",
    "\n",
    "from uuid import uuid4\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, DataStructs, MACCSkeys\n",
    "from datetime import date\n",
    "from scipy.sparse import csr_matrix, vstack\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "pd.set_option('display.max_columns', 1000, 'display.width', 2000, 'display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from torchvision.ops import MLP\n",
    "\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "from torch_geometric.utils.smiles import from_smiles\n",
    "\n",
    "from torchmetrics import (Accuracy,\n",
    "                          AUROC,\n",
    "                          ROC,\n",
    "                          Precision,\n",
    "                          Recall,\n",
    "                          F1Score,\n",
    "                          MeanAbsoluteError,\n",
    "                          MeanSquaredError)\n",
    "from torchmetrics.functional import (mean_absolute_error,\n",
    "                                     mean_squared_error,\n",
    "                                     mean_squared_log_error,\n",
    "                                     pearson_corrcoef,\n",
    "                                     r2_score)\n",
    "from torchmetrics.functional.classification import (binary_accuracy,\n",
    "                                                    binary_auroc,\n",
    "                                                    binary_precision,\n",
    "                                                    binary_recall,\n",
    "                                                    binary_f1_score)\n",
    "\n",
    "# Sets seeds for numpy, torch and python.random.\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "pl.seed_everything(42, workers=True)\n",
    "# torch.use_deterministic_algorithms(True) # TODO: This is a GPU-related thing.."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce logging information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "def set_global_logging_level(level=logging.ERROR, prefices=[\"\"]):\n",
    "    \"\"\"\n",
    "    Override logging levels of different modules based on their name as a prefix.\n",
    "    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n",
    "\n",
    "    Args:\n",
    "        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n",
    "        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n",
    "          Default is `[\"\"]` to match all active loggers.\n",
    "          The match is a case-sensitive `module_name.startswith(prefix)`\n",
    "    \"\"\"\n",
    "    prefix_re = re.compile(fr'^(?:{ \"|\".join(prefices) })')\n",
    "    for name in logging.root.manager.loggerDict:\n",
    "        if re.match(prefix_re, name):\n",
    "            logging.getLogger(name).setLevel(level)\n",
    "\n",
    "# Filter out annoying Pytorch Lightning printouts\n",
    "warnings.filterwarnings('ignore', '.*does not have many workers.*')\n",
    "warnings.filterwarnings('ignore', '.*Checkpoint directory.*')\n",
    "warnings.filterwarnings('ignore', '.*The number of training batches.*')\n",
    "logging.getLogger('pytorch_lightning').setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pytorch_lightning.utilities.rank_zero_warn\").setLevel(logging.ERROR)\n",
    "set_global_logging_level(logging.ERROR, ['transformers', 'nlp', 'torch', 'tensorflow', 'tensorboard', 'wandb', 'xgboost'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(), '..', 'data')\n",
    "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
    "fig_dir = os.path.join(data_dir, 'figures')\n",
    "# checkpoint_dir = os.path.join(os.getcwd(), '..', 'checkpoints')\n",
    "checkpoint_dir = os.path.join(os.getcwd(), '..', 'checkpoints')\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists(src_dir):\n",
    "    os.makedirs(src_dir)\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PROTAC-DB, used for training and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protac_db_df: 429 x 10\n"
     ]
    }
   ],
   "source": [
    "df_file = os.path.join(data_dir, 'protac', 'protac-db_cleaned.csv')\n",
    "protac_df = pd.read_csv(df_file)\n",
    "protac_db_df = pd.concat([\n",
    "    protac_df['Smiles'],\n",
    "    protac_df['Smiles_nostereo'],\n",
    "    protac_df['DC50'].astype(float),\n",
    "    protac_df['pDC50'].astype(float),\n",
    "    protac_df['Dmax'].astype(float),\n",
    "    protac_df['poi_gene_id'],\n",
    "    protac_df['poi_seq'],\n",
    "    protac_df['cell_type'],\n",
    "    protac_df['treatment_hours'],\n",
    "    protac_df['active'],\n",
    "], axis=1).reset_index(drop=True)\n",
    "# protac_db_df['e3_ligase'] = protac_df['E3ligase']\n",
    "print('protac_db_df: {:,} x {:,}'.format(*protac_db_df.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PROTAC-Pedia, used for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protac_pedia_df: 1,203 x 10\n"
     ]
    }
   ],
   "source": [
    "df_file = os.path.join(data_dir, 'protac', 'protac-pedia_cleaned.csv')\n",
    "protac_df = pd.read_csv(df_file)\n",
    "protac_pedia_df = pd.concat([\n",
    "    protac_df['DC50'].astype(float),\n",
    "    protac_df['pDC50'].astype(float),\n",
    "    protac_df['Dmax'].astype(float),\n",
    "    protac_df['poi_seq'],\n",
    "    protac_df['cell_type'],\n",
    "    protac_df['active'],\n",
    "], axis=1).reset_index(drop=True)\n",
    "protac_pedia_df['e3_ligase'] = protac_df['E3 Ligase']\n",
    "protac_pedia_df['poi_gene_id'] = 'Unknown'\n",
    "protac_pedia_df['Smiles'] = protac_df['PROTAC SMILES']\n",
    "protac_pedia_df['Smiles_nostereo'] = protac_df['PROTAC SMILES_nostereo']\n",
    "print('protac_pedia_df: {:,} x {:,}'.format(*protac_pedia_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(result_name):\n",
    "    if not os.path.exists(os.path.join(checkpoint_dir, result_name + '.pkl')):\n",
    "        print(f'WARNING: File {result_name} not found.')\n",
    "        return None\n",
    "    with open(os.path.join(checkpoint_dir, result_name + '.pkl'), 'rb') as fp:\n",
    "        return pickle.load(fp)\n",
    "\n",
    "def print_dict(title, d, filter_keys=True):\n",
    "    print(f'{title}')\n",
    "    filters = ['prediction', 'labels', 'logits', 'fpr', 'tpr', 'confusion']\n",
    "    for k, v in d.items():\n",
    "        if filter_keys:\n",
    "            if not any([f in k for f in filters]):\n",
    "                if isinstance(v, float):\n",
    "                    if v < 1e-3:\n",
    "                        print(f'\\t* {k}: {v:.1e}')\n",
    "                    else:\n",
    "                        print(f'\\t* {k}: {v:.3f}')\n",
    "                else:\n",
    "                    print(f'\\t* {k}: {v}')\n",
    "        else:\n",
    "            print(f'\\t* {k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_xgb ('predict_active_inactive', 1024, False, True):\n",
      "\t* fp_type: maccs_fp\n",
      "\t* fp_radius: 5\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: gbtree\n",
      "\t* lambda: 3.2e-07\n",
      "\t* alpha: 1.7e-08\n",
      "\t* max_depth: 15\n",
      "\t* eta: 0.034\n",
      "\t* gamma: 0.004\n",
      "\t* grow_policy: lossguide\n",
      "results_xgb ('predict_active_inactive', 1024, False, False):\n",
      "\t* fp_type: morgan_fp\n",
      "\t* fp_radius: 2\n",
      "\t* fp_max_path: 9\n",
      "\t* booster: gblinear\n",
      "\t* lambda: 0.005\n",
      "\t* alpha: 5.1e-05\n",
      "results_xgb ('predict_active_inactive', 2048, False, True):\n",
      "\t* fp_type: morgan_fp\n",
      "\t* fp_radius: 3\n",
      "\t* fp_max_path: 9\n",
      "\t* booster: dart\n",
      "\t* lambda: 8.7e-06\n",
      "\t* alpha: 6.1e-08\n",
      "\t* max_depth: 7\n",
      "\t* eta: 5.3e-04\n",
      "\t* gamma: 1.3e-07\n",
      "\t* grow_policy: depthwise\n",
      "\t* sample_type: uniform\n",
      "\t* normalize_type: forest\n",
      "\t* rate_drop: 0.053\n",
      "\t* skip_drop: 0.166\n",
      "results_xgb ('predict_active_inactive', 2048, False, False):\n",
      "\t* fp_type: morgan_fp\n",
      "\t* fp_radius: 2\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: gblinear\n",
      "\t* lambda: 1.1e-06\n",
      "\t* alpha: 2.1e-06\n",
      "results_xgb ('predict_active_inactive', 4096, False, True):\n",
      "\t* fp_type: maccs_fp\n",
      "\t* fp_radius: 10\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: dart\n",
      "\t* lambda: 0.003\n",
      "\t* alpha: 0.003\n",
      "\t* max_depth: 13\n",
      "\t* eta: 0.036\n",
      "\t* gamma: 4.6e-04\n",
      "\t* grow_policy: lossguide\n",
      "\t* sample_type: weighted\n",
      "\t* normalize_type: forest\n",
      "\t* rate_drop: 6.6e-05\n",
      "\t* skip_drop: 0.477\n",
      "results_xgb ('predict_active_inactive', 4096, False, False):\n",
      "\t* fp_type: path_fp\n",
      "\t* fp_radius: 7\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: dart\n",
      "\t* lambda: 4.4e-05\n",
      "\t* alpha: 1.2e-06\n",
      "\t* max_depth: 10\n",
      "\t* eta: 3.2e-06\n",
      "\t* gamma: 6.6e-05\n",
      "\t* grow_policy: lossguide\n",
      "\t* sample_type: uniform\n",
      "\t* normalize_type: tree\n",
      "\t* rate_drop: 9.6e-08\n",
      "\t* skip_drop: 4.0e-06\n",
      "results_fp ('predict_active_inactive', 1024, False):\n",
      "\t* radius: 2\n",
      "\t* fp_max_path: 10\n",
      "\t* num_layers: 2\n",
      "\t* smiles_enc_kwargs_layer_0_size: 608\n",
      "\t* smiles_enc_kwargs_layer_1_size: 768\n",
      "\t* smiles_enc_kwargs_fp_type: morgan_fp\n",
      "\t* smiles_enc_kwargs_dropout: 0.234\n",
      "\t* num_layers_extra: 5\n",
      "\t* model_kwargs_layer_0_size: 480\n",
      "\t* model_kwargs_layer_1_size: 928\n",
      "\t* model_kwargs_layer_2_size: 224\n",
      "\t* model_kwargs_layer_3_size: 224\n",
      "\t* model_kwargs_layer_4_size: 448\n",
      "\t* model_kwargs_dropout: 0.600\n",
      "\t* model_kwargs_learning_rate: 0.002\n",
      "\t* model_kwargs_batch_size: 32\n",
      "results_fp ('predict_active_inactive', 2048, False):\n",
      "\t* radius: 3\n",
      "\t* fp_max_path: 9\n",
      "\t* num_layers: 2\n",
      "\t* smiles_enc_kwargs_layer_0_size: 576\n",
      "\t* smiles_enc_kwargs_layer_1_size: 352\n",
      "\t* smiles_enc_kwargs_fp_type: morgan_fp\n",
      "\t* smiles_enc_kwargs_dropout: 0.558\n",
      "\t* num_layers_extra: 3\n",
      "\t* model_kwargs_layer_0_size: 352\n",
      "\t* model_kwargs_layer_1_size: 192\n",
      "\t* model_kwargs_layer_2_size: 288\n",
      "\t* model_kwargs_dropout: 0.192\n",
      "\t* model_kwargs_learning_rate: 1.3e-04\n",
      "\t* model_kwargs_batch_size: 64\n",
      "results_fp ('predict_active_inactive', 4096, False):\n",
      "\t* radius: 5\n",
      "\t* fp_max_path: 9\n",
      "\t* num_layers: 2\n",
      "\t* smiles_enc_kwargs_layer_0_size: 32\n",
      "\t* smiles_enc_kwargs_layer_1_size: 704\n",
      "\t* smiles_enc_kwargs_fp_type: morgan_fp\n",
      "\t* smiles_enc_kwargs_dropout: 0.181\n",
      "\t* num_layers_extra: 4\n",
      "\t* model_kwargs_layer_0_size: 480\n",
      "\t* model_kwargs_layer_1_size: 736\n",
      "\t* model_kwargs_layer_2_size: 672\n",
      "\t* model_kwargs_layer_3_size: 128\n",
      "\t* model_kwargs_dropout: 0.264\n",
      "\t* model_kwargs_learning_rate: 3.2e-04\n",
      "\t* model_kwargs_batch_size: 64\n",
      "results_gnn ('predict_active_inactive', False, 'attentivefp'):\n",
      "\t* hidden_channels: 320\n",
      "\t* num_layers: 8\n",
      "\t* dropout: 0.588\n",
      "\t* out_channels: 768\n",
      "\t* num_timesteps: 64\n",
      "\t* num_layers_extra: 4\n",
      "\t* model_kwargs_layer_0_size: 288\n",
      "\t* model_kwargs_layer_1_size: 256\n",
      "\t* model_kwargs_layer_2_size: 192\n",
      "\t* model_kwargs_layer_3_size: 352\n",
      "\t* model_kwargs_dropout: 0.120\n",
      "\t* model_kwargs_learning_rate: 7.5e-05\n",
      "\t* model_kwargs_batch_size: 8\n",
      "\t* accumulate_grad_batches: 1\n",
      "results_gnn ('predict_active_inactive', False, 'gat'):\n",
      "\t* hidden_channels: 128\n",
      "\t* num_layers: 6\n",
      "\t* dropout: 0.385\n",
      "\t* out_channels: 64\n",
      "\t* jk: last\n",
      "\t* num_layers_extra: 2\n",
      "\t* model_kwargs_layer_0_size: 96\n",
      "\t* model_kwargs_layer_1_size: 64\n",
      "\t* model_kwargs_dropout: 0.197\n",
      "\t* model_kwargs_learning_rate: 0.001\n",
      "\t* model_kwargs_batch_size: 8\n",
      "\t* accumulate_grad_batches: 4\n",
      "results_gnn ('predict_active_inactive', False, 'gcn'):\n",
      "\t* hidden_channels: 384\n",
      "\t* num_layers: 3\n",
      "\t* dropout: 0.659\n",
      "\t* out_channels: 64\n",
      "\t* jk: last\n",
      "\t* num_layers_extra: 3\n",
      "\t* model_kwargs_layer_0_size: 384\n",
      "\t* model_kwargs_layer_1_size: 256\n",
      "\t* model_kwargs_layer_2_size: 96\n",
      "\t* model_kwargs_dropout: 0.101\n",
      "\t* model_kwargs_learning_rate: 3.2e-04\n",
      "\t* model_kwargs_batch_size: 8\n",
      "\t* accumulate_grad_batches: 1\n",
      "results_gnn ('predict_active_inactive', False, 'gin'):\n",
      "\t* hidden_channels: 128\n",
      "\t* num_layers: 3\n",
      "\t* dropout: 0.612\n",
      "\t* jk: lstm\n",
      "\t* num_layers_extra: 2\n",
      "\t* model_kwargs_layer_0_size: 448\n",
      "\t* model_kwargs_layer_1_size: 384\n",
      "\t* model_kwargs_dropout: 0.074\n",
      "\t* model_kwargs_learning_rate: 1.8e-05\n",
      "\t* model_kwargs_batch_size: 4\n",
      "\t* accumulate_grad_batches: 8\n",
      "results_transformer ('predict_active_inactive', False, 'entropy/roberta_zinc_480m'):\n",
      "\t* num_layers_extra: 5\n",
      "\t* layer_0_size: 384\n",
      "\t* layer_1_size: 448\n",
      "\t* layer_2_size: 384\n",
      "\t* layer_3_size: 352\n",
      "\t* layer_4_size: 64\n",
      "\t* dropout: 0.325\n",
      "\t* learning_rate: 4.0e-05\n",
      "\t* batch_size: 4\n",
      "\t* accumulate_grad_batches: 4\n",
      "results_transformer ('predict_active_inactive', False, 'seyonec/ChemBERTa-zinc-base-v1'):\n",
      "\t* num_layers_extra: 4\n",
      "\t* layer_0_size: 512\n",
      "\t* layer_1_size: 384\n",
      "\t* layer_2_size: 320\n",
      "\t* layer_3_size: 128\n",
      "\t* dropout: 0.133\n",
      "\t* learning_rate: 1.5e-05\n",
      "\t* batch_size: 4\n",
      "\t* accumulate_grad_batches: 4\n",
      "results_transformer ('predict_active_inactive', False, 'DeepChem/ChemBERTa-10M-MTR'):\n",
      "\t* num_layers_extra: 6\n",
      "\t* layer_0_size: 224\n",
      "\t* layer_1_size: 384\n",
      "\t* layer_2_size: 384\n",
      "\t* layer_3_size: 192\n",
      "\t* layer_4_size: 192\n",
      "\t* layer_5_size: 224\n",
      "\t* dropout: 0.400\n",
      "\t* learning_rate: 1.6e-04\n",
      "\t* batch_size: 8\n",
      "\t* accumulate_grad_batches: 2\n",
      "results_transformer ('predict_active_inactive', False, 'SSL_roberta_zinc_480m'):\n",
      "\t* num_layers_extra: 4\n",
      "\t* layer_0_size: 384\n",
      "\t* layer_1_size: 384\n",
      "\t* layer_2_size: 288\n",
      "\t* layer_3_size: 416\n",
      "\t* dropout: 0.351\n",
      "\t* learning_rate: 2.8e-05\n",
      "\t* batch_size: 4\n",
      "\t* accumulate_grad_batches: 4\n",
      "results_transformer ('predict_active_inactive', False, 'SSL_ChemBERTa-zinc-base-v1'):\n",
      "\t* num_layers_extra: 8\n",
      "\t* layer_0_size: 288\n",
      "\t* layer_1_size: 192\n",
      "\t* layer_2_size: 512\n",
      "\t* layer_3_size: 512\n",
      "\t* layer_4_size: 512\n",
      "\t* layer_5_size: 512\n",
      "\t* layer_6_size: 128\n",
      "\t* layer_7_size: 512\n",
      "\t* dropout: 0.027\n",
      "\t* learning_rate: 6.7e-05\n",
      "\t* batch_size: 8\n",
      "\t* accumulate_grad_batches: 8\n",
      "results_transformer ('predict_active_inactive', False, 'SSL_ChemBERTa-10M-MTR'):\n",
      "\t* num_layers_extra: 4\n",
      "\t* layer_0_size: 480\n",
      "\t* layer_1_size: 96\n",
      "\t* layer_2_size: 192\n",
      "\t* layer_3_size: 288\n",
      "\t* dropout: 0.559\n",
      "\t* learning_rate: 1.4e-04\n",
      "\t* batch_size: 8\n",
      "\t* accumulate_grad_batches: 2\n"
     ]
    }
   ],
   "source": [
    "experiments = [\n",
    "    'xgb',\n",
    "    'fp',\n",
    "    'gnn',\n",
    "    'transformer',\n",
    "]\n",
    "for experiment in experiments:\n",
    "    result_type = f'results_{experiment}'\n",
    "    experiments_results[result_type] = load_result(result_type)\n",
    "\n",
    "df_data = []\n",
    "df_data.append({\n",
    "    'Type': 'Reference',\n",
    "    'Models': 'Dummy',\n",
    "    'val_acc': 0.5132,\n",
    "    'val_roc_auc': 0.5,\n",
    "    'test_acc': 0.5930,\n",
    "    'test_roc_auc': 0.5,\n",
    "})\n",
    "df_data.append({\n",
    "    'Type': 'Reference',\n",
    "    'Models': 'DeepPROTACs',\n",
    "    'val_acc': 0.7795,\n",
    "    'val_roc_auc': 0.847,\n",
    "    'test_acc': 0.,\n",
    "    'test_roc_auc': 0.,\n",
    "})\n",
    "for k, results in experiments_results.items():\n",
    "    for experiment_id, design_points in results.items():\n",
    "        trial = design_points['trial']\n",
    "        attrs = trial.user_attrs\n",
    "        \n",
    "        print_dict(f'{k} {experiment_id}:', trial.params)\n",
    "        \n",
    "        attrs['Experiment ID'] = experiment_id\n",
    "        if 'xgb' in k:\n",
    "            fp_bits = experiment_id[1]\n",
    "            use_extra_features = experiment_id[-1]\n",
    "            if use_extra_features:\n",
    "                use_extra_features = ' w/ extra features'\n",
    "            else:\n",
    "                use_extra_features = ''\n",
    "            fp_type = trial.params['fp_type'].replace('_fp', '').upper()\n",
    "            attrs['Type'] = f'XGBoost'\n",
    "            attrs['Models'] = f'XGBoost - {fp_type}-{fp_bits}b{use_extra_features}'\n",
    "        if 'fp' in k:\n",
    "            fp_bits = experiment_id[1]\n",
    "            fp_type = trial.params['smiles_enc_kwargs_fp_type'].replace('_fp', '').upper()\n",
    "            attrs['Models'] = f'MLP - {fp_type}-{fp_bits}b'\n",
    "            attrs['Type'] = f'MLP'\n",
    "        if 'gnn' in k:\n",
    "            gnn_type = attrs['gnn_type']\n",
    "            attrs['Models'] = f'GNN - {gnn_type[0].upper()}{gnn_type[1:-2]}{gnn_type[-2:].upper()}'\n",
    "            attrs['Type'] = f'GNN'\n",
    "        if 'transformer' in k:\n",
    "            attrs['Models'] = f'BERT - {attrs[\"bert_type\"]}'\n",
    "            attrs['Type'] = f'Transformer'\n",
    "        \n",
    "        df_data.append(attrs)\n",
    "        # print(f'Experiment: {experiment_id}')\n",
    "        # print_dict('Hyperparams:', trial.params)\n",
    "        # print_dict('Attributes:', trial.user_attrs)\n",
    "        # print('-' * 80)\n",
    "df = pd.DataFrame(df_data).astype(np.float64, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Models</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Reference</td>\n",
       "      <td>Dummy</td>\n",
       "      <td>51.320000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>59.300000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Reference</td>\n",
       "      <td>DeepPROTACs</td>\n",
       "      <td>77.950000</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(predict_active_inactive, 1024, False, True)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost - MACCS-1024b w/ extra features</td>\n",
       "      <td>81.578946</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>56.976742</td>\n",
       "      <td>0.709524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(predict_active_inactive, 1024, False, False)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost - MORGAN-1024b</td>\n",
       "      <td>76.315790</td>\n",
       "      <td>0.797990</td>\n",
       "      <td>51.162791</td>\n",
       "      <td>0.576471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(predict_active_inactive, 2048, False, True)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost - MORGAN-2048b w/ extra features</td>\n",
       "      <td>73.684210</td>\n",
       "      <td>0.861053</td>\n",
       "      <td>53.488374</td>\n",
       "      <td>0.569188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(predict_active_inactive, 2048, False, False)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost - MORGAN-2048b</td>\n",
       "      <td>80.263156</td>\n",
       "      <td>0.813583</td>\n",
       "      <td>48.837209</td>\n",
       "      <td>0.501961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(predict_active_inactive, 4096, False, True)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost - MACCS-4096b w/ extra features</td>\n",
       "      <td>81.578946</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>56.976742</td>\n",
       "      <td>0.698319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(predict_active_inactive, 4096, False, False)</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>XGBoost - PATH-4096b</td>\n",
       "      <td>73.684210</td>\n",
       "      <td>0.827789</td>\n",
       "      <td>61.627907</td>\n",
       "      <td>0.627451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(predict_active_inactive, 1024, False)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MLP - MORGAN-1024b</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.818087</td>\n",
       "      <td>55.813956</td>\n",
       "      <td>0.606723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(predict_active_inactive, 2048, False)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MLP - MORGAN-2048b</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.796951</td>\n",
       "      <td>67.441863</td>\n",
       "      <td>0.677311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(predict_active_inactive, 4096, False)</td>\n",
       "      <td>MLP</td>\n",
       "      <td>MLP - MORGAN-4096b</td>\n",
       "      <td>80.263156</td>\n",
       "      <td>0.814969</td>\n",
       "      <td>54.651165</td>\n",
       "      <td>0.586275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(predict_active_inactive, False, attentivefp)</td>\n",
       "      <td>GNN</td>\n",
       "      <td>GNN - AttentiveFP</td>\n",
       "      <td>69.736844</td>\n",
       "      <td>0.709979</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.501961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(predict_active_inactive, False, gat)</td>\n",
       "      <td>GNN</td>\n",
       "      <td>GNN - GAT</td>\n",
       "      <td>68.421054</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>44.186047</td>\n",
       "      <td>0.463305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(predict_active_inactive, False, gcn)</td>\n",
       "      <td>GNN</td>\n",
       "      <td>GNN - GCN</td>\n",
       "      <td>76.315790</td>\n",
       "      <td>0.744629</td>\n",
       "      <td>62.790698</td>\n",
       "      <td>0.633053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(predict_active_inactive, False, gin)</td>\n",
       "      <td>GNN</td>\n",
       "      <td>GNN - GIN</td>\n",
       "      <td>72.368419</td>\n",
       "      <td>0.708247</td>\n",
       "      <td>60.465115</td>\n",
       "      <td>0.625210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(predict_active_inactive, False, entropy/roberta_zinc_480m)</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>BERT - roberta_zinc_480m</td>\n",
       "      <td>72.368419</td>\n",
       "      <td>0.866597</td>\n",
       "      <td>55.813956</td>\n",
       "      <td>0.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(predict_active_inactive, False, seyonec/ChemBERTa-zinc-base-v1)</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>BERT - ChemBERTa-zinc-base-v1</td>\n",
       "      <td>78.947371</td>\n",
       "      <td>0.863825</td>\n",
       "      <td>63.953489</td>\n",
       "      <td>0.624370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(predict_active_inactive, False, DeepChem/ChemBERTa-10M-MTR)</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>BERT - ChemBERTa-10M-MTR</td>\n",
       "      <td>76.315790</td>\n",
       "      <td>0.808039</td>\n",
       "      <td>63.953489</td>\n",
       "      <td>0.614566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(predict_active_inactive, False, SSL_roberta_zinc_480m)</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>BERT - SSL_roberta_zinc_480m</td>\n",
       "      <td>76.315790</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>61.627907</td>\n",
       "      <td>0.644538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>(predict_active_inactive, False, SSL_ChemBERTa-zinc-base-v1)</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>BERT - SSL_ChemBERTa-zinc-base-v1</td>\n",
       "      <td>77.631581</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>59.302324</td>\n",
       "      <td>0.609804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(predict_active_inactive, False, SSL_ChemBERTa-10M-MTR)</td>\n",
       "      <td>Transformer</td>\n",
       "      <td>BERT - SSL_ChemBERTa-10M-MTR</td>\n",
       "      <td>73.684210</td>\n",
       "      <td>0.812197</td>\n",
       "      <td>63.953489</td>\n",
       "      <td>0.587675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Experiment ID         Type                                    Models    val_acc  val_roc_auc   test_acc  test_roc_auc\n",
       "0                                                                NaN    Reference                                     Dummy  51.320000     0.500000  59.300000      0.500000\n",
       "1                                                                NaN    Reference                               DeepPROTACs  77.950000     0.847000   0.000000      0.000000\n",
       "2                       (predict_active_inactive, 1024, False, True)      XGBoost   XGBoost - MACCS-1024b w/ extra features  81.578946     0.826057  56.976742      0.709524\n",
       "3                      (predict_active_inactive, 1024, False, False)      XGBoost                    XGBoost - MORGAN-1024b  76.315790     0.797990  51.162791      0.576471\n",
       "4                       (predict_active_inactive, 2048, False, True)      XGBoost  XGBoost - MORGAN-2048b w/ extra features  73.684210     0.861053  53.488374      0.569188\n",
       "5                      (predict_active_inactive, 2048, False, False)      XGBoost                    XGBoost - MORGAN-2048b  80.263156     0.813583  48.837209      0.501961\n",
       "6                       (predict_active_inactive, 4096, False, True)      XGBoost   XGBoost - MACCS-4096b w/ extra features  81.578946     0.826057  56.976742      0.698319\n",
       "7                      (predict_active_inactive, 4096, False, False)      XGBoost                      XGBoost - PATH-4096b  73.684210     0.827789  61.627907      0.627451\n",
       "8                             (predict_active_inactive, 1024, False)          MLP                        MLP - MORGAN-1024b  75.000000     0.818087  55.813956      0.606723\n",
       "9                             (predict_active_inactive, 2048, False)          MLP                        MLP - MORGAN-2048b  75.000000     0.796951  67.441863      0.677311\n",
       "10                            (predict_active_inactive, 4096, False)          MLP                        MLP - MORGAN-4096b  80.263156     0.814969  54.651165      0.586275\n",
       "11                     (predict_active_inactive, False, attentivefp)          GNN                         GNN - AttentiveFP  69.736844     0.709979  50.000000      0.501961\n",
       "12                             (predict_active_inactive, False, gat)          GNN                                 GNN - GAT  68.421054     0.743243  44.186047      0.463305\n",
       "13                             (predict_active_inactive, False, gcn)          GNN                                 GNN - GCN  76.315790     0.744629  62.790698      0.633053\n",
       "14                             (predict_active_inactive, False, gin)          GNN                                 GNN - GIN  72.368419     0.708247  60.465115      0.625210\n",
       "15       (predict_active_inactive, False, entropy/roberta_zinc_480m)  Transformer                  BERT - roberta_zinc_480m  72.368419     0.866597  55.813956      0.566667\n",
       "16  (predict_active_inactive, False, seyonec/ChemBERTa-zinc-base-v1)  Transformer             BERT - ChemBERTa-zinc-base-v1  78.947371     0.863825  63.953489      0.624370\n",
       "17      (predict_active_inactive, False, DeepChem/ChemBERTa-10M-MTR)  Transformer                  BERT - ChemBERTa-10M-MTR  76.315790     0.808039  63.953489      0.614566\n",
       "18           (predict_active_inactive, False, SSL_roberta_zinc_480m)  Transformer              BERT - SSL_roberta_zinc_480m  76.315790     0.833333  61.627907      0.644538\n",
       "19      (predict_active_inactive, False, SSL_ChemBERTa-zinc-base-v1)  Transformer         BERT - SSL_ChemBERTa-zinc-base-v1  77.631581     0.818780  59.302324      0.609804\n",
       "20           (predict_active_inactive, False, SSL_ChemBERTa-10M-MTR)  Transformer              BERT - SSL_ChemBERTa-10M-MTR  73.684210     0.812197  63.953489      0.587675"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert all tensor entries into float values\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = df[col].apply(lambda x: x.item() if isinstance(x, torch.Tensor) else x)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df[['val_acc', 'test_acc']] *= 100\n",
    "display(df[['Experiment ID', 'Type', 'Models', 'val_acc', 'val_roc_auc', 'test_acc', 'test_roc_auc']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    ('Validation accuracy (%)', 'val_acc'),\n",
    "    ('Test accuracy (%)', 'test_acc'),\n",
    "    ('Validation AUC', 'val_roc_auc'),\n",
    "    ('Test AUC', 'test_roc_auc'),\n",
    "]\n",
    "for title, metric in metrics:\n",
    "    ax = sns.barplot(data=df, y='Models', x=metric, orient='h', palette='turbo')\n",
    "    if 'acc' in metric:\n",
    "        ax.set_xlim(0., 100.)\n",
    "        fmt = '%.2f'\n",
    "    else:\n",
    "        ax.set_xlim(0., 1.)\n",
    "        fmt = '%.2f'\n",
    "        # plt.grid(axis='x', alpha=0.5)\n",
    "\n",
    "    for bars_group in ax.containers:\n",
    "        ax.bar_label(bars_group, padding=5, fmt=fmt) # fontsize=12\n",
    "    \n",
    "    dummy_score = float(df[df['Models'] == 'Dummy'][metric])\n",
    "    ax.axvline(dummy_score, ls='--', c='black', alpha=0.3)\n",
    "    \n",
    "    ref_score = float(df[df['Models'] == 'DeepPROTACs'][metric])\n",
    "    if ref_score > 0:\n",
    "        ax.axvline(ref_score, ls='--', c='black', alpha=0.3)\n",
    "    \n",
    "    # plt.xticks(rotation=90)\n",
    "    plt.title(title)\n",
    "    # plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
    "    plt.savefig(os.path.join(fig_dir, f'barplot_{metric}.pdf'))\n",
    "    plt.savefig(os.path.join(fig_dir, f'barplot_{metric}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = df.copy()\n",
    "test_df = df.copy()\n",
    "\n",
    "# Copy 'val_acc' and 'val_roc_auc' columns to 'acc' and 'roc_auc' columns respectively\n",
    "val_df['Accuracy'] = df['val_acc']\n",
    "val_df['AUC'] = df['val_roc_auc']\n",
    "val_df['Dataset'] = 'Validation'\n",
    "\n",
    "test_df['Accuracy'] = df['test_acc']\n",
    "test_df['AUC'] = df['test_roc_auc']\n",
    "test_df['Dataset'] = 'Test'\n",
    "\n",
    "new_df = pd.concat([val_df, test_df])\n",
    "# Reset the index of the new dataframe\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "# display(new_df)\n",
    "\n",
    "# plt.figure(figsize=(6, 10))\n",
    "# ax = sns.barplot(data=new_df, x='Accuracy', y='Models', hue='Dataset', orient='h')\n",
    "# ax.set_xlim(0., 100.)\n",
    "# plt.grid(axis='x', alpha=0.8)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "ax = sns.barplot(data=new_df, y='Accuracy', x='Models', hue='Dataset')\n",
    "ax.set_ylim(0., 100.)\n",
    "plt.grid(axis='y', alpha=0.8)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "dummy_score = float(df[df['Models'] == 'Dummy']['test_acc'])\n",
    "# ax.axhline(dummy_score, ls='--', c='black', alpha=0.3)\n",
    "ax.axhline(dummy_score, ls='--', c='black', alpha=0.99, label='Dummy model\\ntest accuracy')\n",
    "\n",
    "fmt = '%.2f'\n",
    "fmt = '{:.1f}'\n",
    "for bars_group in ax.containers:\n",
    "    # Add note for DeepPROTACs test results not being available\n",
    "    labels = ['(Not available)' if x == 0 else f'{x:,.1f}' for x in bars_group.datavalues]\n",
    "    ax.bar_label(bars_group, padding=5, fmt=fmt, labels=labels, rotation=90) # fontsize=12\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
    "plt.title(f'Accuracy results (%)')\n",
    "f = os.path.join(fig_dir, f'barplot_accuracy')\n",
    "plt.savefig(f + '.pdf', bbox_inches='tight')\n",
    "plt.savefig(f + '.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "ax = sns.barplot(data=new_df, y='AUC', x='Models', hue='Dataset')\n",
    "ax.set_ylim(0., 1.)\n",
    "plt.grid(axis='y', alpha=0.8)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "dummy_score = float(df[df['Models'] == 'Dummy']['test_roc_auc'])\n",
    "# ax.axhline(dummy_score, ls='--', c='black', alpha=0.3)\n",
    "ax.axhline(dummy_score, ls='--', c='black', alpha=0.99, label='Dummy model\\ntest AUC')\n",
    "\n",
    "fmt = '%.2f'\n",
    "for bars_group in ax.containers:\n",
    "    labels = ['(Not available)' if x == 0 else f'{x:,.2f}' for x in bars_group.datavalues]\n",
    "    ax.bar_label(bars_group, padding=5, fmt=fmt, labels=labels, rotation=90) # fontsize=12\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
    "plt.title(f'AUC results')\n",
    "f = os.path.join(fig_dir, f'barplot_auc')\n",
    "plt.savefig(f + '.pdf', bbox_inches='tight')\n",
    "plt.savefig(f + '.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "new_df['Accuracy Drop'] = df['val_acc'] - df['test_acc']\n",
    "new_df['AUC Drop'] = df['val_roc_auc'] - df['test_roc_auc']\n",
    "\n",
    "# Drop Dummy and DeepPROTACs rows\n",
    "new_df = new_df[new_df['Models'] != 'Dummy']\n",
    "new_df = new_df[new_df['Models'] != 'DeepPROTACs']\n",
    "# Reset the index of the new dataframe\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "# plt.figure(figsize=(12, 4))\n",
    "ax = sns.barplot(data=new_df, y='Accuracy Drop', x='Type')\n",
    "# ax.set_ylim(0., 100.)\n",
    "plt.grid(axis='y', alpha=0.8)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "fmt = '{:.1f}%'\n",
    "for bars_group in ax.containers:\n",
    "    ax.bar_label(bars_group, padding=1, fmt=fmt, rotation=0) # fontsize=12\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
    "plt.title(f'Accuracy drops (%)')\n",
    "\n",
    "f = os.path.join(fig_dir, f'barplot_accuracy_drops_per_type')\n",
    "plt.savefig(f + '.pdf', bbox_inches='tight')\n",
    "plt.savefig(f + '.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()\n",
    "new_df['Accuracy Drop'] = df['val_acc'] - df['test_acc']\n",
    "new_df['AUC Drop'] = df['val_roc_auc'] - df['test_roc_auc']\n",
    "\n",
    "# Drop Dummy and DeepPROTACs rows\n",
    "new_df = new_df[new_df['Models'] != 'Dummy']\n",
    "new_df = new_df[new_df['Models'] != 'DeepPROTACs']\n",
    "# Reset the index of the new dataframe\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the resulting dataframe\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = sns.barplot(data=new_df, y='Accuracy Drop', x='Models')\n",
    "# ax.set_ylim(0., 100.)\n",
    "plt.grid(axis='y', alpha=0.8)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "fmt = '{:.1f}%'\n",
    "for bars_group in ax.containers:\n",
    "    ax.bar_label(bars_group, padding=1, fmt=fmt, rotation=0) # fontsize=12\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
    "plt.title(f'Accuracy drops (%)')\n",
    "\n",
    "f = os.path.join(fig_dir, f'barplot_accuracy_drops_per_model')\n",
    "plt.savefig(f + '.pdf', bbox_inches='tight')\n",
    "plt.savefig(f + '.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for k, results in load_result('results_transformer_ssl').items():\n",
    "    print_dict(k, results)\n",
    "    df_data.append({'BERT Model': k.replace('SSL_', ''), 'Perplexity on SSL set': 'Before finetuning', 'Perplexity score': results['train_perplexity_before']})\n",
    "    df_data.append({'BERT Model': k.replace('SSL_', ''), 'Perplexity on SSL set': 'After finetuning', 'Perplexity score': results['train_perplexity_after']})\n",
    "    df_data.append({'BERT Model': k.replace('SSL_', ''), 'Perplexity on Val set': 'Before finetuning', 'Perplexity score': results['val_perplexity_before']})\n",
    "    df_data.append({'BERT Model': k.replace('SSL_', ''), 'Perplexity on Val set': 'After finetuning', 'Perplexity score': results['val_perplexity_after']})\n",
    "df = pd.DataFrame(df_data).astype(np.float64, errors='ignore')\n",
    "\n",
    "for hue in ['Perplexity on SSL set', 'Perplexity on Val set']:\n",
    "    plt.figure(figsize=(8, 4.5))\n",
    "    ax = sns.barplot(data=df, y='Perplexity score', x='BERT Model', hue=hue)\n",
    "    # ax.set_ylim(0., 100.)\n",
    "    ax.set_yscale('log')\n",
    "    plt.grid(axis='y', alpha=0.8)\n",
    "    # plt.xticks(rotation=90)\n",
    "\n",
    "    fmt = '%.2f'\n",
    "    for bars_group in ax.containers:\n",
    "        ax.bar_label(bars_group, padding=0.5, fmt=fmt) # fontsize=12\n",
    "    # plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
    "    plt.title(hue)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames To LateX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from io import StringIO\n",
    "\n",
    "# csv = '''\n",
    "# Experiment ID\tType\tModels\tval_acc\tval_roc_auc\ttest_acc\ttest_roc_auc\n",
    "# NaN\tReference\tDummy\t51.320000\t0.500000\t59.300000\t0.500000\n",
    "# NaN\tReference\tDeepPROTACs\t77.950000\t0.847000\t0.000000\t0.000000\n",
    "# (predict_active_inactive, 1024, False, True)\tXGBoost\tXGBoost - MACCS-1024b w/ extra features\t81.578946\t0.826057\t56.976742\t0.709524\n",
    "# (predict_active_inactive, 1024, False, False)\tXGBoost\tXGBoost - MORGAN-1024b\t76.315790\t0.797990\t51.162791\t0.576471\n",
    "# (predict_active_inactive, 2048, False, True)\tXGBoost\tXGBoost - MORGAN-2048b w/ extra features\t73.684210\t0.861053\t53.488374\t0.569188\n",
    "# (predict_active_inactive, 2048, False, False)\tXGBoost\tXGBoost - MORGAN-2048b\t80.263156\t0.813583\t48.837209\t0.501961\n",
    "# (predict_active_inactive, 4096, False, True)\tXGBoost\tXGBoost - MACCS-4096b w/ extra features\t81.578946\t0.826057\t56.976742\t0.698319\n",
    "# (predict_active_inactive, 4096, False, False)\tXGBoost\tXGBoost - PATH-4096b\t73.684210\t0.827789\t61.627907\t0.627451\n",
    "# (predict_active_inactive, 1024, False)\tMLP\tMLP - MORGAN-1024b\t75.000000\t0.818087\t55.813956\t0.606723\n",
    "# (predict_active_inactive, 2048, False)\tMLP\tMLP - MORGAN-2048b\t75.000000\t0.796951\t67.441863\t0.677311\n",
    "# (predict_active_inactive, 4096, False)\tMLP\tMLP - MORGAN-4096b\t80.263156\t0.814969\t54.651165\t0.586275\n",
    "# (predict_active_inactive, False, attentivefp)\tGNN\tGNN - AttentiveFP\t69.736844\t0.709979\t50.000000\t0.501961\n",
    "# (predict_active_inactive, False, gat)\tGNN\tGNN - GAT\t68.421054\t0.743243\t44.186047\t0.463305\n",
    "# (predict_active_inactive, False, gcn)\tGNN\tGNN - GCN\t76.315790\t0.744629\t62.790698\t0.633053\n",
    "# (predict_active_inactive, False, gin)\tGNN\tGNN - GIN\t72.368419\t0.708247\t60.465115\t0.625210\n",
    "# (predict_active_inactive, False, entropy/roberta_zinc_480m)\tTransformer\tBERT - roberta_zinc_480m\t72.368419\t0.866597\t55.813956\t0.566667\n",
    "# (predict_active_inactive, False, seyonec/ChemBERTa-zinc-base-v1)\tTransformer\tBERT - ChemBERTa-zinc-base-v1\t78.947371\t0.863825\t63.953489\t0.624370\n",
    "# (predict_active_inactive, False, DeepChem/ChemBERTa-10M-MTR)\tTransformer\tBERT - ChemBERTa-10M-MTR\t76.315790\t0.808039\t63.953489\t0.614566\n",
    "# (predict_active_inactive, False, SSL_roberta_zinc_480m)\tTransformer\tBERT - SSL_roberta_zinc_480m\t76.315790\t0.833333\t61.627907\t0.644538\n",
    "# (predict_active_inactive, False, SSL_ChemBERTa-zinc-base-v1)\tTransformer\tBERT - SSL_ChemBERTa-zinc-base-v1\t77.631581\t0.818780\t59.302324\t0.609804\n",
    "# (predict_active_inactive, False, SSL_ChemBERTa-10M-MTR)\tTransformer\tBERT - SSL_ChemBERTa-10M-MTR\t73.684210\t0.812197\t63.953489\t0.587675\n",
    "# '''\n",
    "\n",
    "# df = pd.read_csv(StringIO(csv), sep='\\t')\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "results_xgb\n",
      "--------------------------------------------------------------------------------\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "{} &                   0 &                   1 &                   2 &                   3 &                   4 &                   5 \\\\\n",
      "\\midrule\n",
      "fp\\_type                   &            maccs\\_fp &           morgan\\_fp &           morgan\\_fp &           morgan\\_fp &            maccs\\_fp &             path\\_fp \\\\\n",
      "fp\\_radius                 &                   5 &                   2 &                   3 &                   2 &                  10 &                   7 \\\\\n",
      "fp\\_max\\_path               &                  10 &                   9 &                   9 &                  10 &                  10 &                  10 \\\\\n",
      "booster                   &              gbtree &            gblinear &                dart &            gblinear &                dart &                dart \\\\\n",
      "lambda                    &               3e-07 &               0.005 &               9e-06 &               1e-06 &               0.003 &               4e-05 \\\\\n",
      "alpha                     &               2e-08 &               5e-05 &               6e-08 &               2e-06 &               0.003 &               1e-06 \\\\\n",
      "max\\_depth                 &               2e+01 &                   - &                   7 &                   - &               1e+01 &               1e+01 \\\\\n",
      "eta                       &                0.03 &                   - &              0.0005 &                   - &                0.04 &               3e-06 \\\\\n",
      "gamma                     &               0.004 &                   - &               1e-07 &                   - &              0.0005 &               7e-05 \\\\\n",
      "grow\\_policy               &           lossguide &                   - &           depthwise &                   - &           lossguide &           lossguide \\\\\n",
      "extra\\_features (fixed)    &                True &               False &                True &               False &                True &               False \\\\\n",
      "Accuracy [\\%] (Validation) &  tensor(8.1579e+25) &  tensor(7.6316e+23) &  tensor(7.3684e+23) &  tensor(8.0263e+23) &  tensor(8.1579e+23) &  tensor(7.3684e+23) \\\\\n",
      "Accuracy [\\%] (Test)       &  tensor(5.6977e+25) &  tensor(5.1163e+23) &  tensor(5.3488e+23) &  tensor(4.8837e+23) &  tensor(5.6977e+23) &  tensor(6.1628e+23) \\\\\n",
      "ROC AUC (Validation)      &      tensor(0.8261) &      tensor(0.7980) &      tensor(0.8611) &      tensor(0.8136) &      tensor(0.8261) &      tensor(0.8278) \\\\\n",
      "ROC AUC (Test)            &      tensor(0.7095) &      tensor(0.5765) &      tensor(0.5692) &      tensor(0.5020) &      tensor(0.6983) &      tensor(0.6275) \\\\\n",
      "layer\\_sizes               &                  [] &                  [] &                  [] &                  [] &                  [] &                  [] \\\\\n",
      "sample\\_type               &                   - &                   - &             uniform &                   - &            weighted &             uniform \\\\\n",
      "normalize\\_type            &                   - &                   - &              forest &                   - &              forest &                tree \\\\\n",
      "rate\\_drop                 &                   - &                   - &                0.05 &                   - &               7e-05 &               1e-07 \\\\\n",
      "skip\\_drop                 &                   - &                   - &                 0.2 &                   - &                 0.5 &               4e-06 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "results_fp\n",
      "--------------------------------------------------------------------------------\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "{} &                          0 &                1 &                     2 \\\\\n",
      "\\midrule\n",
      "radius                         &                          2 &                3 &                     5 \\\\\n",
      "fp\\_max\\_path                    &                         10 &                9 &                     9 \\\\\n",
      "num\\_layers                     &                          2 &                2 &                     2 \\\\\n",
      "smiles\\_enc\\_kwargs\\_layer\\_0\\_size &                        608 &              576 &                    32 \\\\\n",
      "smiles\\_enc\\_kwargs\\_layer\\_1\\_size &                        768 &              352 &                   704 \\\\\n",
      "smiles\\_enc\\_kwargs\\_fp\\_type      &                  morgan\\_fp &        morgan\\_fp &             morgan\\_fp \\\\\n",
      "smiles\\_enc\\_kwargs\\_dropout      &                        0.2 &              0.6 &                   0.2 \\\\\n",
      "num\\_layers\\_extra               &                          5 &                3 &                     4 \\\\\n",
      "model\\_kwargs\\_layer\\_0\\_size      &                        480 &              352 &                   480 \\\\\n",
      "model\\_kwargs\\_layer\\_1\\_size      &                        928 &              192 &                   736 \\\\\n",
      "model\\_kwargs\\_layer\\_2\\_size      &                        224 &              288 &                   672 \\\\\n",
      "model\\_kwargs\\_layer\\_3\\_size      &                      2e+02 &                - &                 1e+02 \\\\\n",
      "model\\_kwargs\\_layer\\_4\\_size      &                      4e+02 &                - &                     - \\\\\n",
      "model\\_kwargs\\_dropout           &                        0.6 &              0.2 &                   0.3 \\\\\n",
      "model\\_kwargs\\_learning\\_rate     &                      0.002 &           0.0001 &                0.0003 \\\\\n",
      "model\\_kwargs\\_batch\\_size        &                         32 &               64 &                    64 \\\\\n",
      "fp\\_bits (fixed)                &                       1024 &             2048 &                  4096 \\\\\n",
      "Accuracy [\\%] (Validation)      &                      8e+01 &            8e+01 &                 8e+01 \\\\\n",
      "Accuracy [\\%] (Test)            &                      6e+01 &            7e+01 &                 5e+01 \\\\\n",
      "ROC AUC (Validation)           &                        0.8 &              0.8 &                   0.8 \\\\\n",
      "ROC AUC (Test)                 &                        0.6 &              0.7 &                   0.6 \\\\\n",
      "layer\\_sizes                    &  [480, 928, 224, 224, 448] &  [352, 192, 288] &  [480, 736, 672, 128] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "results_gnn\n",
      "--------------------------------------------------------------------------------\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "{} &                     0 &         1 &               2 &           3 \\\\\n",
      "\\midrule\n",
      "hidden\\_channels            &                   320 &       128 &             384 &         128 \\\\\n",
      "num\\_layers                 &                     8 &         6 &               3 &           3 \\\\\n",
      "dropout                    &                   0.6 &       0.4 &             0.7 &         0.6 \\\\\n",
      "out\\_channels               &                 8e+02 &     6e+01 &           6e+01 &           - \\\\\n",
      "num\\_timesteps              &                 6e+01 &         - &               - &           - \\\\\n",
      "num\\_layers\\_extra           &                     4 &         2 &               3 &           2 \\\\\n",
      "model\\_kwargs\\_layer\\_0\\_size  &                   288 &        96 &             384 &         448 \\\\\n",
      "model\\_kwargs\\_layer\\_1\\_size  &                   256 &        64 &             256 &         384 \\\\\n",
      "model\\_kwargs\\_layer\\_2\\_size  &                 2e+02 &         - &           1e+02 &           - \\\\\n",
      "model\\_kwargs\\_layer\\_3\\_size  &                 4e+02 &         - &               - &           - \\\\\n",
      "model\\_kwargs\\_dropout       &                   0.1 &       0.2 &             0.1 &        0.07 \\\\\n",
      "model\\_kwargs\\_learning\\_rate &                 8e-05 &     0.001 &          0.0003 &       2e-05 \\\\\n",
      "model\\_kwargs\\_batch\\_size    &                     8 &         8 &               8 &           4 \\\\\n",
      "accumulate\\_grad\\_batches    &                     1 &         4 &               1 &           8 \\\\\n",
      "gnn\\_type (fixed)           &           attentivefp &       gat &             gcn &         gin \\\\\n",
      "Accuracy [\\%] (Validation)  &                 7e+01 &     7e+01 &           8e+01 &       7e+01 \\\\\n",
      "Accuracy [\\%] (Test)        &                 5e+01 &     4e+01 &           6e+01 &       6e+01 \\\\\n",
      "ROC AUC (Validation)       &                   0.7 &       0.7 &             0.7 &         0.7 \\\\\n",
      "ROC AUC (Test)             &                   0.5 &       0.5 &             0.6 &         0.6 \\\\\n",
      "layer\\_sizes                &  [288, 256, 192, 352] &  [96, 64] &  [384, 256, 96] &  [448, 384] \\\\\n",
      "jk                         &                     - &      last &            last &        lstm \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "results_transformer\n",
      "--------------------------------------------------------------------------------\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "{} &                         0 &                       1 &                               2 &                      3 &                                         4 &                      5 \\\\\n",
      "\\midrule\n",
      "num\\_layers\\_extra          &                         5 &                       4 &                               6 &                      4 &                                         8 &                      4 \\\\\n",
      "layer\\_0\\_size              &                       384 &                     512 &                             224 &                    384 &                                       288 &                    480 \\\\\n",
      "layer\\_1\\_size              &                       448 &                     384 &                             384 &                    384 &                                       192 &                     96 \\\\\n",
      "layer\\_2\\_size              &                       384 &                     320 &                             384 &                    288 &                                       512 &                    192 \\\\\n",
      "layer\\_3\\_size              &                       352 &                     128 &                             192 &                    416 &                                       512 &                    288 \\\\\n",
      "layer\\_4\\_size              &                     6e+01 &                       - &                           2e+02 &                      - &                                     5e+02 &                      - \\\\\n",
      "dropout                   &                       0.3 &                     0.1 &                             0.4 &                    0.4 &                                      0.03 &                    0.6 \\\\\n",
      "learning\\_rate             &                     4e-05 &                   1e-05 &                          0.0002 &                  3e-05 &                                     7e-05 &                 0.0001 \\\\\n",
      "batch\\_size                &                         4 &                       4 &                               8 &                      4 &                                         8 &                      8 \\\\\n",
      "accumulate\\_grad\\_batches   &                         4 &                       4 &                               2 &                      4 &                                         8 &                      2 \\\\\n",
      "bert\\_type (fixed)         &         roberta\\_zinc\\_480m &  ChemBERTa-zinc-base-v1 &               ChemBERTa-10M-MTR &  SSL\\_roberta\\_zinc\\_480m &                SSL\\_ChemBERTa-zinc-base-v1 &  SSL\\_ChemBERTa-10M-MTR \\\\\n",
      "Accuracy [\\%] (Validation) &                     7e+01 &                   8e+01 &                           8e+01 &                  8e+01 &                                     8e+01 &                  7e+01 \\\\\n",
      "Accuracy [\\%] (Test)       &                     6e+01 &                   6e+01 &                           6e+01 &                  6e+01 &                                     6e+01 &                  6e+01 \\\\\n",
      "ROC AUC (Validation)      &                       0.9 &                     0.9 &                             0.8 &                    0.8 &                                       0.8 &                    0.8 \\\\\n",
      "ROC AUC (Test)            &                       0.6 &                     0.6 &                             0.6 &                    0.6 &                                       0.6 &                    0.6 \\\\\n",
      "layer\\_sizes               &  [384, 448, 384, 352, 64] &    [512, 384, 320, 128] &  [224, 384, 384, 192, 192, 224] &   [384, 384, 288, 416] &  [288, 192, 512, 512, 512, 512, 128, 512] &    [480, 96, 192, 288] \\\\\n",
      "layer\\_5\\_size              &                         - &                       - &                           2e+02 &                      - &                                     5e+02 &                      - \\\\\n",
      "layer\\_6\\_size              &                         - &                       - &                               - &                      - &                                     1e+02 &                      - \\\\\n",
      "layer\\_7\\_size              &                         - &                       - &                               - &                      - &                                     5e+02 &                      - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ste\\AppData\\Local\\Temp\\ipykernel_27180\\920848393.py:34: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(tmp.T.to_latex(escape=True, float_format='{:4.1g}'.format))\n",
      "C:\\Users\\ste\\AppData\\Local\\Temp\\ipykernel_27180\\920848393.py:34: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(tmp.T.to_latex(escape=True, float_format='{:4.1g}'.format))\n",
      "C:\\Users\\ste\\AppData\\Local\\Temp\\ipykernel_27180\\920848393.py:34: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(tmp.T.to_latex(escape=True, float_format='{:4.1g}'.format))\n",
      "C:\\Users\\ste\\AppData\\Local\\Temp\\ipykernel_27180\\920848393.py:34: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(tmp.T.to_latex(escape=True, float_format='{:4.1g}'.format))\n"
     ]
    }
   ],
   "source": [
    "old2new = {\n",
    "    'val_acc': 'Accuracy [%] (Validation)',\n",
    "    'test_acc': 'Accuracy [%] (Test)',\n",
    "    'val_roc_auc': 'ROC AUC (Validation)',\n",
    "    'test_roc_auc': 'ROC AUC (Test)',\n",
    "}\n",
    "for k, results in experiments_results.items():\n",
    "    print('-' * 80)\n",
    "    print(k)\n",
    "    print('-' * 80)\n",
    "    tmp = []\n",
    "    for experiment_id, design_points in results.items():\n",
    "        params = design_points['trial'].params.copy()\n",
    "        params.update({q: design_points['trial'].user_attrs[q] for q in old2new.keys()})\n",
    "        params['val_acc'] *= 100.0\n",
    "        params['test_acc'] *= 100.0\n",
    "        params['layer_sizes'] = []\n",
    "        for k, v in params.items():\n",
    "            if 'layer' in k and 'size' in k and 'smiles' not in k and 'layer_sizes' not in k:\n",
    "                params['layer_sizes'].append(v)\n",
    "        if 'xgb' in k:\n",
    "            params['extra_features (fixed)'] = experiment_id[-1]\n",
    "        elif 'fp' in k:\n",
    "            params['fp_bits (fixed)'] = experiment_id[1]\n",
    "        elif 'gnn' in k:\n",
    "            params['gnn_type (fixed)'] = experiment_id[-1]\n",
    "        elif 'transformer' in k:\n",
    "            params['bert_type (fixed)'] = experiment_id[-1].split('/')[-1]\n",
    "        tmp.append(params)\n",
    "        # print_dict(f'{k} {experiment_id}:', trial.params)\n",
    "    tmp = pd.DataFrame(tmp).fillna('-')\n",
    "    tmp = tmp.rename(columns=old2new)\n",
    "    # print(tmp.T.to_latex(escape=True))\n",
    "    print(tmp.T.to_latex(escape=True, float_format='{:4.1g}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_xgb ('predict_active_inactive', 1024, False, True):\n",
      "\t* fp_type: maccs_fp\n",
      "\t* fp_radius: 5\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: gbtree\n",
      "\t* lambda: 3.2e-07\n",
      "\t* alpha: 1.7e-08\n",
      "\t* max_depth: 15\n",
      "\t* eta: 0.034\n",
      "\t* gamma: 0.004\n",
      "\t* grow_policy: lossguide\n",
      "results_xgb ('predict_active_inactive', 1024, False, False):\n",
      "\t* fp_type: morgan_fp\n",
      "\t* fp_radius: 2\n",
      "\t* fp_max_path: 9\n",
      "\t* booster: gblinear\n",
      "\t* lambda: 0.005\n",
      "\t* alpha: 5.1e-05\n",
      "results_xgb ('predict_active_inactive', 2048, False, True):\n",
      "\t* fp_type: morgan_fp\n",
      "\t* fp_radius: 3\n",
      "\t* fp_max_path: 9\n",
      "\t* booster: dart\n",
      "\t* lambda: 8.7e-06\n",
      "\t* alpha: 6.1e-08\n",
      "\t* max_depth: 7\n",
      "\t* eta: 5.3e-04\n",
      "\t* gamma: 1.3e-07\n",
      "\t* grow_policy: depthwise\n",
      "\t* sample_type: uniform\n",
      "\t* normalize_type: forest\n",
      "\t* rate_drop: 0.053\n",
      "\t* skip_drop: 0.166\n",
      "results_xgb ('predict_active_inactive', 2048, False, False):\n",
      "\t* fp_type: morgan_fp\n",
      "\t* fp_radius: 2\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: gblinear\n",
      "\t* lambda: 1.1e-06\n",
      "\t* alpha: 2.1e-06\n",
      "results_xgb ('predict_active_inactive', 4096, False, True):\n",
      "\t* fp_type: maccs_fp\n",
      "\t* fp_radius: 10\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: dart\n",
      "\t* lambda: 0.003\n",
      "\t* alpha: 0.003\n",
      "\t* max_depth: 13\n",
      "\t* eta: 0.036\n",
      "\t* gamma: 4.6e-04\n",
      "\t* grow_policy: lossguide\n",
      "\t* sample_type: weighted\n",
      "\t* normalize_type: forest\n",
      "\t* rate_drop: 6.6e-05\n",
      "\t* skip_drop: 0.477\n",
      "results_xgb ('predict_active_inactive', 4096, False, False):\n",
      "\t* fp_type: path_fp\n",
      "\t* fp_radius: 7\n",
      "\t* fp_max_path: 10\n",
      "\t* booster: dart\n",
      "\t* lambda: 4.4e-05\n",
      "\t* alpha: 1.2e-06\n",
      "\t* max_depth: 10\n",
      "\t* eta: 3.2e-06\n",
      "\t* gamma: 6.6e-05\n",
      "\t* grow_policy: lossguide\n",
      "\t* sample_type: uniform\n",
      "\t* normalize_type: tree\n",
      "\t* rate_drop: 9.6e-08\n",
      "\t* skip_drop: 4.0e-06\n",
      "\\begin{tabular}{lllllll}\n",
      "\\toprule\n",
      "{} &          0 &          1 &          2 &          3 &          4 &          5 \\\\\n",
      "\\midrule\n",
      "fp\\_type        &   maccs\\_fp &  morgan\\_fp &  morgan\\_fp &  morgan\\_fp &   maccs\\_fp &    path\\_fp \\\\\n",
      "fp\\_radius      &          5 &          2 &          3 &          2 &         10 &          7 \\\\\n",
      "fp\\_max\\_path    &         10 &          9 &          9 &         10 &         10 &         10 \\\\\n",
      "booster        &     gbtree &   gblinear &       dart &   gblinear &       dart &       dart \\\\\n",
      "lambda         &       0.00 &       0.01 &       0.00 &       0.00 &       0.00 &       0.00 \\\\\n",
      "alpha          &       0.00 &       0.00 &       0.00 &       0.00 &       0.00 &       0.00 \\\\\n",
      "max\\_depth      &      15.00 &        NaN &       7.00 &        NaN &      13.00 &      10.00 \\\\\n",
      "eta            &       0.03 &        NaN &       0.00 &        NaN &       0.04 &       0.00 \\\\\n",
      "gamma          &       0.00 &        NaN &       0.00 &        NaN &       0.00 &       0.00 \\\\\n",
      "grow\\_policy    &  lossguide &        NaN &  depthwise &        NaN &  lossguide &  lossguide \\\\\n",
      "sample\\_type    &        NaN &        NaN &    uniform &        NaN &   weighted &    uniform \\\\\n",
      "normalize\\_type &        NaN &        NaN &     forest &        NaN &     forest &       tree \\\\\n",
      "rate\\_drop      &        NaN &        NaN &       0.05 &        NaN &       0.00 &       0.00 \\\\\n",
      "skip\\_drop      &        NaN &        NaN &       0.17 &        NaN &       0.48 &       0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ste\\AppData\\Local\\Temp\\ipykernel_27180\\2478884251.py:46: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(tmp.T.to_latex(escape=True, float_format='{:0.2f}'.format))\n",
      "C:\\Users\\ste\\AppData\\Local\\Temp\\ipykernel_27180\\2478884251.py:48: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(tmp.T.to_latex(escape=True, float_format='{:0.ef}'.format))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Format specifier missing precision",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[39mprint\u001b[39m(tmp\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mto_latex(escape\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, float_format\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{:0.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat))\n\u001b[0;32m     47\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[39mprint\u001b[39m(tmp\u001b[39m.\u001b[39;49mT\u001b[39m.\u001b[39;49mto_latex(escape\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, float_format\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m:0.ef}\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat))\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\core\\generic.py:3469\u001b[0m, in \u001b[0;36mNDFrame.to_latex\u001b[1;34m(self, buf, columns, col_space, header, index, na_rep, formatters, float_format, sparsify, index_names, bold_rows, column_format, longtable, escape, encoding, decimal, multicolumn, multicolumn_format, multirow, caption, label, position)\u001b[0m\n\u001b[0;32m   3453\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m cast(\u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m)\n\u001b[0;32m   3454\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3455\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   3456\u001b[0m     columns\u001b[39m=\u001b[39mcolumns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3467\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3468\u001b[0m )\n\u001b[1;32m-> 3469\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_latex(\n\u001b[0;32m   3470\u001b[0m     buf\u001b[39m=\u001b[39;49mbuf,\n\u001b[0;32m   3471\u001b[0m     column_format\u001b[39m=\u001b[39;49mcolumn_format,\n\u001b[0;32m   3472\u001b[0m     longtable\u001b[39m=\u001b[39;49mlongtable,\n\u001b[0;32m   3473\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3474\u001b[0m     multicolumn\u001b[39m=\u001b[39;49mmulticolumn,\n\u001b[0;32m   3475\u001b[0m     multicolumn_format\u001b[39m=\u001b[39;49mmulticolumn_format,\n\u001b[0;32m   3476\u001b[0m     multirow\u001b[39m=\u001b[39;49mmultirow,\n\u001b[0;32m   3477\u001b[0m     caption\u001b[39m=\u001b[39;49mcaption,\n\u001b[0;32m   3478\u001b[0m     label\u001b[39m=\u001b[39;49mlabel,\n\u001b[0;32m   3479\u001b[0m     position\u001b[39m=\u001b[39;49mposition,\n\u001b[0;32m   3480\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1059\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_latex\u001b[1;34m(self, buf, column_format, longtable, encoding, multicolumn, multicolumn_format, multirow, caption, label, position)\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mformats\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlatex\u001b[39;00m \u001b[39mimport\u001b[39;00m LatexFormatter\n\u001b[0;32m   1048\u001b[0m latex_formatter \u001b[39m=\u001b[39m LatexFormatter(\n\u001b[0;32m   1049\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1050\u001b[0m     longtable\u001b[39m=\u001b[39mlongtable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     position\u001b[39m=\u001b[39mposition,\n\u001b[0;32m   1058\u001b[0m )\n\u001b[1;32m-> 1059\u001b[0m string \u001b[39m=\u001b[39m latex_formatter\u001b[39m.\u001b[39;49mto_string()\n\u001b[0;32m   1060\u001b[0m \u001b[39mreturn\u001b[39;00m save_to_buffer(string, buf\u001b[39m=\u001b[39mbuf, encoding\u001b[39m=\u001b[39mencoding)\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\latex.py:719\u001b[0m, in \u001b[0;36mLatexFormatter.to_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_string\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    715\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m    Render a DataFrame to a LaTeX tabular, longtable, or table/tabular\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \u001b[39m    environment output.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\latex.py:357\u001b[0m, in \u001b[0;36mTableBuilderAbstract.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_result\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[39m\"\"\"String representation of LaTeX table.\"\"\"\u001b[39;00m\n\u001b[0;32m    354\u001b[0m     elements \u001b[39m=\u001b[39m [\n\u001b[0;32m    355\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv_begin,\n\u001b[0;32m    356\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtop_separator,\n\u001b[1;32m--> 357\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheader,\n\u001b[0;32m    358\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmiddle_separator,\n\u001b[0;32m    359\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv_body,\n\u001b[0;32m    360\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbottom_separator,\n\u001b[0;32m    361\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv_end,\n\u001b[0;32m    362\u001b[0m     ]\n\u001b[0;32m    363\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m elements \u001b[39mif\u001b[39;00m item])\n\u001b[0;32m    364\u001b[0m     trailing_newline \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\latex.py:409\u001b[0m, in \u001b[0;36mGenericTableBuilder.header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mheader\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     iterator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_row_iterator(over\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mheader\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    410\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mlist\u001b[39m(iterator))\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\latex.py:472\u001b[0m, in \u001b[0;36mGenericTableBuilder._create_row_iterator\u001b[1;34m(self, over)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39m\"\"\"Create iterator over header or body of the table.\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \n\u001b[0;32m    461\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39m    Iterator over body or header.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    471\u001b[0m iterator_kind \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_iterator(over)\n\u001b[1;32m--> 472\u001b[0m \u001b[39mreturn\u001b[39;00m iterator_kind(\n\u001b[0;32m    473\u001b[0m     formatter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfmt,\n\u001b[0;32m    474\u001b[0m     multicolumn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulticolumn,\n\u001b[0;32m    475\u001b[0m     multicolumn_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulticolumn_format,\n\u001b[0;32m    476\u001b[0m     multirow\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultirow,\n\u001b[0;32m    477\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\latex.py:86\u001b[0m, in \u001b[0;36mRowStringConverter.__init__\u001b[1;34m(self, formatter, multicolumn, multicolumn_format, multirow)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultirow \u001b[39m=\u001b[39m multirow\n\u001b[0;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclinebuf: \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[\u001b[39mint\u001b[39m]] \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrcols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_strcols()\n\u001b[0;32m     87\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrrows \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrcols))\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\latex.py:147\u001b[0m, in \u001b[0;36mRowStringConverter._get_strcols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    145\u001b[0m     strcols \u001b[39m=\u001b[39m [[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_empty_info_line]]\n\u001b[0;32m    146\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     strcols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfmt\u001b[39m.\u001b[39;49mget_strcols()\n\u001b[0;32m    149\u001b[0m \u001b[39m# reestablish the MultiIndex that has been joined by get_strcols()\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt\u001b[39m.\u001b[39mindex \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mindex, ABCMultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\format.py:617\u001b[0m, in \u001b[0;36mDataFrameFormatter.get_strcols\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_strcols\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m]]:\n\u001b[0;32m    614\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[39m    Render a DataFrame to a list of columns (as lists of strings).\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 617\u001b[0m     strcols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_strcols_without_index()\n\u001b[0;32m    619\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex:\n\u001b[0;32m    620\u001b[0m         str_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_formatted_index(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame)\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\format.py:883\u001b[0m, in \u001b[0;36mDataFrameFormatter._get_strcols_without_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    879\u001b[0m cheader \u001b[39m=\u001b[39m str_columns[i]\n\u001b[0;32m    880\u001b[0m header_colwidth \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\n\u001b[0;32m    881\u001b[0m     \u001b[39mint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcol_space\u001b[39m.\u001b[39mget(c, \u001b[39m0\u001b[39m)), \u001b[39m*\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj\u001b[39m.\u001b[39mlen(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m cheader)\n\u001b[0;32m    882\u001b[0m )\n\u001b[1;32m--> 883\u001b[0m fmt_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_col(i)\n\u001b[0;32m    884\u001b[0m fmt_values \u001b[39m=\u001b[39m _make_fixed_width(\n\u001b[0;32m    885\u001b[0m     fmt_values, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjustify, minimum\u001b[39m=\u001b[39mheader_colwidth, adj\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj\n\u001b[0;32m    886\u001b[0m )\n\u001b[0;32m    888\u001b[0m max_len \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madj\u001b[39m.\u001b[39mlen(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m fmt_values), header_colwidth)\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\format.py:897\u001b[0m, in \u001b[0;36mDataFrameFormatter.format_col\u001b[1;34m(self, i)\u001b[0m\n\u001b[0;32m    895\u001b[0m frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtr_frame\n\u001b[0;32m    896\u001b[0m formatter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_formatter(i)\n\u001b[1;32m--> 897\u001b[0m \u001b[39mreturn\u001b[39;00m format_array(\n\u001b[0;32m    898\u001b[0m     frame\u001b[39m.\u001b[39;49miloc[:, i]\u001b[39m.\u001b[39;49m_values,\n\u001b[0;32m    899\u001b[0m     formatter,\n\u001b[0;32m    900\u001b[0m     float_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfloat_format,\n\u001b[0;32m    901\u001b[0m     na_rep\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mna_rep,\n\u001b[0;32m    902\u001b[0m     space\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcol_space\u001b[39m.\u001b[39;49mget(frame\u001b[39m.\u001b[39;49mcolumns[i]),\n\u001b[0;32m    903\u001b[0m     decimal\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecimal,\n\u001b[0;32m    904\u001b[0m     leading_space\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex,\n\u001b[0;32m    905\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1328\u001b[0m, in \u001b[0;36mformat_array\u001b[1;34m(values, formatter, float_format, na_rep, digits, space, justify, decimal, leading_space, quoting)\u001b[0m\n\u001b[0;32m   1313\u001b[0m     digits \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mdisplay.precision\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1315\u001b[0m fmt_obj \u001b[39m=\u001b[39m fmt_klass(\n\u001b[0;32m   1316\u001b[0m     values,\n\u001b[0;32m   1317\u001b[0m     digits\u001b[39m=\u001b[39mdigits,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     quoting\u001b[39m=\u001b[39mquoting,\n\u001b[0;32m   1326\u001b[0m )\n\u001b[1;32m-> 1328\u001b[0m \u001b[39mreturn\u001b[39;00m fmt_obj\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1359\u001b[0m, in \u001b[0;36mGenericArrayFormatter.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_result\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m-> 1359\u001b[0m     fmt_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_format_strings()\n\u001b[0;32m   1360\u001b[0m     \u001b[39mreturn\u001b[39;00m _make_fixed_width(fmt_values, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjustify)\n",
      "File \u001b[1;32mc:\\Users\\ste\\Anaconda2\\envs\\env-thesis\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1424\u001b[0m, in \u001b[0;36mGenericArrayFormatter._format_strings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1422\u001b[0m     fmt_values\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00m_format(v)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1423\u001b[0m \u001b[39melif\u001b[39;00m is_float_type[i]:\n\u001b[1;32m-> 1424\u001b[0m     fmt_values\u001b[39m.\u001b[39mappend(float_format(v))\n\u001b[0;32m   1425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1426\u001b[0m     \u001b[39mif\u001b[39;00m leading_space \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m         \u001b[39m# False specifically, so that the default is\u001b[39;00m\n\u001b[0;32m   1428\u001b[0m         \u001b[39m# to include a space if we get here.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Format specifier missing precision"
     ]
    }
   ],
   "source": [
    "tmp = df[df['Type'] == 'XGBoost'].astype(np.float64, errors='ignore')\n",
    "# tmp = tmp.dropna()\n",
    "\n",
    "old2new = {\n",
    "    'val_acc': 'Accuracy [%] (Validation)',\n",
    "    'test_acc': 'Accuracy [%] (Test)',\n",
    "    'val_roc_auc': 'ROC AUC (Validation)',\n",
    "    'test_roc_auc': 'ROC AUC (Test)',\n",
    "}\n",
    "tmp = tmp.rename(columns=old2new)\n",
    "\n",
    "# def polish(row):\n",
    "#     if 'w/ extra features' in row['Models']:\n",
    "#         row['extra_features (fixed)'] = True\n",
    "#     else:\n",
    "#         row['extra_features (fixed)'] = False\n",
    "#     if '1024' in row['Models']:\n",
    "#         row['fp_bits (fixed)'] = 1024\n",
    "#     if '2048' in row['Models']:\n",
    "#         row['fp_bits (fixed)'] = 2048\n",
    "#     if '4096' in row['Models']:\n",
    "#         row['fp_bits (fixed)'] = 4096\n",
    "#     if 'MACCS' in row['Models']:\n",
    "#         row['fp_bits (fixed)'] = 167\n",
    "#         row['fp_type'] = 'MACCS'\n",
    "#     if 'MORGAN' in row['Models']:\n",
    "#         row['fp_type'] = 'Morgan'\n",
    "#     if 'PATH' in row['Models']:\n",
    "#         row['fp_type'] = 'Path'\n",
    "#     return row\n",
    "\n",
    "# tmp = tmp.apply(polish, axis=1)\n",
    "\n",
    "# print(tmp.T.style.to_latex())\n",
    "# print('\\n\\n')\n",
    "\n",
    "print(tmp.T.to_latex(escape=True, float_format='{:0.2f}'.format))\n",
    "print('\\n\\n')\n",
    "print(tmp.T.to_latex(escape=True, float_format='{:0.e}'.format))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (5, 5)\n",
    "plt.figure(figsize=figsize)\n",
    "opt_point = (0.45, 0.7)\n",
    "rand_space = np.random.random(size=(100, 2))\n",
    "plt.scatter(rand_space[:, 0], rand_space[:, 1], label='Searched points')\n",
    "plt.scatter(*opt_point, marker='x', c='r', label='Optimal point')\n",
    "plt.title('Random search')\n",
    "plt.xlabel('Hyperparameter 1')\n",
    "plt.ylabel('Hyperparameter 2')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.8)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "for i in range(10):\n",
    "    x = np.random.default_rng().uniform(opt_point[0] - i * 0.1, opt_point[0] + i * 0.1, max(1, 20 - i * 2))\n",
    "    y = np.random.default_rng().uniform(opt_point[1] - i * 0.1, opt_point[1] + i * 0.1, max(1, 20 - i * 2))\n",
    "    plt.scatter(x, y, c='C0', label='Searched points' if i == 0 else '')\n",
    "# plt.scatter(rand_space[:, 0], rand_space[:, 1], c='C0', label='Searched points')\n",
    "rand_space = np.random.random(size=(5, 2))\n",
    "\n",
    "plt.scatter(*opt_point, marker='x', c='r', label='Optimal point')\n",
    "plt.title('Optimized Optuna search')\n",
    "plt.xlabel('Hyperparameter 1')\n",
    "plt.ylabel('Hyperparameter 2')\n",
    "plt.legend()\n",
    "plt.xlim(0., 1.)\n",
    "plt.ylim(0., 1.)\n",
    "plt.grid(alpha=0.8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
