{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROTAC Complex Encoding\n",
    "\n",
    "Collection of ideas and unfinished work. To be ignored for now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Encoding\n",
    "\n",
    "EVOformer from AlphaFold may be used for predicting molecule structures. The problem with general molecules is that they do not have a structure as proteins. Proteins are polymers, and each individual amino acid has its own shape, so this information is somehow leveraged by AlphaFold in its predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'use_morgan_fp': ('categorical', [True, False]),\n",
    "    'use_maccs_fp': ('categorical', [True, False]),\n",
    "    'use_path_fp': ('categorical', [True, False]),\n",
    "    'pathfp_min_path': (int, 1, 32),\n",
    "    'pathfp_max_path': (int, 1, 64),\n",
    "    'morgan_bitwidth': (int, 1024, 2048),\n",
    "    'pathfp_bitwidth': (int, 1024, 2048),\n",
    "    'morgan_encoder_hidden_sz': (int, 256, 2048),\n",
    "    'maccs_encoder_hidden_sz': (int, 256, 2048),\n",
    "    'pathfp_encoder_hidden_sz': (int, 256, 2048),\n",
    "    'learning_rate': (float, 1e-5, 1e-3),\n",
    "    'gnn_layer_type': ('categorical', ['GraphConv', 'GCN', 'GAT']),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding SELFIES via ChemGPT (DEPRECATED)\n",
    "\n",
    "> Christian: SELFIES are not useful, we have already investigated and studied them.\n",
    "\n",
    "Let's start by installing and importing the required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selfies sentencepiece transformers datasets wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_from_disk\n",
    "import selfies as sf\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the dataset will consist of a pair of the SELFIES encoding and the degradation percentage. In order to get the SELFIES encoding, each SMILES entry (without stereochemistry information) is converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [(sf.encoder(x['Smiles_nostereo']), x['degradation']) for x in train_upsampled.to_dict(orient='records')]\n",
    "df = pd.DataFrame(entries, columns=['text', 'labels'])\n",
    "train_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "entries = [(sf.encoder(x['Smiles_nostereo']), x['degradation']) for x in test.to_dict(orient='records')]\n",
    "df = pd.DataFrame(entries, columns=['text', 'labels'])\n",
    "test_dataset = Dataset.from_pandas(df, preserve_index=False)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset,\n",
    "})\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now import the tokenizer and tokenize the SELFIES strings in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ncfrey/ChemGPT-4.7M')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(entries):\n",
    "    return tokenizer(entries['text'], padding='max_length', truncation=True, max_length=256, return_tensors='pt')\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can download the pretrained ChemGPT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# model = AutoModelForCausalLM.from_pretrained('ncfrey/ChemGPT-4.7M', num_labels=1) # Original\n",
    "model = AutoModelForSequenceClassification.from_pretrained('ncfrey/ChemGPT-4.7M', num_labels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze all un-initialized layers in order to avoid \"catastrophic forgetting\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uninit_layers =[\n",
    "    'score.weight',\n",
    "    'transformer.h.1.attn.attention.bias',\n",
    "    'transformer.h.3.attn.attention.bias',\n",
    "    'transformer.h.5.attn.attention.bias',\n",
    "    'transformer.h.7.attn.attention.bias',\n",
    "    'transformer.h.9.attn.attention.bias',\n",
    "    'transformer.h.11.attn.attention.bias',\n",
    "    'transformer.h.13.attn.attention.bias',\n",
    "    'transformer.h.15.attn.attention.bias',\n",
    "    'transformer.h.17.attn.attention.bias',\n",
    "    'transformer.h.19.attn.attention.bias',\n",
    "    'transformer.h.21.attn.attention.bias',\n",
    "    'transformer.h.23.attn.attention.bias',\n",
    "]\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if name in uninit_layers:\n",
    "        param.requires_grad = True\n",
    "        print(name, param.requires_grad)\n",
    "    else:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {'rmse': rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%wandb\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # label_names='degradation,\n",
    "    report_to='wandb',\n",
    "    output_dir='test_trainer',\n",
    "    logging_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=15,\n",
    "    save_total_limit=2,\n",
    "    save_strategy='no')\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(tokenized_datasets['test'])\n",
    "g = plt.plot(predictions.predictions, label='predictions')\n",
    "g = plt.plot(predictions.label_ids, label='label_ids')\n",
    "g = plt.legend()\n",
    "g = plt.grid(alpha=0.8)\n",
    "g = plt.xlabel('Test ID')\n",
    "g = plt.ylabel('Degradation (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained('ncfrey/ChemGPT-4.7M', num_labels=1) # Original\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this [post](https://github.com/huggingface/transformers/issues/7540):\n",
    "\n",
    "> BERT (the base model without any heads on top) outputs 2 things: `last_hidden_state` and `pooler_output`.\n",
    "> \n",
    "> * `last_hidden_state` contains the hidden representations for each token in each sequence of the batch. So the size is `(batch_size, seq_len, hidden_size)`.\n",
    "> * `pooler_output` contains a \"representation\" of each sequence in the batch, and is of size `(batch_size, hidden_size)`. What it basically does is take the hidden representation of the [CLS] token of each sequence in the batch (which is a vector of size `hidden_size`), and then run that through the [BertPooler](https://github.com/huggingface/transformers/blob/de4d7b004a24e4bb087eb46d742ea7939bc74644/src/transformers/modeling_bert.py#L498) nn.Module. This consists of a linear layer followed by a Tanh activation function. The weights of this linear layer are already pretrained on the next sentence prediction task (note that BERT is pretrained on 2 tasks: masked language modeling and next sentence prediction). I assume that the authors of the Transformers library have taken the weights from the original TF implementation, and initialized the layer with them. In theory, they would come from [BertForPretraining](https://github.com/huggingface/transformers/blob/de4d7b004a24e4bb087eb46d742ea7939bc74644/src/transformers/modeling_bert.py#L862) - which is BERT with the 2 pretraining heads on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import selfies as sf\n",
    "\n",
    "smi = protac_db_df.iloc[42]['Smiles_nostereo']\n",
    "sf = sf.encoder(smi)\n",
    "print(f'smi: {smi}')\n",
    "print(f'sf: {sf}')\n",
    "\n",
    "inputs = tokenizer(sf, return_tensors='pt')\n",
    "outputs_transformer = model.transformer(**inputs, output_hidden_states=True)\n",
    "outputs = model(**inputs, output_hidden_states=True)\n",
    "print(f'Model Transformer output keys: {outputs_transformer.keys()}')\n",
    "print(f'Model Tranformer+Head output keys: {outputs.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['logits'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['hidden_states'] # A tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding POI Sequence (TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding POI Sequence via Protein Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this [implementation](https://huggingface.co/Rostlab/prot_bert). There are more models available at this [repository](https://github.com/agemagician/ProtTrans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_rare_amino_acids = lambda seq: re.sub(r'[UZOB]', 'X', seq)\n",
    "poi_seq = input_df['poi_seq'].apply(rem_rare_amino_acids)\n",
    "print('POIs:', poi_seq.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 128\n",
    "tmp = [' [SEP] '.join([seq[i:i+n] for i in range(0, len(seq), n)]) for seq in poi_seq]\n",
    "tmp[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False) #.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\").to(device)\n",
    "\n",
    "# only GPUs support half-precision currently; if you want to run on CPU use full-precision (not recommended, much slower)\n",
    "model = model.full() if device == 'cpu' else model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare your protein sequences as a list\n",
    "sequence_examples = ['PRTEINO', 'SEQWENCE [SEP] SEQWENCE']\n",
    "\n",
    "# replace all rare/ambiguous amino acids by X and introduce white-space between all amino acids\n",
    "sequence_examples = [' '.join(list(re.sub(r'[UZOB]', 'X', sequence))) for sequence in sequence_examples]\n",
    "\n",
    "# tokenize sequences and pad up to the longest sequence in the batch\n",
    "ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding='longest')\n",
    "\n",
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate embeddings\n",
    "with torch.no_grad():\n",
    "    embedding_rpr = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# extract residue embeddings for the first ([0,:]) sequence in the batch and remove padded & special tokens ([0,:7]) \n",
    "emb_0 = embedding_repr.last_hidden_state[0, :7] # shape (7 x 1024)\n",
    "# same for the second ([1,:]) sequence but taking into account different sequence lengths ([1,:8])\n",
    "emb_1 = embedding_repr.last_hidden_state[1, :8] # shape (8 x 1024)\n",
    "\n",
    "# if you want to derive a single representation (per-protein embedding) for the whole protein\n",
    "emb_0_per_protein = emb_0.mean(dim=0) # shape (1024)\n",
    "\n",
    "print(emb_0)\n",
    "print(emb_1)\n",
    "print(emb_0_per_protein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding POI Sequence via ProtBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this [implementation](https://huggingface.co/Rostlab/prot_bert). There are more models available at this [repository](https://github.com/agemagician/ProtTrans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import re\n",
    "\n",
    "poi_tokenizer = BertTokenizer.from_pretrained('Rostlab/prot_bert', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get BERT [output](https://huggingface.co/docs/transformers/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_Example = 'AETCZAO'\n",
    "sequence_Example = re.sub(r'[UZOB]', 'X', sequence_Example)\n",
    "poi_tokenizer(sequence_Example, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_rare_amino_acids = lambda seq: re.sub(r'[UZOB]', 'X', seq)\n",
    "poi_seq = input_df['poi_seq'].apply(rem_rare_amino_acids)\n",
    "print('POIs:', poi_seq.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: The sequence max sequence length is at the moment requiring too much RAM to handle it. I truncate it as a temporary workaround.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def nearest_pow2(x):\n",
    "    return 1 << (x - 1).bit_length()\n",
    "\n",
    "longest_seq = max([len(seq) for seq in poi_seq])\n",
    "seq_max_len = nearest_pow2(longest_seq)\n",
    "# seq_max_len = 128\n",
    "poi_tokenizer.max_length = seq_max_len\n",
    "seq_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BINARY_CLASSIFICATION = False\n",
    "\n",
    "del_aminoacids = lambda seq: re.sub(r'[UZOB]', 'X', ' '.join(seq))\n",
    "train_upsampled_with_poi = train_upsampled.copy()\n",
    "train_upsampled_with_poi['poi_seq'] = train_upsampled_with_poi['poi_seq'].apply(del_aminoacids)\n",
    "test_with_poi = test.copy()\n",
    "test_with_poi['poi_seq'] = test_with_poi['poi_seq'].apply(del_aminoacids)\n",
    "\n",
    "train_dataset = ProtacDataset(train_upsampled_with_poi,\n",
    "                              poi_tokenizer=poi_tokenizer,\n",
    "                              binary_classification=BINARY_CLASSIFICATION)\n",
    "test_dataset = ProtacDataset(test,\n",
    "                             poi_tokenizer=poi_tokenizer,\n",
    "                             binary_classification=BINARY_CLASSIFICATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POIEncoder(pl.LightningModule):\n",
    "\n",
    "    def __init__(self,\n",
    "                 hidden_size:int=64,\n",
    "                 n_layers:int=3,\n",
    "                 batch_size:int=64,\n",
    "                 learning_rate:float=1e-3):\n",
    "        super().__init__()\n",
    "        # Save the arguments passed to init\n",
    "        self.save_hyperparameters()\n",
    "        self.__dict__.update(locals()) # Add arguments as attributes\n",
    "        # Define PyTorch models\n",
    "        hidden_channels = [hidden_size] * n_layers\n",
    "        self.extra_features_encoder = MLP(in_channels=3,\n",
    "                                          hidden_channels=hidden_channels,\n",
    "                                          norm_layer=nn.BatchNorm1d,\n",
    "                                          inplace=False,\n",
    "                                          dropout=0.5)\n",
    "        self.poi_encoder = BertModel.from_pretrained('Rostlab/prot_bert')\n",
    "        self.head = nn.Linear(hidden_size + poi_embedding_size, 1)\n",
    "        # Define loss metrics\n",
    "        self.val_mse = MeanSquaredError()\n",
    "        self.test_mse = MeanSquaredError()\n",
    "\n",
    "    def forward(self, x_in):\n",
    "        # Ecode \"extra\" features\n",
    "        concentrations = x_in['concentrations']\n",
    "        e3_ligase = x_in['e3_ligase']\n",
    "        cell_type = x_in['cell_type']\n",
    "        x = torch.cat((concentrations, e3_ligase, cell_type), dim=-1)\n",
    "        extra_features_embedding = self.extra_features_encoder(x)\n",
    "        # Ecode POI sequence\n",
    "        input_ids = x_in['poi_seq']['input_ids'].squeeze(dim=1)\n",
    "        token_type_ids = x_in['poi_seq']['token_type_ids'].squeeze(dim=1)\n",
    "        attention_mask = x_in['poi_seq']['attention_mask'].squeeze(dim=1)\n",
    "        poi_embedding = self.poi_encoder(input_ids, token_type_ids,\n",
    "                                         attention_mask)['pooler_output']\n",
    "        # Run linear head\n",
    "        x = torch.cat((extra_features_embedding, poi_embedding), dim=-1)\n",
    "        return self.head(x)\n",
    "\n",
    "    def step(self, batch, phase='train'):\n",
    "        y = batch['labels']\n",
    "        preds = self.forward(batch)\n",
    "        loss = F.mse_loss(preds, y)\n",
    "        self.log(f'{phase}_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.step(batch, phase='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.step(batch, phase='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.step(batch, phase='test')\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    ####################\n",
    "    # DATA RELATED HOOKS\n",
    "    ####################\n",
    "\n",
    "    # def prepare_data(self):\n",
    "    #     # download\n",
    "    #     MNIST(self.data_dir, train=True, download=True)\n",
    "    #     MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=custom_collate)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, collate_fn=custom_collate)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, collate_fn=custom_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "model = POIEncoder(hidden_size=32,\n",
    "                   n_layers=3,\n",
    "                   batch_size=4,\n",
    "                   learning_rate=1e-6)\n",
    "\n",
    "callbacks = [\n",
    "    TQDMProgressBar(refresh_rate=20),\n",
    "    EarlyStopping(monitor='val_loss', mode='min'),\n",
    "    ModelCheckpoint(save_weights_only=True, mode='min', monitor='val_loss'),\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5,\n",
    "                     gradient_clip_val=0.5,\n",
    "                     gradient_clip_algorithm='norm',\n",
    "                     accelerator='auto',\n",
    "                     devices=1 if torch.cuda.is_available() else None,\n",
    "                     log_every_n_steps=8,\n",
    "                     callbacks=callbacks,\n",
    "                     logger=CSVLogger(save_dir='logs/'))\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(ckpt_path='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
    "del metrics['step']\n",
    "metrics.set_index('epoch', inplace=True)\n",
    "display(metrics.dropna(axis=1, how='all').head())\n",
    "g = sns.relplot(data=metrics, kind='line')\n",
    "g = plt.grid(alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "y = []\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    _ = model.eval()\n",
    "    for batch in model.test_dataloader():\n",
    "        predictions.extend(model(batch).detach().tolist())\n",
    "        y.extend(batch['labels'].detach().tolist())\n",
    "predictions = np.array(predictions).flatten()\n",
    "y = np.array(y).flatten()\n",
    "sorted_idx = np.argsort(y)\n",
    "# Plot predicitons (sorted)\n",
    "g = plt.plot(predictions[sorted_idx], label='Predicted degradation (%)')\n",
    "g = plt.plot(y[sorted_idx], label='Reference degradation (%)')\n",
    "g = plt.legend()\n",
    "g = plt.grid(alpha=0.8)\n",
    "g = plt.xlabel('Test ID (sorted by degradation perc.)')\n",
    "g = plt.ylabel('Degradation (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "> LightGBM can use categorical features as input directly. It doesnâ€™t need to convert to one-hot encoding, and is much faster than one-hot encoding (about 8x speed-up).\n",
    ">\n",
    "> Note: You should convert your categorical features to int type before you construct Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "src_dir = os.path.join('/content/drive/', 'MyDrive', 'Colab Notebooks', 'thesis', 'src')\n",
    "sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from binary_label_metrics import BinaryLabelMetrics\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN) #INFO, WARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = {\n",
    "  # Number of Optuna trials\n",
    "  'NTRIALS': 20,\n",
    "  # Number of boosted trees to be created\n",
    "  'NBOOST': 50,\n",
    "  # Number of classes in response variable\n",
    "  'NCLASS': 2,\n",
    "  # Morgan fingerpring bit length\n",
    "  'FP_BITS': 1024,\n",
    "}\n",
    "\n",
    "offs = max(map(len, prm.keys()))\n",
    "print('Parameters:')\n",
    "for k, v in prm.items():\n",
    "    print(f'\\t{k:>{offs}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBMObjective(object):\n",
    "    def __init__(self, X_train, y_train):\n",
    "        self.best_booster = None\n",
    "        self._booster = None\n",
    "        self.X = X_train\n",
    "        self.y = y_train\n",
    "        self.dtrain = lgb.Dataset(self.X, self.y)\n",
    "        self.nclass = 2\n",
    "        self.prm_lgb = {      \n",
    "              'objective': 'multiclass' if self.nclass > 2 else 'binary',\n",
    "              'metric': None, \n",
    "              'verbosity': -1,\n",
    "              'boosting_type': 'gbdt',\n",
    "              'force_row_wise': True,\n",
    "              'min_gain_to_split': .5,\n",
    "        }\n",
    "  \n",
    "    def __call__(self, trial):    \n",
    "        if self.nclass > 2:\n",
    "            def f1_eval(preds, dataset):\n",
    "                y = preds.reshape(-1, self.nclass).argmax(axis=1)\n",
    "                f_score = f1_score(dataset.get_label(), y, average='micro')\n",
    "                return 'f1_score', f_score, True\n",
    "        else:\n",
    "            def f1_eval(preds, dataset):\n",
    "                pred1 = np.zeros(dataset.get_label().shape[0], dtype=int)\n",
    "                pred1[-dataset.get_label().sum().astype(int):] = 1\n",
    "                f_score = f1_score(dataset.get_label()[preds.argsort()], pred1,\n",
    "                                   average='micro')\n",
    "                return 'f1_score', f_score, True\n",
    "\n",
    "        trial_prm = {\n",
    "            'learning_rate': trial.suggest_float('learning_rate', .01, .3, log=True),\n",
    "            'lambda_l1': trial.suggest_float('lambda_l1', 1E-3, 1., log=True),\n",
    "            'lambda_l2': trial.suggest_float('lambda_l2', .5, 3., log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 8, 32),\n",
    "            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 50, 100),\n",
    "            'feature_fraction': trial.suggest_float('feature_fraction', .3, .6),\n",
    "            'bagging_fraction': trial.suggest_float('bagging_fraction', .4, 1.),\n",
    "            'bagging_freq': trial.suggest_int('bagging_freq', 2, 6),\n",
    "            'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'rf'])\n",
    "        }\n",
    "        prm_lgb = dict(self.prm_lgb)\n",
    "        prm_lgb.update(trial_prm)\n",
    "        eval_hist = lgb.cv(prm_lgb, self.dtrain, nfold=5, seed=12345,\n",
    "                           num_boost_round=prm['NBOOST'], feval=f1_eval,\n",
    "                           callbacks=[lgb.early_stopping(20, verbose=False)])\n",
    "        return eval_hist['f1_score-mean'][-1]\n",
    "\n",
    "    def callback(self, study, trial):\n",
    "        if study.best_trial == trial:\n",
    "            print(f'{study.best_trial.number} ({study.best_trial.values[0]:.3f}) -> ', end=' ', flush=True)\n",
    "            self.best_booster = self._booster\n",
    "            return\n",
    "        if trial.number % 20 == 0:\n",
    "            print(f'{trial.number}', end=' ', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only consider the features that the model can process, _e.g._, get rid of the SMILES, which are strings. Also, remove the degradation percentage, since we are trying to predict the \"binarized\" version of it.\n",
    "\n",
    "TODO: From investigating the feature importance, we see that the _concentration_ is actually the most important one. Because of that, it is removed in the following experiments.\n",
    "\n",
    "TODO: If we remove the _concentration_, however, we might have many different entries with the _same data_ in the remaining columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_features = [\n",
    "    'degradation', # NOTE: Must be removed, it's the \"regression version\" of y\n",
    "    # 'concentration',\n",
    "    'Smiles',\n",
    "    'Smiles_nostereo',\n",
    "    'poi_seq',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate Optuna objective and start optimization, _i.e._, training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_upsampled.drop(removed_features, axis=1)\n",
    "objective = LightGBMObjective(X, y_train_upsampled)\n",
    "print(f\"Number of trials: {prm['NTRIALS']}\")\n",
    "print(f\"Trial ID (F1 score): \", end='')\n",
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), \n",
    "                            sampler=optuna.samplers.TPESampler(seed=1234),\n",
    "                            direction='maximize')\n",
    "study.optimize(objective, n_trials=prm['NTRIALS'], callbacks=[objective.callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = ('params', 'user_attrs', 'value', 'duration')\n",
    "trials_df = study.trials_dataframe(attrs=attributes)\n",
    "for y in ['params', 'user_attrs']:\n",
    "    trials_df.columns = [x[1 + len(y):] if x.startswith(y) else x for x in trials_df.columns]\n",
    "trials_df['duration'] = trials_df['duration'].apply(lambda x: x.total_seconds())\n",
    "\n",
    "with pd.option_context('display.max_rows', 6, 'display.float_format', '{:.4f}'.format):\n",
    "    display_html(trials_df.sort_values('value', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training time: {trials_df['duration'].sum() / 60:.1f}min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df.groupby('boosting_type').agg(meanv=('value', 'mean'), sdv=('value', 'std'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify best model and re-train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.argmax(trials_df['value'].values)\n",
    "lgb_prm = study.trials[best_idx].params\n",
    "lgb_prm.update({\n",
    "    'objective': 'multiclass',\n",
    "    'metric': None,\n",
    "    'num_class': 2,\n",
    "    'force_row_wise': True, \n",
    "    'verbosity': -1,\n",
    "    'min_gain_to_split': .5,\n",
    "})\n",
    "\n",
    "def f1_eval(preds, dtrain):\n",
    "    preds = preds.reshape(prm['NCLASS'], -1).T.argmax(axis=1)\n",
    "    f_score = f1_score(dtrain.get_label(), preds, average='micro')\n",
    "    return 'f1_score', f_score, True\n",
    "\n",
    "# Get dataset\n",
    "# Balance classes via class weighting (unnecessacy, we are already upsampling)\n",
    "# wt = class_weight.compute_sample_weight(class_weight='balanced', y=y)\n",
    "# dtrain = lgb.Dataset(X, y, weight=wt)\n",
    "X = X_train_upsampled.drop(removed_features, axis=1)\n",
    "dtrain = lgb.Dataset(X, y_train_upsampled)\n",
    "model = lgb.train(lgb_prm, dtrain, feval=f1_eval, num_boost_round=prm['NBOOST'])\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test.drop(removed_features, axis=1)\n",
    "y_hat = np.array([val[1] for val in model.predict(X)])\n",
    "scores_df = pd.DataFrame({'label': list(y_test), 'score': list(y_hat)})\n",
    "\n",
    "blm = BinaryLabelMetrics()\n",
    "blm.add_model('binary_gbm', scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm.plot_roc(params={'legloc': 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# blm.plot(chart_types=[2, 5], params={'legloc': 2, 'chart_thresh': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test.drop(removed_features, axis=1)\n",
    "y_pred = np.array([0 if f1 >= 50 else 1 for _, f1 in model.predict(X)])\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat,\n",
    "                              display_labels=['inactive', 'active'])\n",
    "g = disp.plot(cmap=plt.cm.Blues)\n",
    "g = plt.title(f'Confusion Matrix')\n",
    "# plt.savefig(os.path.join(fig_dir, f'conf_mat_{model_type}.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Plot feature importance](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.plot_importance.html#lightgbm.plot_importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lgb.plot_importance(model, max_num_features=20, figsize=(9, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train.columns:\n",
    "    if 'dss' in c:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics on Hold-Out Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array([val[1] for val in model.predict(X_test)])\n",
    "print(y_hat.shape, y_test.shape)\n",
    "scores_df = pd.DataFrame({'label': list(y_test), 'score': list(y_hat)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm = BinaryLabelMetrics()\n",
    "blm.add_model('binary_gbm', scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blm.plot_roc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "l = blm._f1[0]\n",
    "l = [x for x in l if math.isnan(x) == False]\n",
    "original = ['original', blm._auc, blm._prrec, max(l)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(var, df):\n",
    "    if var == 'cellType':\n",
    "        cols = test.columns.tolist()\n",
    "        ct_cols = [c for c in cols if 'ct' in c]\n",
    "        new_df = df.copy(deep=True)\n",
    "        for col in ct_cols:\n",
    "            new_df[col] = new_df[col].sample(frac=1).values\n",
    "        return new_df\n",
    "    elif var == 'e3':\n",
    "        cols = test.columns.tolist()\n",
    "        ct_cols = [c for c in cols if 'e3' in c]\n",
    "        new_df = df.copy(deep=True)\n",
    "        for col in ct_cols:\n",
    "            new_df[col] = new_df[col].sample(frac=1).values\n",
    "        return new_df\n",
    "    elif var == 'ligand':\n",
    "        cols = test.columns.tolist()\n",
    "        ct_cols = [c for c in cols if 'sm' in c]\n",
    "        new_df = df.copy(deep=True)\n",
    "        for col in ct_cols:\n",
    "            new_df[col] = new_df[col].sample(frac=1).values\n",
    "        return new_df\n",
    "    elif var == 'receptor':\n",
    "        cols = test.columns.tolist()\n",
    "        ct_cols = [c for c in cols if (len(c) == 2 or len(c) == 3) and 'sm' not in c]\n",
    "        new_df = df.copy(deep=True)\n",
    "        for col in ct_cols:\n",
    "            new_df[col] = new_df[col].sample(frac=1).values\n",
    "        return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "metrics = [['shuffled_var', 'auc', 'pr_rec', 'f1']]\n",
    "for var in ['cellType', 'e3', 'ligand', 'receptor']:\n",
    "    new_df = shuffle(var, test)\n",
    "    X_test = new_df.drop(['resp_categorical', 'resp', 'Smiles'], axis=1).values\n",
    "    y_hat = np.array([val[1] for val in model.predict(X_test)])\n",
    "    print(y_hat.shape, y_test.shape, y_hat)\n",
    "    scores_df = pd.DataFrame({'label': list(y_test), 'score': list(y_hat)})\n",
    "    blm = BinaryLabelMetrics()\n",
    "    blm.add_model('binary_gbm', scores_df)\n",
    "    lst = blm._f1[0]\n",
    "    newlist = [x for x in lst if math.isnan(x) == False]\n",
    "    metrics.append([var, blm._auc, blm._prrec, max(newlist)])\n",
    "metrics.append(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POI Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
