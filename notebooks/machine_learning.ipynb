{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RETRAIN_XGBOOST = False\n",
        "RETRAIN_FP_MODEL = False\n",
        "RETRAIN_GNN_MODEL = False\n",
        "RETRAIN_SSL_MODEL = False\n",
        "RETRAIN_BERT_MODEL = False"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e3o4xs9ytAHd"
      },
      "source": [
        "# Machine Learning for Predicting Targeted Protein Degradation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LIF410J1UQI3"
      },
      "source": [
        "## Notes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "q-dBIrPnAIPs"
      },
      "source": [
        "### Machine Learning Model\n",
        "\n",
        "The model will try to predict whether a given PROTAC is active or not, effectively making it a binary classification task."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Biochemistry Notes\n",
        "\n",
        "Some notes about the biochemistry behind the PROTACs (it might contain some errors/silly statements, as I'm not a biochemist):\n",
        "\n",
        "* A gene is a portion the DNA in the chomosome\n",
        "* A gene starts and ends with a specific sequence\n",
        "* A gene is \"copied\" to an mRNA, the mRNA (or something else?) then converts it to the protein\n",
        "* 3 gene bases encode one aminoacid in the protein. An aminoacid can be encoded by several triplets (side note: the more triplets encode the same aminoacid, the less likely is that, in case of mutations, a different aminoacid is encoded)\n",
        "* Genes can be slightly different in different organisms, that's why we have different uniprot ID, despite the gene reported in the entry is the same\n",
        "* The cell type _might_ refer to the different cell type used for conducting the experiments. In fact, different cells might be difficult to handle/grow in lab. Also,  despite different cell types might use/have internally the same protein, the protein can be slightly different in different cells. Finally, the cell itself can influence the PROTAC response and in turn result in different DC50 values\n",
        "* Intuitively, $IC_{50}$ in general measures how well two molecules bind togheter. That's why it is reported for different pairs, like E3-e3_ligase, Warhead-POI, et cetera."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Technical Stuff\n",
        "\n",
        "* Is Optuna really popular to be used in larger projects?\n",
        "    * Yes, AZ even has its in-house development of Optuna (Eva can point me to the persons working on it to discuss things)\n",
        "* Is there a framework for automatically conducting ablation studies?\n",
        "* Shall I share information/work via jupyter/colab/github?\n",
        "* Almost everything is stored in categorical fashion, maybe Pytorch won't like it for technical reasons..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "taXns479ASSk"
      },
      "source": [
        "### TODOs on Technical Stuff\n",
        "\n",
        "* Is there a framework for automatically conducting ablation studies?\n",
        "* Shall I share information/work via jupyter/colab/github?\n",
        "    * Yes, I'm working on public data, so it's fine (but do it at the end of the project)\n",
        "* ~~Better organize the checkpoints, the evaluation results and the plots. Maybe a common CSV file?~~\n",
        "* ~~Add single mapping argument for wrapper model inside `train_model`~~\n",
        "* ~~Add `get_smiles_embedding_size` method to the sub-models, instead of a wrapper-model argument~~\n",
        "* ~~Is Optuna really popular to be used in larger projects?~~\n",
        "    * Yes, AZ even has its in-house development of Optuna (Eva can point me to the persons working on it to discuss things)\n",
        "* ~~Implement a Optuna callback for deleting all but the best model checkpoints~~"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "16SrOKXRAMSc"
      },
      "source": [
        "### TODOs\n",
        "\n",
        "* What loss function shall we use? The Huber loss seems to be a good candidate, but how do we set its $\\delta$ parameter? How many \"outliers\" are there?\n",
        "* The final model shall include some representation of the SMILES (either fingerprints or BERT-based or GNN-based), together with other features like E3 ligase, cell type, et cetera\n",
        "\n",
        "* When encoding SMILES to graphs, what about using the binding affinity as node features?\n",
        "* Encoding/pass to the model the **binding pockets**, _i.e._, amino acids binding to the PROTAC\n",
        "* Encode/pass to the model the gene ID\n",
        "    * The POI sequence itself is not \"useful\": if we were to extract the embeddings from AlphaFold, which is _trained_ to generate the 3D structure, then we might gain something from the POI sequence. Also, it would be useful to leverage information from the 3D structure of the _complex_, which we currently don't have \n",
        "    * How do we represent the POI amino acid sequence anyway?\n",
        "        * Count vectorizer?\n",
        "        * Specific tokenizer?\n",
        "        * MSA?\n",
        "        * Custom Enbedding?\n",
        "        * AlphaFold?\n",
        "* Web scraping degradation percentages from the Western Blot figures, which are only available online\n",
        "* Instead of predicting a value, what about returning the function parameters of the $DC_{50}$ response?\n",
        "    * Interesting idea, but we don't have that much information from the dataset unfortunately\n",
        "        * We might have it actually, but only for a restricted number of entries...\n",
        "* AZ we have some PROTAC patents which might have some extra data we can use \n",
        "* ~~Include mutations for different genes for the same Uniprot ID~~\n",
        "* ~~Reproduce Roc√≠o's student model~~\n",
        "* ~~Explore additional fingerprints~~:\n",
        "    * ~~Morgan (already included)~~\n",
        "    * ~~MACCS~~\n",
        "    * ~~Path-based (at different lenghts to eventually capture how things are connected to each other and the long linker atoms)~~\n",
        "* ~~Predict the concentration value (**in log base 10!**)~~\n",
        "* ~~Check why number of Uniprot ID is different from number of gene entries~~\n",
        "    * I need to update the entries to include some _mutations_: they are not captured by the Uniprot ID, but should be easy to include\n",
        "* ~~Normalize the concentration:~~\n",
        "    1. ~~Convert nM to M~~\n",
        "    2. ~~Take the negative logarithm~~\n",
        "* ~~The cell type might be case insensitive, double check it with Eva~~\n",
        "    * It is case sensitive\n",
        "* ~~Check if DS biased towards a certain E3~~\n",
        "    * Yes, it is\n",
        "* ~~Double check if the current DB is the \"full one\"~~\n",
        "    * Yes, it is\n",
        "* ~~Get finer details like canonical SMILES representation. (RDKit can get the canonal one)~~"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Future Work Ideas\n",
        "\n",
        "* Data augmentations:\n",
        "    * Apply upsampling w.r.t. features like E3 ligase, cell type, et cetera\n",
        "    * Scrumble the SMILES\n",
        "* SSL:\n",
        "    * Contrastive learning \n",
        "    * Apply active learning and [semi-supervised learning](https://lilianweng.github.io/posts/2021-12-05-semi-supervised/) techniques\n",
        "* Explainability:\n",
        "    * Detailed analysis of feature importance from the XGBoost model and SSL Transformer models\n",
        "    * Chamical space analysis of PROTAC-DB vs. PROTAC-pedia (UMAP, PCA, t-SNE, et cetera, of fingerprints and SMILES (show the variance in the plots!))\n",
        "    * Plotting on the $D_{max}$ vs. $pDC_{50}$ graph the predictions of the model. I suspect and hope that the model will struggle to predict point on the border between active and inactive PROTACs. (Add two dotted lines to the plot to show the activity thresholds)\n",
        "* Model-related ideas:\n",
        "    * Try residual connections\n",
        "    * Trying even more types of fingerprints, like [CDDD](https://github.com/jrwnter/cddd)\n",
        "    * Combining/adding multiple fingerprints, like Morgan and path-based\n",
        "    * Advanced embeddings for other features, like the POI sequence\n",
        "        * How to deal with the different cell types?\n",
        "            * One-hot encoding?\n",
        "            * Embedding?\n",
        "            * Other?\n",
        "* Ensemble Methods: Ensemble methods involve training multiple models independently and then combining their predictions to make final decisions. Techniques such as bagging, boosting, and stacking are commonly used to aggregate the predictions of multiple models.\n",
        "* Using PROTAC-pedia entries to train on their definition of active/inactive and then finetune on PROTAC-DB and a more stringent definition of active/inactive\n",
        "* Predict the regression task"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6jXxZ4uuUyVj"
      },
      "source": [
        "activity cliffiness (prediction)?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IpxP8zNsUQI5"
      },
      "source": [
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8QHseegZqkB"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.WARN) #INFO, WARN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRY808Nlw2wL"
      },
      "outputs": [],
      "source": [
        "# import ray\n",
        "# from ray import air, tune\n",
        "# from ray.air import session\n",
        "# from ray.tune import CLIReporter\n",
        "# from ray.tune.schedulers import (ASHAScheduler,\n",
        "#                                  PopulationBasedTraining,\n",
        "#                                  HyperBandScheduler)\n",
        "# from ray.tune.integration.pytorch_lightning import (TuneReportCallback,\n",
        "#                                                     TuneReportCheckpointCallback)\n",
        "\n",
        "# from ray.tune.search import ConcurrencyLimiter\n",
        "# from ray.tune.search.optuna import OptunaSearch\n",
        "# from ray.air import CheckpointConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPmGVOzXUQI7"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display_html\n",
        "# from IPython.core.interactiveshell import InteractiveShell\n",
        "# InteractiveShell.ast_node_interactivity = 'all'\n",
        "\n",
        "import collections\n",
        "import itertools\n",
        "import re\n",
        "import gc\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import requests as r\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shutil\n",
        "import random\n",
        "import copy\n",
        "import os\n",
        "\n",
        "import typing\n",
        "from typing import Mapping, Literal, Callable, List, ClassVar, Any, Tuple, Type\n",
        "\n",
        "from uuid import uuid4\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs, MACCSkeys, Draw\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from datetime import date\n",
        "from scipy.sparse import csr_matrix, vstack\n",
        "from tqdm import tqdm\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
        "from sklearn import preprocessing\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.utils import resample, class_weight\n",
        "\n",
        "pd.set_option('display.max_columns', 1000, 'display.width', 2000, 'display.max_colwidth', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9HNp4bCcj8f"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
        "\n",
        "# import lightning as pl\n",
        "# from lightning import LightningModule, Trainer, seed_everything\n",
        "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "# from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
        "# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "# from pytorch_lightning.loggers import CSVLogger, TensorBoardLogger\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "from torchvision.ops import MLP\n",
        "\n",
        "import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data\n",
        "from torch_geometric.utils.smiles import from_smiles\n",
        "\n",
        "from torchmetrics import (Accuracy,\n",
        "                          AUROC,\n",
        "                          ROC,\n",
        "                          Precision,\n",
        "                          Recall,\n",
        "                          F1Score,\n",
        "                          MeanAbsoluteError,\n",
        "                          MeanSquaredError)\n",
        "from torchmetrics.functional import (mean_absolute_error,\n",
        "                                     mean_squared_error,\n",
        "                                     mean_squared_log_error,\n",
        "                                     pearson_corrcoef,\n",
        "                                     r2_score)\n",
        "from torchmetrics.functional.classification import (binary_accuracy,\n",
        "                                                    binary_auroc,\n",
        "                                                    binary_precision,\n",
        "                                                    binary_recall,\n",
        "                                                    binary_f1_score)\n",
        "\n",
        "# Sets seeds for numpy, torch and python.random.\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "pl.seed_everything(42, workers=True)\n",
        "# torch.use_deterministic_algorithms(True) # TODO: This is a GPU-related thing.."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reduce logging information:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import warnings\n",
        "import re\n",
        "\n",
        "def set_global_logging_level(level=logging.ERROR, prefices=[\"\"]):\n",
        "    \"\"\"\n",
        "    Override logging levels of different modules based on their name as a prefix.\n",
        "    It needs to be invoked after the modules have been loaded so that their loggers have been initialized.\n",
        "\n",
        "    Args:\n",
        "        - level: desired level. e.g. logging.INFO. Optional. Default is logging.ERROR\n",
        "        - prefices: list of one or more str prefices to match (e.g. [\"transformers\", \"torch\"]). Optional.\n",
        "          Default is `[\"\"]` to match all active loggers.\n",
        "          The match is a case-sensitive `module_name.startswith(prefix)`\n",
        "    \"\"\"\n",
        "    prefix_re = re.compile(fr'^(?:{ \"|\".join(prefices) })')\n",
        "    for name in logging.root.manager.loggerDict:\n",
        "        if re.match(prefix_re, name):\n",
        "            logging.getLogger(name).setLevel(level)\n",
        "\n",
        "# Filter out annoying Pytorch Lightning printouts\n",
        "warnings.filterwarnings('ignore', '.*does not have many workers.*')\n",
        "warnings.filterwarnings('ignore', '.*Checkpoint directory.*')\n",
        "warnings.filterwarnings('ignore', '.*The number of training batches.*')\n",
        "warnings.filterwarnings('ignore', '.*is an instance of.*')\n",
        "logging.getLogger('pytorch_lightning').setLevel(logging.ERROR)\n",
        "logging.getLogger(\"pytorch_lightning.utilities.rank_zero_warn\").setLevel(logging.ERROR)\n",
        "set_global_logging_level(logging.ERROR, ['transformers', 'nlp', 'torch', 'tensorflow', 'tensorboard', 'wandb', 'xgboost'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Setup directories:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3azf4V8j60J"
      },
      "outputs": [],
      "source": [
        "data_dir = os.path.join(os.getcwd(), '..', 'data')\n",
        "src_dir = os.path.join(os.getcwd(), '..', 'src')\n",
        "fig_dir = os.path.join(data_dir, 'figures')\n",
        "checkpoint_dir = os.path.join(os.getcwd(), '..', 'checkpoints')\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "if not os.path.exists(src_dir):\n",
        "    os.makedirs(src_dir)\n",
        "if not os.path.exists(fig_dir):\n",
        "    os.makedirs(fig_dir)\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "\n",
        "\n",
        "# edge_index = torch.tensor([[0, 1, 1, 2],\n",
        "#                            [1, 0, 2, 1]], dtype=torch.long)\n",
        "# x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
        "\n",
        "# data = torch_geometric.data.Data(x=x, edge_index=edge_index)\n",
        "\n",
        "data = from_smiles('CN1C=NC2=C1C(=O)N(C(=O)N2C)C')\n",
        "# g = torch_geometric.utils.to_networkx(data, to_undirected=True)\n",
        "# nx.draw(g)\n",
        "\n",
        "\n",
        "import networkx as nx\n",
        "from matplotlib import pyplot as plt\n",
        "from torch_geometric.nn import to_hetero\n",
        "\n",
        "g = torch_geometric.utils.to_networkx(data)\n",
        "# Networkx seems to create extra nodes from our heterogeneous graph, so I remove them\n",
        "isolated_nodes = [node for node in g.nodes() if g.out_degree(node) == 0]\n",
        "[g.remove_node(i_n) for i_n in isolated_nodes]\n",
        "# Plot the graph\n",
        "nx.draw(g, with_labels=True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.matshow(data.x.numpy())\n",
        "plt.title('Node feature matrix')\n",
        "plt.ylabel('Node index')\n",
        "plt.xlabel('Node features')\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.matshow(data.edge_index.numpy())\n",
        "plt.title('Edge matrix')\n",
        "plt.xlabel('Edge index')\n",
        "plt.ylabel('Edge')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.utils.convert import to_scipy_sparse_matrix, from_scipy_sparse_matrix\n",
        "\n",
        "adj = to_scipy_sparse_matrix(data.edge_index)\n",
        "plt.spy(adj)\n",
        "plt.title('Adjacency matrix')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Datasets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load PROTAC-DB, used for training and validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tez3YLm1FBTU"
      },
      "outputs": [],
      "source": [
        "df_file = os.path.join(data_dir, 'processed', 'protac-db_dc50_dmax.csv')\n",
        "protac_df = pd.read_csv(df_file)\n",
        "protac_db_df = pd.concat([\n",
        "    protac_df['Smiles'],\n",
        "    protac_df['Smiles_nostereo'],\n",
        "    protac_df['DC50'].astype(float),\n",
        "    protac_df['pDC50'].astype(float),\n",
        "    protac_df['Dmax'].astype(float),\n",
        "    protac_df['poi_gene_id'],\n",
        "    protac_df['poi_seq'],\n",
        "    protac_df['cell_type'],\n",
        "    protac_df['e3_ligase'],\n",
        "    # protac_df['treatment_hours'], # NOTE: Not used in this analysis...\n",
        "    protac_df['active'],\n",
        "], axis=1).reset_index(drop=True)\n",
        "print('protac_db_df: {:,} x {:,}'.format(*protac_db_df.shape))\n",
        "\n",
        "dataframes = {}\n",
        "files = [\n",
        "    'protac-db_DC50_Dmax',\n",
        "    'protac-db_ssl',\n",
        "    'protac-db_no_degradation',\n",
        "    'protac-db_interpolated',\n",
        "]\n",
        "relevant_cols = [\n",
        "    'DC50',\n",
        "    'pDC50',\n",
        "    'Dmax',\n",
        "    'poi_gene_id',\n",
        "    'poi_seq',\n",
        "    'cell_type',\n",
        "    'e3_ligase',\n",
        "    'Smiles',\n",
        "    'Smiles_nostereo',\n",
        "    # 'treatment_hours', # NOTE: Not used in our work...\n",
        "    'active',\n",
        "]\n",
        "for f in files:\n",
        "    df_file = os.path.join(data_dir, 'processed', f + '.csv')\n",
        "    print(f'Loading \"{f}\"...')\n",
        "    dataframes[f] = pd.read_csv(df_file, usecols=relevant_cols).reset_index(drop=True)\n",
        "    display(dataframes[f])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load PROTAC-Pedia, used for testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_file = os.path.join(data_dir, 'processed', 'protac-pedia_dc50_dmax.csv')\n",
        "protac_df = pd.read_csv(df_file)\n",
        "protac_pedia_df = pd.concat([\n",
        "    protac_df['DC50'].astype(float),\n",
        "    protac_df['pDC50'].astype(float),\n",
        "    protac_df['Dmax'].astype(float),\n",
        "    protac_df['poi_seq'],\n",
        "    protac_df['cell_type'],\n",
        "    protac_df['active'],\n",
        "    protac_df['Active/Inactive'],\n",
        "], axis=1).reset_index(drop=True)\n",
        "protac_pedia_df['e3_ligase'] = protac_df['E3 Ligase']\n",
        "protac_pedia_df['poi_gene_id'] = 'Unknown'\n",
        "protac_pedia_df['Smiles'] = protac_df['PROTAC SMILES']\n",
        "protac_pedia_df['Smiles_nostereo'] = protac_df['PROTAC SMILES_nostereo']\n",
        "print('protac_pedia_df: {:,} x {:,}'.format(*protac_pedia_df.shape))\n",
        "\n",
        "dataframes['protac-pedia'] = protac_pedia_df\n",
        "dataframes['protac-pedia_DC50_Dmax'] = protac_pedia_df[~protac_pedia_df['active'].isna()]\n",
        "dataframes['protac-pedia_ssl'] = protac_pedia_df[protac_pedia_df['active'].isna()]\n",
        "\n",
        "print('protac-pedia_DC50_Dmax:')\n",
        "display(dataframes['protac-pedia_DC50_Dmax'])\n",
        "print('protac-pedia_ssl:')\n",
        "display(dataframes['protac-pedia_ssl'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assemble Train/Val/Test Sets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train/Test Split (TODO)\n",
        "\n",
        "There are two approaches or strategies we might want to pursue:\n",
        "\n",
        "* Given a PROTAC structure, we want to make the best DC prediction\n",
        "* Given a POI, we want the best PROTAC that targets it\n",
        "\n",
        "In our case, the end goal is to design efficient PROTACs, so we follow the first paradigm.\n",
        "Because of that, we now make sure that the same SMILES/PROTAC structure ends up in a single dataset, either in the training or test set.\n",
        "<!-- Since we want to predict the degradation percentage PROTAC-wise, we split the train-test sets according to the PROTACs' SMILES representations. -->\n",
        "\n",
        "The following is inspired from this [Stackoverflow question](https://stackoverflow.com/questions/54797508/how-to-generate-a-train-test-split-based-on-a-group-id).\n",
        "\n",
        "TODO: Make sure that both PROTAC and POI are \"separate\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TRAIN_SPLIT_PERC = 0.9\n",
        "TEST_SPLIT_PERC = 1.0 - TRAIN_SPLIT_PERC\n",
        "\n",
        "def split_df(df, test_perc=TEST_SPLIT_PERC):\n",
        "    tmp = df\n",
        "    if isinstance(df, list):\n",
        "        tmp = pd.concat(df, axis=0, ignore_index=True)\n",
        "    splitter = GroupShuffleSplit(test_size=test_perc,\n",
        "                                 n_splits=2,\n",
        "                                 random_state=42)\n",
        "    split = splitter.split(tmp, groups=tmp['Smiles_nostereo'])\n",
        "    train_inds, val_inds = next(split)\n",
        "    train_df, val_df = tmp.iloc[train_inds], tmp.iloc[val_inds]\n",
        "    return train_df, val_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assemble the train/val/test sets for binary classification task:\n",
        "\n",
        "NOTE: PROTAC-Pedia is used for testing, so we remove all its entries which are also present in PROTAC-DB. We also do NOT include them in the SSL set either, so they are \"lost forever\", unfortunately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assemble PROTAC-DB and PROTAC-Pedia for binary classification task\n",
        "protac_db = pd.concat([dataframes['protac-db_DC50_Dmax'],\n",
        "                 dataframes['protac-db_no_degradation']],\n",
        "                axis=0, ignore_index=True)\n",
        "protac_pedia = dataframes['protac-pedia']\n",
        "# Split PROTAC-DB into train, val sets\n",
        "# NOTE: We specify 15% split w/out interpolated values, so the final amount will\n",
        "# be lower than 15% of the total dataset\n",
        "train, val = split_df(protac_db, test_perc=0.15)\n",
        "# Get test set from PROTAC-Pedia entries NOT in PROTAC-DB and with active labels\n",
        "test = protac_pedia[~protac_pedia['Smiles_nostereo'].isin(protac_db['Smiles_nostereo'])]\n",
        "test = test[~test['active'].isna()]\n",
        "\n",
        "# Remove interpolated entries which are in validation set\n",
        "interpolated = dataframes['protac-db_interpolated']\n",
        "not_in_val = interpolated[~interpolated['Smiles_nostereo'].isin(val['Smiles_nostereo'])]\n",
        "in_val = interpolated[interpolated['Smiles_nostereo'].isin(val['Smiles_nostereo'])]\n",
        "\n",
        "# Add interpolated entries to training set if not in validation, else to\n",
        "# the validation set\n",
        "print(f'train len before adding interpolated: {len(train)}')\n",
        "train = pd.concat([train, not_in_val], axis=0, ignore_index=True)\n",
        "print(f'train len after adding interpolated: {len(train)}')\n",
        "\n",
        "print(f'val len before adding interpolated: {len(val)}')\n",
        "val = pd.concat([val, in_val], axis=0, ignore_index=True)\n",
        "print(f'val len after adding interpolated: {len(val)}')\n",
        "\n",
        "dataframes['train_bin'] = train\n",
        "dataframes['val_bin'] = val\n",
        "dataframes['test_bin'] = test\n",
        "           \n",
        "print(f'train len: {len(train)} ({len(train) / (len(train) + len(val)) * 100:.1f}%)')\n",
        "print(f'val len: {len(val)} ({len(val) / (len(val) + len(train)) * 100:.1f}%)')\n",
        "print(f'test len: {len(test)}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assemble the train/val/test sets for regression task:\n",
        "\n",
        "NOTE: PROTAC-Pedia is used for testing, so we remove all its entries which are also present in PROTAC-DB. We also do NOT include them in the SSL set either, so they are \"lost forever\", unfortunately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assemble PROTAC-DB and PROTAC-Pedia for regression task\n",
        "protac_db = pd.concat([dataframes['protac-db_DC50_Dmax'],\n",
        "                       dataframes['protac-db_interpolated']\n",
        "                       ], axis=0, ignore_index=True)\n",
        "protac_pedia = dataframes['protac-pedia']\n",
        "# Split PROTAC-DB into train, val sets\n",
        "train, val = split_df(protac_db)\n",
        "# Get test set from PROTAC-Pedia entries NOT in PROTAC-DB and with active labels\n",
        "test = protac_pedia[~protac_pedia['Smiles_nostereo'].isin(protac_db['Smiles_nostereo'])]\n",
        "test = test[~test['active'].isna()]\n",
        "\n",
        "dataframes['train_regr'] = train\n",
        "dataframes['val_regr'] = val\n",
        "dataframes['test_regr'] = test\n",
        "           \n",
        "display(train)\n",
        "display(val)\n",
        "display(test)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assemble dataset for SSL binary classification task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ssl_df = pd.concat([dataframes['protac-db_ssl'],\n",
        "                    dataframes['protac-db_DC50_Dmax'],\n",
        "                    dataframes['protac-db_interpolated'],\n",
        "                    dataframes['protac-db_no_degradation']],\n",
        "                axis=0, ignore_index=True)\n",
        "val_df = dataframes['val_bin']\n",
        "test_df = dataframes['test_bin']\n",
        "# Remove entries in val and test sets from ssl_df\n",
        "print(f'SSL len before removal: {len(ssl_df)}')\n",
        "ssl_df = ssl_df[~ssl_df['Smiles_nostereo'].isin(val_df['Smiles_nostereo'])]\n",
        "ssl_df = ssl_df[~ssl_df['Smiles_nostereo'].isin(test_df['Smiles_nostereo'])]\n",
        "print(f'SSL len after removal: {len(ssl_df)}')\n",
        "# Store and display\n",
        "dataframes['ssl_bin'] = ssl_df\n",
        "display(ssl_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assemble dataset for SSL regression task:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ssl_df = pd.concat([dataframes['protac-db_ssl'],\n",
        "                    dataframes['protac-db_DC50_Dmax'],\n",
        "                    dataframes['protac-db_interpolated'],\n",
        "                    dataframes['protac-db_no_degradation']],\n",
        "                axis=0, ignore_index=True)\n",
        "val_df = dataframes['val_regr']\n",
        "test_df = dataframes['test_regr']\n",
        "# Remove entries in val and test sets from ssl_df\n",
        "ssl_df = ssl_df[~ssl_df['Smiles_nostereo'].isin(val_df['Smiles_nostereo'])]\n",
        "ssl_df = ssl_df[~ssl_df['Smiles_nostereo'].isin(test_df['Smiles_nostereo'])]\n",
        "# Store and display\n",
        "dataframes['ssl_regr'] = ssl_df\n",
        "display(ssl_df)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check for data leakage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_data_leakage(train_df, val_df):\n",
        "    train_smiles = train_df['Smiles_nostereo'].tolist()\n",
        "    drop_indices = []\n",
        "    for index, row in list(val_df.iterrows()):\n",
        "        if row['Smiles_nostereo'] in train_smiles:\n",
        "            drop_indices.append(index)\n",
        "    drop_indices = list(set(drop_indices))\n",
        "    if len(drop_indices) == 0:\n",
        "        print('No data leakage detected.')\n",
        "    else:\n",
        "        print(f'Detected {len(drop_indices)} leaking entries.')\n",
        "\n",
        "checks = [('train', 'val'), ('train', 'test'), ('ssl', 'val'), ('ssl', 'test')]\n",
        "for train, test in checks:\n",
        "    for task in ['_bin', '_regr']:\n",
        "        print(f'Checking leakage between {train + task} and {test + task}...', end=' ')\n",
        "        check_data_leakage(dataframes[train + task], dataframes[test + task])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Removing Class Imbalance\n",
        "\n",
        "If we aim at predicting the percentage degradation, the dataset as it is right now is heavily unbalanced towards 50% degradation. Here, we try to compensate the issue via class weighting and up-/down-sampling.\n",
        "\n",
        "* [Motivations and intuition behind using class weights versus up- or down-sampling](https://datascience.stackexchange.com/questions/44755/why-doesnt-class-weight-resolve-the-imbalanced-classification-problem).\n",
        "* [Getting the class weights](https://datascience.stackexchange.com/questions/13490/how-to-set-class-weights-for-imbalanced-classes-in-keras)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_active_inactive(val_bin_df, train_bin_df, test_bin_df, descr='countplot_active_entries_train_val_test'):\n",
        "    val_bin_df['Dataset'] = 'Validation'\n",
        "    train_bin_df['Dataset'] = 'Train'\n",
        "    test_bin_df['Dataset'] = 'Test'\n",
        "\n",
        "    val_bin_df['active'] = val_bin_df['active'].astype(bool)\n",
        "    train_bin_df['active'] = train_bin_df['active'].astype(bool)\n",
        "    test_bin_df['active'] = test_bin_df['active'].astype(bool)\n",
        "\n",
        "    tmp = pd.concat([train_bin_df, val_bin_df, test_bin_df], axis=0)\n",
        "    tmp['Active/Inactive'] = tmp['active'].apply(lambda x: 'Active' if x else 'Inactive')\n",
        "\n",
        "    top_n = tmp['Active/Inactive'].value_counts().index\n",
        "    ax = sns.countplot(data=tmp, hue='Active/Inactive', x='Dataset', hue_order=['Inactive', 'Active'])\n",
        "\n",
        "    for bars_group in ax.containers:\n",
        "        ax.bar_label(bars_group, padding=1) # fontsize=12\n",
        "\n",
        "    plt.grid(axis='y', alpha=0.7)\n",
        "    plt.title('Active and inactive entries in train/val/test datasets')\n",
        "    f = os.path.join(fig_dir, descr)\n",
        "    plt.savefig(f + '.pdf', bbox_inches='tight')\n",
        "    plt.savefig(f + '.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "val_bin_df = dataframes['val_bin'].copy()\n",
        "train_bin_df = dataframes['train_bin'].copy()\n",
        "test_bin_df = dataframes['test_bin'].copy()\n",
        "plot_active_inactive(val_bin_df, train_bin_df, test_bin_df)\n",
        "del val_bin_df\n",
        "del train_bin_df\n",
        "del test_bin_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Upsampling/Downsampling\n",
        "\n",
        "From this [blogpost](https://towardsdatascience.com/heres-what-i-ve-learnt-about-sklearn-resample-ab735ae1abc4).\n",
        "\n",
        "TODO: While resampling, introducing variations to the data, for example by giving a different SMILES representation (for the same molecule ofc) for each new sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def shuffle_smiles(smiles):\n",
        "    rand_config = {\n",
        "        'isomericSmiles': False, # random.choice([True, False]),\n",
        "        'kekuleSmiles': random.choice([True, False]),\n",
        "        # 'rootedAtAtom': (optional) if non-negative, this forces the SMILES to start at a particular atom. Defaults to -1.\n",
        "        'canonical': random.choice([True, False]),\n",
        "        'allBondsExplicit': random.choice([True, False]),\n",
        "        'allHsExplicit': random.choice([True, False]),\n",
        "    }\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    return Chem.MolToSmiles(mol, **rand_config)\n",
        "\n",
        "def scramble_smiles(smiles, plot_mol=False):\n",
        "    # Convert SMILES string to RDKit molecule object\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    new_mol = copy.deepcopy(mol)\n",
        "    # Round 1: randomize order of double bonds\n",
        "    Chem.Kekulize(new_mol)\n",
        "    # Round 2: shuffle atom indices\n",
        "    atom_indices = list(range(new_mol.GetNumAtoms()))\n",
        "    random.shuffle(atom_indices)\n",
        "    new_mol = Chem.RenumberAtoms(new_mol, atom_indices)\n",
        "    # Round 3: randomize order of double bonds again\n",
        "    Chem.Kekulize(new_mol)\n",
        "    # Generate a new SMILES string from the new molecule object\n",
        "    new_smiles = Chem.MolToSmiles(new_mol, isomericSmiles=False, canonical=False)\n",
        "    # Check if the scrambled molecule is the same as the original one\n",
        "    canon_new_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), canonical=True)\n",
        "    canon_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(new_smiles), canonical=True)\n",
        "    if plot_mol:\n",
        "        print('Original molecule:')\n",
        "        display(mol)\n",
        "        print('Transformed molecule:')\n",
        "        display(new_mol)\n",
        "    if canon_smiles != canon_new_smiles:\n",
        "        print(f'original/scrambled:\\n{smiles}\\n{new_smiles}')\n",
        "        if smiles != new_smiles:\n",
        "            pass\n",
        "            # display(mol)\n",
        "            # display(new_mol)\n",
        "        print('-' * 80)\n",
        "        return smiles\n",
        "    else:\n",
        "        return new_smiles\n",
        "\n",
        "examples = dataframes['train_bin'].at[0, 'Smiles_nostereo']\n",
        "print(f'Original SMILES: {examples}')\n",
        "print(f'Transformed SMILES: {scramble_smiles(examples, plot_mol=True)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = dataframes['train_bin']\n",
        "active_df = train_df[train_df['active'] == True]\n",
        "inactive_df = train_df[train_df['active'] == False]\n",
        "# Set majority and minority classes datasets\n",
        "if len(active_df) > len(inactive_df):\n",
        "    majority_df = active_df\n",
        "    minority_df = inactive_df\n",
        "else:\n",
        "    majority_df = inactive_df\n",
        "    minority_df = active_df\n",
        "# Upsample the minority class\n",
        "n_samples = abs(len(active_df) - len(inactive_df))\n",
        "minority_upsampled_df = resample(minority_df, random_state=42,\n",
        "                                 n_samples=n_samples, replace=True)\n",
        "# Transform SMILES strings of the upsampled class\n",
        "minority_upsampled_df['Smiles_nostereo'] = minority_upsampled_df['Smiles_nostereo'].apply(scramble_smiles)\n",
        "# Concatenate the upsampled dataframe\n",
        "train_upsampled_bin_df = pd.concat([minority_upsampled_df, train_df], axis=0)\n",
        "dataframes['train_upsampled_bin'] = train_upsampled_bin_df\n",
        "\n",
        "val_bin_df = dataframes['val_bin'].copy()\n",
        "test_bin_df = dataframes['test_bin'].copy()\n",
        "plot_active_inactive(val_bin_df, train_upsampled_bin_df, test_bin_df)\n",
        "del val_bin_df\n",
        "del test_bin_df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Legacy code for the remaining section..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assemble train/val/test sets and SSL in deprecating old way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# protac_db_df['poi_gene_id'] = input_df['poi_gene_id']\n",
        "splitter = GroupShuffleSplit(test_size=TEST_SPLIT_PERC, n_splits=2, random_state=42)\n",
        "# Split \"entire\" dataset\n",
        "split = splitter.split(protac_db_df, groups=protac_db_df['Smiles'])\n",
        "train_inds, val_inds = next(split)\n",
        "train_df, val_df = protac_db_df.iloc[train_inds], protac_db_df.iloc[val_inds]\n",
        "# Split datasets for binary classification\n",
        "bin_df = protac_db_df.dropna(subset=['active'])\n",
        "split = splitter.split(bin_df, groups=bin_df['Smiles'])\n",
        "train_inds, val_inds = next(split)\n",
        "train_bin_df, val_bin_df = bin_df.iloc[train_inds], bin_df.iloc[val_inds]\n",
        "# Get test dataset from PROTAC-Pedia entries which are NOT in PROTAC-DB\n",
        "tmp = protac_pedia_df.dropna(subset=['active'])\n",
        "test_df = tmp[~tmp['Smiles_nostereo'].isin(protac_db_df['Smiles_nostereo'])]\n",
        "test_bin_df = test_df\n",
        "# Reporting\n",
        "print(f'Len(PROTAC-Pedia): {len(protac_pedia_df)}')\n",
        "print(f'Len(PROTAC-Pedia) with active/inactive: {len(tmp)}')\n",
        "print(f'Train data len.: {len(train_df)}')\n",
        "print(f'Val data len.: {len(val_df)}')\n",
        "print(f'Test data len.: {len(test_df)}')\n",
        "print(f'Train data len.: {len(train_bin_df)} (binary classification)')\n",
        "print(f'Val data len.: {len(val_bin_df)} (binary classification)')\n",
        "print(f'Test data len.: {len(test_bin_df)} (binary classification)')\n",
        "\n",
        "not_in_val = ~protac_pedia_df['Smiles_nostereo'].isin(val_bin_df['Smiles_nostereo'])\n",
        "not_in_test = ~protac_pedia_df['Smiles_nostereo'].isin(protac_db_df['Smiles_nostereo'])\n",
        "tmp = protac_pedia_df[not_in_val & not_in_test].copy()\n",
        "tmp['active'] = tmp['Active/Inactive']\n",
        "print(f'Len(PROTAC-Pedia) with active/inactive: {len(tmp)}')\n",
        "splitter = GroupShuffleSplit(test_size=0.1, n_splits=2, random_state=42)\n",
        "split = splitter.split(tmp, groups=tmp['Smiles'])\n",
        "train_inds, val_inds = next(split)\n",
        "train_bin_protac_pedia_df = tmp.iloc[train_inds]\n",
        "val_bin_protac_pedia_df = tmp.iloc[val_inds]\n",
        "print(f'Train data len.: {len(train_bin_protac_pedia_df)} (binary classification PROTAC-Pedia)')\n",
        "print(f'Val data len.: {len(val_bin_protac_pedia_df)} (binary classification PROTAC-Pedia)')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Checking for data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'[Before data leaking check] Train data len.: {len(train_df)}')\n",
        "print(f'[Before data leaking check] Val data len.: {len(val_df)}')\n",
        "\n",
        "train_smiles = train_df['Smiles'].tolist()\n",
        "# train_genes = train_df['poi_gene_id'].tolist()\n",
        "drop_indices = []\n",
        "for index, row in list(val_df.iterrows()) + list(test_df.iterrows()):\n",
        "    if row['Smiles'] in train_smiles:\n",
        "        # print(f'Index n.{index} is leaking SMILES')\n",
        "        drop_indices.append(index)\n",
        "    # if row['poi_gene_id'] in train_genes:\n",
        "    #     # print(f'Index n.{index} is leaking genes')\n",
        "    #     drop_indices.append(index)\n",
        "drop_indices = list(set(drop_indices))\n",
        "if len(drop_indices) == 0:\n",
        "    print('No data leakage detected.')\n",
        "else:\n",
        "    print(f'Detected {len(drop_indices)} leaking entries.')\n",
        "    train_df = pd.concat([train_df, val_df.loc[drop_indices]], axis=0)\n",
        "    val_df = val_df.drop(drop_indices)\n",
        "    print(f'[After data leaking check] Train data len.: {len(train_df)}')\n",
        "    print(f'[After data leaking check] Val data len.: {len(val_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'Binary Classification')\n",
        "print(f'[Before data leaking check] Train data len.: {len(train_bin_df)}')\n",
        "print(f'[Before data leaking check] Test data len.: {len(val_bin_df)}')\n",
        "\n",
        "train_smiles = train_bin_df['Smiles'].tolist()\n",
        "# train_genes = train_bin_df['poi_gene_id'].tolist()\n",
        "drop_indices = []\n",
        "for index, row in list(val_df.iterrows()) + list(test_df.iterrows()):\n",
        "    if row['Smiles'] in train_smiles:\n",
        "        # print(f'Index n.{index} is leaking SMILES')\n",
        "        drop_indices.append(index)\n",
        "    # if row['poi_gene_id'] in train_genes:\n",
        "    #     print(f'Index n.{index} is leaking genes')\n",
        "    #     drop_indices.append(index)\n",
        "drop_indices = list(set(drop_indices))\n",
        "if len(drop_indices) == 0:\n",
        "    print('No data leakage detected.')\n",
        "else:\n",
        "    print(f'Detected {len(drop_indices)} leaking entries.')\n",
        "#     train_bin_df = pd.concat([train_bin_df, val_bin_df.loc[drop_indices]], axis=1)\n",
        "#     val_bin_df = val_bin_df.drop(drop_indices)\n",
        "#     print(f'[After data leaking check] Train data len.: {len(train_bin_df)}')\n",
        "#     print(f'[After data leaking check] Test data len.: {len(val_bin_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set other classes to another dataframe\n",
        "active_df = train_bin_df[train_bin_df['active']]\n",
        "# Set the minority class to a seperate dataframe\n",
        "inactive_df = train_bin_df[train_bin_df['active'] == False]\n",
        "# Upsample the minority class\n",
        "n_samples = len(active_df) # - len(inactive_df)\n",
        "inactive_df_upsampled = resample(inactive_df, random_state=42,\n",
        "                                 n_samples=n_samples, replace=True)\n",
        "inactive_df_upsampled['Smiles_nostereo'] = inactive_df_upsampled.apply(lambda row: scramble_smiles(row['Smiles_nostereo']), axis=1)\n",
        "# Concatenate the upsampled dataframe\n",
        "train_upsampled_bin_df = pd.concat([inactive_df_upsampled, active_df])\n",
        "print(f'inactive_df_upsampled len: {len(inactive_df_upsampled)}')\n",
        "print(f'active_df len: {len(active_df)}')\n",
        "print(f'train_upsampled len: {len(train_upsampled_bin_df)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sns.histplot(data=val_bin_df['active'].astype(float))\n",
        "val_bin_df['Dataset'] = 'Validation'\n",
        "train_bin_df['Dataset'] = 'Train'\n",
        "test_bin_df['Dataset'] = 'Test'\n",
        "\n",
        "tmp = pd.concat([train_bin_df, val_bin_df, test_bin_df], axis=0)\n",
        "tmp['Active/Inactive'] = tmp['active'].apply(lambda x: 'Active' if x else 'Inactive')\n",
        "\n",
        "top_n = tmp['Active/Inactive'].value_counts().index\n",
        "ax = sns.countplot(data=tmp, hue='Active/Inactive', x='Dataset')\n",
        "\n",
        "# plt.xticks(rotation=90)\n",
        "for bars_group in ax.containers:\n",
        "    ax.bar_label(bars_group, padding=1) # fontsize=12\n",
        "\n",
        "plt.grid(axis='y', alpha=0.7)\n",
        "plt.title('Active and inactive entries in train/val/test datasets')\n",
        "f = os.path.join(fig_dir, 'countplot_active_entries_train_val_test')\n",
        "plt.savefig(f + '.pdf', bbox_inches='tight')\n",
        "plt.savefig(f + '.png', bbox_inches='tight')\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "del val_bin_df['Dataset']\n",
        "del train_bin_df['Dataset']\n",
        "del test_bin_df['Dataset']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sns.histplot(data=val_bin_df['active'].astype(float))\n",
        "val_bin_protac_pedia_df['Type'] = 'Val'\n",
        "train_bin_protac_pedia_df['Type'] = 'Train'\n",
        "test_bin_df['Type'] = 'Test'\n",
        "\n",
        "tmp = pd.concat([train_bin_protac_pedia_df, val_bin_protac_pedia_df, test_bin_df], axis=0)\n",
        "tmp['active'] = tmp['active'].astype(int).copy()\n",
        "sns.histplot(data=tmp, x='active', hue='Type', multiple='dodge')\n",
        "# plt.xticks(rotation=90)\n",
        "plt.grid(axis='y', alpha=0.9)\n",
        "plt.title('Active entries in datasets')\n",
        "# plt.show()\n",
        "plt.close()\n",
        "\n",
        "del val_bin_protac_pedia_df['Type']\n",
        "del train_bin_protac_pedia_df['Type']\n",
        "del test_bin_df['Type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('-' * 80)\n",
        "print('PROTAC-DB statistics:')\n",
        "print('-' * 80)\n",
        "for x in zip([train_bin_df, val_bin_df, test_bin_df], ['Train', 'Val', 'Test']):\n",
        "    df, name = x\n",
        "    n_active = len(df[df['active'] == True])\n",
        "    n_inactive = len(df[df['active'] == False])\n",
        "    n_active_perc = n_active / len(df) * 100\n",
        "    n_inactive_perc = n_inactive / len(df) * 100\n",
        "    print(f'{name} dataset num. active entries:\\t{n_active:4d} ({n_active_perc:2.1f}%)')\n",
        "    print(f'{name} dataset num. inactive entries:\\t{n_inactive:4d} ({n_inactive_perc:2.1f}%)')\n",
        "print('-' * 80)\n",
        "print('PROTAC-Pedia statistics:')\n",
        "print('-' * 80)\n",
        "for x in zip([train_bin_protac_pedia_df, val_bin_protac_pedia_df], ['Train', 'Val']):\n",
        "    df, name = x\n",
        "    n_active = len(df[df['active'] == True])\n",
        "    n_inactive = len(df[df['active'] == False])\n",
        "    n_active_perc = n_active / len(df) * 100\n",
        "    n_inactive_perc = n_inactive / len(df) * 100\n",
        "    print(f'{name} dataset num. active entries:\\t{n_active:4d} ({n_active_perc:2.1f}%)')\n",
        "    print(f'{name} dataset num. inactive entries:\\t{n_inactive:4d} ({n_inactive_perc:2.1f}%)')\n",
        "print('-' * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.histplot(data=train_bin_df['active'].astype(float))\n",
        "# plt.xticks(rotation=90)\n",
        "plt.grid(axis='y', alpha=0.9)\n",
        "plt.title('Active entries in train dataset (unbalanced)')\n",
        "# plt.savefig(os.path.join(fig_dir, 'active_entries_hist.pdf'), bbox_inches='tight')\n",
        "# plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.histplot(data=train_upsampled_bin_df['active'].astype(float))\n",
        "# plt.xticks(rotation=90)\n",
        "plt.grid(axis='y', alpha=0.9)\n",
        "plt.title('Active entries in train dataset (balanced, i.e., upsampled)')\n",
        "# plt.savefig(os.path.join(fig_dir, 'active_entries_hist.pdf'), bbox_inches='tight')\n",
        "# plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Class Weights (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.utils import class_weight\n",
        "\n",
        "# class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "#                                                   classes=train_df['Dmax'].astype(float).unique(),\n",
        "#                                                   y=train_df['Dmax'].astype(float))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GQw9twJc8-CA"
      },
      "source": [
        "## POI Sequence Encoding"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ctxwOxeshrLA"
      },
      "source": [
        "#### POI Sequence to $N_{grams}$\n",
        "\n",
        "Count-vectorize the POI amino acid sequence.\n",
        "\n",
        "(Not ideal and very simple, but it's a start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "ngram_min_range = 2 # Orginal: 3\n",
        "ngram_max_range = 2 # Orginal: 3\n",
        "poi_vectorizer = CountVectorizer(analyzer='char', ngram_range=(ngram_min_range, ngram_max_range))\n",
        "X = poi_vectorizer.fit_transform(protac_db_df['poi_seq'].tolist())\n",
        "rec_n_grams_df = pd.DataFrame(X.toarray(), columns=list(s.replace(' ', '') for s in poi_vectorizer.get_feature_names_out()))\n",
        "print(f'POI embedding size: {rec_n_grams_df.shape[-1]}')\n",
        "\n",
        "# Load the pre-trained countvectorizer if it exists, otherwise train it\n",
        "poi_encoder_filepath = os.path.join(checkpoint_dir, 'poi_encoder.joblib')\n",
        "if os.path.exists(poi_encoder_filepath):\n",
        "    print('Loading pre-trained POI vectorizer...')\n",
        "    poi_encoder = joblib.load(poi_encoder_filepath)\n",
        "else:\n",
        "    print('Training POI vectorizer...')\n",
        "    poi_encoder = CountVectorizer(analyzer='char', ngram_range=(ngram_min_range, ngram_max_range))\n",
        "    X = poi_encoder.fit_transform(dataframes['ssl_bin']['poi_seq'].tolist())\n",
        "    rec_n_grams_df = pd.DataFrame(X.toarray(), columns=list(s.replace(' ', '') for s in poi_encoder.get_feature_names_out()))\n",
        "    print(f'POI embedding size: {rec_n_grams_df.shape[-1]}')\n",
        "    joblib.dump(poi_encoder, poi_encoder_filepath)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2TBo73YXhuQC"
      },
      "source": [
        "#### POI Gene Ordinal Encoding"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add the \"Unknown\" class to the POI genes.\n",
        "\n",
        "Since genes ultimately encode proteins, we can use the gene ID as a categorical feature to include information about the POIs.\n",
        "\n",
        "(The information loss is considerable, since the gene ID is not that informative compared to the entire amino acid sequence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "poi_gene_enc = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',\n",
        "                                            unknown_value=-1,\n",
        "                                            encoded_missing_value=-1)\n",
        "poi_gene_id = protac_db_df['poi_gene_id'].to_numpy().reshape(-1, 1)\n",
        "poi_gene_enc.fit(poi_gene_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gri7HMyj6lkN"
      },
      "source": [
        "## E3 Ligase and Cell Type Ordinal Encoding\n",
        "\n",
        "Notice that the \"other E3\" have been dropped during the previous steps, leading to only 5 possibilities left."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsuxyHvIpNtg"
      },
      "outputs": [],
      "source": [
        "e3_ligase_enc = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',\n",
        "                                             unknown_value=-1,\n",
        "                                             encoded_missing_value=-1)\n",
        "e3_ligase = protac_db_df['e3_ligase'].to_numpy().reshape(-1, 1)\n",
        "e3_ligase_enc.fit(e3_ligase)\n",
        "\n",
        "# Load the pre-trained ordinal encoder if it exists, otherwise train it\n",
        "e3_encoder_filepath = os.path.join(checkpoint_dir, 'e3_encoder.joblib')\n",
        "if os.path.exists(e3_encoder_filepath):\n",
        "    print('Loading pre-trained POI vectorizer...')\n",
        "    e3_encoder = joblib.load(e3_encoder_filepath)\n",
        "else:\n",
        "    print('Training E3 encoder...')\n",
        "    e3_encoder = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',\n",
        "                                              unknown_value=-1,\n",
        "                                              encoded_missing_value=-1)\n",
        "    e3_ligase = dataframes['ssl_bin']['e3_ligase'].to_numpy().reshape(-1, 1)\n",
        "    e3_encoder.fit(e3_ligase)\n",
        "    joblib.dump(e3_encoder, e3_encoder_filepath)\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd-eaP-thX8J"
      },
      "outputs": [],
      "source": [
        "cell_type_enc = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',\n",
        "                                             unknown_value=-1,\n",
        "                                             encoded_missing_value=-1)\n",
        "cell_type = protac_db_df['cell_type'].to_numpy().reshape(-1, 1)\n",
        "cell_type_enc.fit(cell_type)\n",
        "\n",
        "# Load the pre-trained ordinal encoder if it exists, otherwise train it\n",
        "cell_encoder_filepath = os.path.join(checkpoint_dir, 'cell_encoder.joblib')\n",
        "if os.path.exists(cell_encoder_filepath):\n",
        "    print('Loading pre-trained POI vectorizer...')\n",
        "    cell_encoder = joblib.load(cell_encoder_filepath)\n",
        "else:\n",
        "    print('Training E3 encoder...')\n",
        "    cell_encoder = preprocessing.OrdinalEncoder(handle_unknown='use_encoded_value',\n",
        "                                                unknown_value=-1,\n",
        "                                                encoded_missing_value=-1)\n",
        "    e3_ligase = dataframes['ssl_bin']['cell_type'].to_numpy().reshape(-1, 1)\n",
        "    cell_encoder.fit(e3_ligase)\n",
        "    joblib.dump(cell_encoder, cell_encoder_filepath)\n",
        "print('Done!')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Molecular Fingerprints\n",
        "\n",
        "SMILES $\\rightarrow$ molecule is unique.\n",
        "\n",
        "molecule $\\not\\to$ SMILES is _not_ unique.\n",
        "\n",
        "By construction, a SMILES encodes a unique molecule. However, one molecule can be encoded by multiple SMILES representations.\n",
        "\n",
        "On the other end, Morgan fingerprints are designed to create a one-to-one mapping of molecules, given there are enough bits given to the representation.\n",
        "\n",
        "Fingerprints appear to be very informative and descriptive of the molecules. The Tanimoto similarity score b/w molecular fingerprints can somewhat give a measurements of similarity b/w two molecules.\n",
        "\n",
        "Refer to this [tutorial](https://chem.libretexts.org/Courses/Intercollegiate_Courses/Cheminformatics/06%3A_Molecular_Similarity/6.04%3A_Python_Assignment).\n",
        "\n",
        "[Pytorch, convert to binary tensor](https://stackoverflow.com/questions/55918468/convert-integer-to-pytorch-tensor-of-binary-bits)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_fingerprint(smiles: str, n_bits: int = 1024, fp_type: Literal['morgan', 'maccs', 'path'] = 'morgan',\n",
        "                    min_path: int = 1, max_path: int = 2,\n",
        "                    atomic_radius: int = 2) -> np.ndarray:\n",
        "    \"\"\"Returns molecular fingerprint of a given molecule SMILES.\n",
        "\n",
        "    Args:\n",
        "        smiles (str): SMILES string to convert.\n",
        "        n_bits (int, optional): Number of bits of the generated fingerprint. Defaults to 1024.\n",
        "        fp_type (Literal[&#39;morgan&#39;, &#39;maccs&#39;, &#39;path&#39;], optional): Fingerprint type to generate. Defaults to 'morgan'.\n",
        "        min_path (int, optional): Minimum path lenght for path-based fingerprints. Defaults to 1.\n",
        "        max_path (int, optional): Maximum path lenght for path-based fingerprints. Defaults to 2.\n",
        "        atomic_radius (int, optional): Atomic radius for MORGAN fingerprints. Defaults to 2.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: When wrong fingerprint type is requested.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The generated fingerprint.\n",
        "    \"\"\" \n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if fp_type == 'morgan':\n",
        "        fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, atomic_radius,\n",
        "                                                            nBits=n_bits)\n",
        "    elif fp_type == 'maccs':\n",
        "        fingerprint = MACCSkeys.GenMACCSKeys(mol)\n",
        "    elif fp_type == 'path':\n",
        "        fingerprint = Chem.rdmolops.RDKFingerprint(mol, fpSize=n_bits,\n",
        "                                                   minPath=min_path,\n",
        "                                                   maxPath=max_path)\n",
        "    else:\n",
        "        raise ValueError(f'Wrong type of fingerprint requested. Received \"{fp_type}\", expected one in: [morgan|maccs|path]')\n",
        "    array = np.zeros((0,), dtype=np.int8)\n",
        "    DataStructs.ConvertToNumpyArray(fingerprint, array)\n",
        "    return array\n",
        "\n",
        "fp2str = lambda fp: ''.join([str(x) for x in fp])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compress and Store Fingerprints\n",
        "\n",
        "Code inspired from this [StackOverflow question](https://stackoverflow.com/questions/71621513/how-do-i-compress-a-rather-long-binary-string-in-python-so-that-i-will-be-able-t)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zlib\n",
        "\n",
        "# Numpy array -> Binary string\n",
        "num2str = lambda fp: ''.join([str(x) for x in fp])\n",
        "# Binary string -> Hexadecimal (compressed) string\n",
        "str2hex = lambda fp: zlib.compress(fp.encode()).hex()\n",
        "# Hexadecimal (compressed) string -> Binary string\n",
        "hex2str = lambda fp: zlib.decompress(bytearray.fromhex(fp)).decode()\n",
        "# Binary string -> Numpy array\n",
        "str2num = lambda fp: np.array([x for x in fp], dtype=np.int8)\n",
        "\n",
        "fp = get_fingerprint(protac_db_df.iloc[17]['Smiles'], n_bits=1024, fp_type='maccs')\n",
        "fp_dec = str2num(hex2str(str2hex(num2str(fp))))\n",
        "np.allclose(fp, fp_dec)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Morgan Fingerprints\n",
        "\n",
        "The notebook now adds $n$ columns, each containing the $i$-th bit of Morgan fingerprint, with $i=1,...,n$. In our case we have $n = 1024$.\n",
        "\n",
        "**We obtain the fingerprint from the \"removed stereochemistry\" SMILES, in order to further avoid overlaps.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_bits = 32\n",
        "compress = lambda s: str2hex(num2str(get_fingerprint(s, n_bits=n_bits)))\n",
        "protac_db_df[f'morgan_{n_bits}bits'] = protac_db_df['Smiles_nostereo'].apply(compress)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MACCS Fingerprints\n",
        "\n",
        "Inspired by this [tutorial](https://projects.volkamerlab.org/teachopencadd/talktorials/T004_compound_similarity.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "smiles_example = protac_db_df.iloc[0]['Smiles']\n",
        "\n",
        "MACCS_BITWIDTH = len(fp2str(get_fingerprint(protac_db_df.iloc[31]['Smiles'], n_bits=128, fp_type='maccs')))\n",
        "MACCS_BITWIDTH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_bits = 167\n",
        "compress = lambda s: str2hex(num2str(get_fingerprint(s, n_bits=n_bits, fp_type='maccs')))\n",
        "# input_df[f'maccs_{n_bits}bits'] = input_df['Smiles_nostereo'].apply(compress)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Path-Based Fingerprints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_bits = 32\n",
        "compress = lambda s: str2hex(num2str(get_fingerprint(s, n_bits=n_bits, fp_type='path')))\n",
        "# input_df[f'path_{n_bits}bits'] = input_df['Smiles_nostereo'].apply(compress)\n",
        "# input_df[f'path_{n_bits}bits']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nHFt4MgTSYMY"
      },
      "source": [
        "## PyTorch Dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Litylw6ZSfPA"
      },
      "outputs": [],
      "source": [
        "# TODO: Cast everything to np.float16??? Maybe not, CPUs might not support it...\n",
        "\n",
        "class ProtacDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dataframe,\n",
        "                 task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                 scale_concentration: bool = False,\n",
        "                 scale_degradation: bool = False,\n",
        "                 include_smiles_as_str: bool = False,\n",
        "                 include_smiles_as_graphs: bool = False,\n",
        "                 smiles_tokenizer: Any = None,\n",
        "                 include_poi_seq: bool = True,\n",
        "                 poi_vectorizer: Any = None,\n",
        "                 ngram_range: Tuple[int, int] = (2, 2),      \n",
        "                 tokenize_poi_seq: bool = False,\n",
        "                 poi_tokenizer: Any = None,\n",
        "                 include_poi_gene: bool = False,\n",
        "                 precompute_smiles_as_graphs: bool = False,\n",
        "                 precompute_fingerprints: bool = False,\n",
        "                 precompute_poi_seq: bool = False,\n",
        "                 use_for_ssl: bool = False,\n",
        "                 return_tensors: str | None = None,\n",
        "                 use_morgan_fp: bool = False,\n",
        "                 morgan_bits: int = 1024,\n",
        "                 morgan_atomic_radius: int = 2,\n",
        "                 use_maccs_fp: bool = False,\n",
        "                 use_path_fp: bool = False,\n",
        "                 path_bits: int = 1024,\n",
        "                 fp_min_path: int = 1,\n",
        "                 fp_max_path: int = 16,\n",
        "                 poi_gene_enc: sklearn.preprocessing.OrdinalEncoder | sklearn.preprocessing.OneHotEncoder | None = None,\n",
        "                 e3_ligase_enc: sklearn.preprocessing.OrdinalEncoder | sklearn.preprocessing.OneHotEncoder | None = None,\n",
        "                 cell_type_enc: sklearn.preprocessing.OrdinalEncoder | sklearn.preprocessing.OneHotEncoder | None = None,\n",
        "                 normalize_extra_features: bool = False):\n",
        "        \"\"\"Pytorch Dataset for PROTAC data. Each element will consist of a dictionary of different processed features.\n",
        "        When processed by a DataLoader, the dictionary structure will remain, but each value will be converted to a batch of tensors.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataframe : pandas.DataFrame\n",
        "            Pandas dataframe containing the data.\n",
        "        task : Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'], default='predict_pDC50_and_Dmax'\n",
        "            The task for which to load the dataset.\n",
        "        scale_concentration : bool, default=False\n",
        "            Whether to scale the concentrations to the range [0, 1].\n",
        "        scale_degradation : bool, default=False\n",
        "            Whether to scale the Dmax to the range [0, 1].\n",
        "        include_smiles_as_str : bool, default=False\n",
        "            Whether to include the SMILES as a string.\n",
        "        include_smiles_as_graphs : bool, default=False\n",
        "            Whether to include the SMILES as graphs.\n",
        "        smiles_tokenizer : Any, default=None\n",
        "            The SMILES tokenizer to use. If None, will use a default one.\n",
        "        poi_vectorizer : Any, default=None\n",
        "            The POI vectorizer to use. If None, will use a default one.\n",
        "        poi_tokenizer : Any, default=None\n",
        "            The POI tokenizer to use. If None, will use a default one.\n",
        "        include_poi_seq : bool, default=False\n",
        "            Whether to include the POI sequence.\n",
        "        precompute_smiles_as_graphs : bool, default=False\n",
        "            Whether to precompute the SMILES graphs.\n",
        "        precompute_fingerprints : bool, default=False\n",
        "            Whether to precompute the fingerprints.\n",
        "        use_for_ssl : bool, default=False\n",
        "            Whether to use the dataset for self-supervised learning.\n",
        "        use_morgan_fp : bool, default=False\n",
        "            Whether to use Morgan fingerprints.\n",
        "        morgan_bits : int, default=1024\n",
        "            The number of bits to use for the Morgan fingerprints.\n",
        "        use_maccs_fp : bool, default=False\n",
        "            Whether to use MACCS fingerprints.\n",
        "        use_path_fp : bool, default=False\n",
        "            Whether to use path fingerprints.\n",
        "        \"\"\"\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        self.hparams = {k: v for k, v in locals().items() if k != 'dataframe' and k != 'self'} # Store hyperparameters\n",
        "        self.maccs_bits = 167 # Hardcoded, see RDKit documentation\n",
        "        self.dataset_len = len(self.dataframe)\n",
        "        if task == 'predict_pDC50' or task == 'predict_active_inactive':\n",
        "            if not use_for_ssl:\n",
        "                self.dataframe = dataframe.dropna(subset=['active'])\n",
        "        self.smiles = self.dataframe['Smiles_nostereo']\n",
        "        # if include_selfies:\n",
        "        #     self.selfies = [sf.encoder(s) for s in self.smiles]\n",
        "        \n",
        "        # TODO: The SSL dataframe has the same columns, so there is no point in\n",
        "        # having a separate if-else clause for it. Just use the same code for both.\n",
        "        if not use_for_ssl:\n",
        "            # Get POI gene as integer classes and normalize them\n",
        "            if poi_gene_enc is not None:\n",
        "                self.gene = self.dataframe['poi_gene_id'].to_numpy().reshape(-1, 1)\n",
        "                self.gene = poi_gene_enc.transform(self.gene)\n",
        "                self.gene = self.gene.flatten().astype(np.float32)\n",
        "                if normalize_extra_features:\n",
        "                    self.gene /= len(poi_gene_enc.categories_)\n",
        "            else:\n",
        "                self.poi_gene_enc = preprocessing.OrdinalEncoder(\n",
        "                    handle_unknown='use_encoded_value',\n",
        "                    unknown_value=-1,\n",
        "                    encoded_missing_value=-1\n",
        "                )\n",
        "                tmp = self.dataframe['poi_gene_id'].to_numpy().reshape(-1, 1)\n",
        "                tmp = self.poi_gene_enc.fit_transform(tmp)\n",
        "                self.gene = tmp.astype(np.float32).flatten()\n",
        "            # Get E3 ligase as integer classes and normalize them\n",
        "            if e3_ligase_enc is not None:\n",
        "                self.e3_ligase = self.dataframe['e3_ligase'].to_numpy().reshape(-1, 1)\n",
        "                self.e3_ligase = e3_ligase_enc.transform(self.e3_ligase)\n",
        "                self.e3_ligase = self.e3_ligase.flatten().astype(np.float32)\n",
        "                if normalize_extra_features:\n",
        "                    self.e3_ligase /= len(e3_ligase_enc.categories_)\n",
        "            else:\n",
        "                self.e3_ligase_enc = preprocessing.OrdinalEncoder(\n",
        "                    handle_unknown='use_encoded_value',\n",
        "                    unknown_value=-1,\n",
        "                    encoded_missing_value=-1\n",
        "                )\n",
        "                tmp = self.dataframe['e3_ligase'].to_numpy().reshape(-1, 1)\n",
        "                tmp = self.e3_ligase_enc.fit_transform(tmp)\n",
        "                self.e3_ligase = tmp.astype(np.float32).flatten()\n",
        "            # Get cell type as integer classes and normalize them\n",
        "            if cell_type_enc is not None:\n",
        "                self.cell_type = self.dataframe['cell_type'].to_numpy().reshape(-1, 1)\n",
        "                self.cell_type = cell_type_enc.transform(self.cell_type)\n",
        "                self.cell_type = self.cell_type.flatten().astype(np.float32)\n",
        "                if normalize_extra_features:\n",
        "                    self.cell_type /= len(cell_type_enc.categories_)\n",
        "            else:\n",
        "                self.cell_type_enc = preprocessing.OrdinalEncoder(\n",
        "                    handle_unknown='use_encoded_value',\n",
        "                    unknown_value=-1,\n",
        "                    encoded_missing_value=-1\n",
        "                )\n",
        "                tmp = self.dataframe['cell_type'].to_numpy().reshape(-1, 1)\n",
        "                tmp = self.cell_type_enc.fit_transform(tmp)\n",
        "                self.cell_type = tmp.astype(np.float32).flatten()\n",
        "            # Get the POI sequence\n",
        "            if include_poi_seq:\n",
        "                self.poi_seq = self.dataframe['poi_seq'].to_list()\n",
        "                if poi_vectorizer is None:\n",
        "                    self.poi_vectorizer = CountVectorizer(analyzer='char',\n",
        "                                                          ngram_range=ngram_range)\n",
        "                    self.poi_vectorizer.fit(self.poi_seq)\n",
        "                if precompute_poi_seq:\n",
        "                    self.poi_seq = self.poi_vectorizer.transform(self.poi_seq)\n",
        "                    self.poi_seq = self.poi_seq.toarray().astype(np.float32)\n",
        "            # Get the concentration and degradation values\n",
        "            self.active = self.dataframe['active'].astype(np.float32)\n",
        "            # TODO: Scaling the concentrations and degradations???\n",
        "            if scale_concentration:\n",
        "                self.pDC50 = (self.dataframe['pDC50'] * 0.1).astype(np.float32)\n",
        "            else:\n",
        "                self.pDC50 = self.dataframe['pDC50'].astype(np.float32)\n",
        "            if scale_degradation:\n",
        "                self.Dmax = (self.dataframe['Dmax']).astype(np.float32)\n",
        "            else:\n",
        "                self.Dmax = self.dataframe['Dmax'].astype(np.float32)\n",
        "            # Tokenize the POI sequence (for example for BERT-based models)\n",
        "            if tokenize_poi_seq:\n",
        "                if poi_tokenizer is None:\n",
        "                    self.poi_seq = self.dataframe['poi_seq']\n",
        "                else:\n",
        "                    self.poi_seq = [self.poi_tokenizer(seq, padding='max_length', truncation=True, return_tensors='pt') for seq in self.dataframe['poi_seq']]\n",
        "                \n",
        "        if precompute_fingerprints:\n",
        "            if self.use_morgan_fp:\n",
        "                self.morgan_fp = np.array([get_fingerprint(s, n_bits=self.morgan_bits, fp_type='morgan', atomic_radius=morgan_atomic_radius).astype(np.float32) for s in self.smiles])\n",
        "            if self.use_maccs_fp:\n",
        "                self.maccs_fp = np.array([get_fingerprint(s, fp_type='maccs').astype(np.float32) for s in self.smiles])\n",
        "            if self.use_path_fp:\n",
        "                self.path_fp = np.array([get_fingerprint(s, n_bits=self.path_bits, fp_type='path', min_path=self.fp_min_path, max_path=self.fp_max_path).astype(np.float32) for s in self.smiles])\n",
        "        if include_smiles_as_graphs or precompute_smiles_as_graphs:\n",
        "            # NOTE: self.graph_smiles is a list of PytorchGeometric Data objects\n",
        "            self.graph_smiles = [from_smiles(s) for s in self.smiles]\n",
        "        if smiles_tokenizer:\n",
        "            # NOTE: Do NOT return tensors when doing SSL, i.e., MLM, as reported\n",
        "            # in this conversation: https://discuss.huggingface.co/t/extra-dimension-with-datacollatorfor-languagemodeling-into-bertformaskedlm/6400/6\n",
        "            if use_for_ssl:\n",
        "                self.smiles_tokenized = [\n",
        "                    smiles_tokenizer(s, padding='max_length', truncation=True) for s in self.smiles\n",
        "                ]\n",
        "                assert len(self.smiles_tokenized) == len(self.smiles), (\n",
        "                    f'ERROR. Len tokenized {len(self.smiles_tokenized)} /= len SMILES {len(self.smiles)}'\n",
        "                )\n",
        "            else:\n",
        "                self.smiles_tokenized = [\n",
        "                    smiles_tokenizer(s, padding='max_length', truncation=True, return_tensors='pt') for s in self.smiles\n",
        "                ]\n",
        "\n",
        "    @staticmethod\n",
        "    def load(pt_file):\n",
        "        # TODO: Work in progress\n",
        "        return torch.load(pt_file)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.smiles)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        smiles = self.smiles.iloc[idx]\n",
        "        if self.use_for_ssl:\n",
        "            elem = {}\n",
        "            if self.smiles_tokenizer:\n",
        "                smiles_tokenized = self.smiles_tokenized[idx]\n",
        "                elem['input_ids'] = smiles_tokenized['input_ids']\n",
        "                elem['attention_mask'] = smiles_tokenized['attention_mask']\n",
        "                elem['labels'] = smiles_tokenized['input_ids'].copy()\n",
        "            else:\n",
        "                elem['smiles'] = smiles\n",
        "            return elem\n",
        "        elem = {\n",
        "            'e3_ligase': self.e3_ligase[idx][..., None],\n",
        "            'cell_type': self.cell_type[idx][..., None],\n",
        "        }\n",
        "        if self.include_poi_gene:\n",
        "            elem['poi_gene_id'] = self.gene[idx][..., None]\n",
        "        if self.task == 'predict_active_inactive':\n",
        "            elem['labels'] = self.active.iloc[idx][..., None]\n",
        "        elif self.task == 'predict_pDC50':\n",
        "            elem['labels'] = self.pDC50.iloc[idx][..., None]\n",
        "        elif self.task == 'predict_pDC50_and_Dmax':\n",
        "            Dmax = self.Dmax.iloc[idx]\n",
        "            pDC50 = self.pDC50.iloc[idx]\n",
        "            elem['labels'] = np.array([Dmax, pDC50])\n",
        "        else:\n",
        "            raise ValueError(f'Task \"{self.task}\" not recognized. Available: \"predict_pDC50\" \\| \"predict_active_inactive\" \\| \"predict_pDC50_and_Dmax\"')\n",
        "        if self.include_smiles_as_graphs or self.precompute_smiles_as_graphs:\n",
        "            if self.precompute_smiles_as_graphs:\n",
        "                elem['smiles_graph'] = self.graph_smiles[idx]\n",
        "            else:\n",
        "                elem['smiles_graph'] = from_smiles(smiles)\n",
        "        if self.smiles_tokenizer:\n",
        "            elem['smiles_tokenized'] = self.smiles_tokenized[idx]\n",
        "        if self.include_poi_seq or self.tokenize_poi_seq:\n",
        "            if self.precompute_poi_seq:\n",
        "                elem['poi_seq'] = self.poi_seq[idx]\n",
        "            else:\n",
        "                poi_seq = self.poi_vectorizer.transform([self.poi_seq[idx]])\n",
        "                poi_seq = poi_seq.toarray().flatten().astype(np.float32)\n",
        "                elem['poi_seq'] = poi_seq\n",
        "        if self.include_smiles_as_str:\n",
        "            elem['smiles'] = smiles\n",
        "        if self.use_morgan_fp:\n",
        "            if self.precompute_fingerprints:\n",
        "                fp = self.morgan_fp[idx].copy()\n",
        "            else:\n",
        "                fp = get_fingerprint(smiles, n_bits=self.morgan_bits).astype(np.float32)\n",
        "            elem['morgan_fp'] = fp\n",
        "        if self.use_maccs_fp:\n",
        "            if self.precompute_fingerprints:\n",
        "                fp = self.maccs_fp[idx].copy()\n",
        "            else:\n",
        "                fp = get_fingerprint(smiles, fp_type='maccs').astype(np.float32)\n",
        "            elem['maccs_fp'] = fp\n",
        "        if self.use_path_fp:\n",
        "            if self.precompute_fingerprints:\n",
        "                fp = self.path_fp[idx].copy()\n",
        "            else:\n",
        "                fp = get_fingerprint(smiles, n_bits=self.path_bits,\n",
        "                                     fp_type='path',\n",
        "                                     min_path=self.fp_min_path,\n",
        "                                     max_path=self.fp_max_path).astype(np.float32)\n",
        "            elem['path_fp'] = fp\n",
        "        return elem\n",
        "\n",
        "    def get_fingerprint(self, fp_type: Literal['morgan_fp', 'maccs_fp', 'path_fp'] = 'morgan_fp'):\n",
        "        # TODO: Add the proper checks if fingerprints are used\n",
        "        if self.precompute_fingerprints:\n",
        "            if fp_type == 'morgan_fp':\n",
        "                return self.morgan_fp\n",
        "            elif fp_type == 'maccs_fp':\n",
        "                return self.maccs_fp\n",
        "            elif fp_type == 'path_fp':\n",
        "                return self.path_fp\n",
        "            else:\n",
        "                raise ValueError(f'Fingerprint type \"{fp_type}\" not recognized. Available: \"morgan_fp\" \\| \"maccs_fp\" \\| \"path_fp\"')\n",
        "        else:\n",
        "            smiles = self.smiles\n",
        "            if fp_type == 'morgan_fp':\n",
        "                return np.array([get_fingerprint(s, n_bits=self.morgan_bits).astype(np.float32) for s in smiles])\n",
        "            elif fp_type == 'maccs_fp':\n",
        "                return np.array([get_fingerprint(s, fp_type='maccs_fp').astype(np.float32) for s in smiles])\n",
        "            elif fp_type == 'path_fp':\n",
        "                return np.array([get_fingerprint(s, n_bits=self.path_bits, fp_type='path_fp', min_path=self.fp_min_path, max_path=self.fp_max_path).astype(np.float32) for s in smiles])\n",
        "            else:\n",
        "                raise ValueError(f'Fingerprint type \"{fp_type}\" not recognized. Available: \"morgan_fp\" \\| \"maccs_fp\" \\| \"path_fp\"')\n",
        "    \n",
        "    def get_poi_seq_emb_size(self):\n",
        "        if self.include_poi_seq:\n",
        "            return len(self.poi_vectorizer.get_feature_names_out())\n",
        "        else:\n",
        "            return 0\n",
        "    \n",
        "    def __str__(self) -> str:\n",
        "        return f'ProtacDataset for {self.task} task with {len(self)} samples.'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VOQI-QISLfrw"
      },
      "source": [
        "In order to have batches of graphs _along side with the other features_, we need to _extend_ the default collate function to include data of Pytorch Geometric type `Data`.\n",
        "\n",
        "Refer to [this documentation](https://pytorch.org/docs/stable/data.html#torch.utils.data.default_collate)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO4kl4Dw66SA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data._utils.collate import collate\n",
        "from torch.utils.data._utils.collate import default_collate_fn_map\n",
        "\n",
        "def graph_collate(batch, *, collate_fn_map=None):\n",
        "    # Handle graph data separately: graph representation and computation can be\n",
        "    # greatly optimized due to their sparse nature. In fact, multiple graphs in\n",
        "    # a batch can be seen as a \"big\" graph of unconnected sub-graphs. Hence,\n",
        "    # their adjecency matrices can be combined together to form a single one.\n",
        "    return torch_geometric.data.Batch.from_data_list(batch)\n",
        "\n",
        "def custom_collate(batch):\n",
        "    collate_map = default_collate_fn_map.copy()\n",
        "    collate_map.update({torch_geometric.data.Data: graph_collate})\n",
        "    return collate(batch, collate_fn_map=collate_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJCyl4d8QDRl"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "\n",
        "protac_dataset_src = '''\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch_geometric\n",
        "import torch_geometric.nn as geom_nn\n",
        "import torch_geometric.data as geom_data\n",
        "from torch_geometric.utils.smiles import from_smiles\n",
        "from torch.utils.data._utils.collate import collate\n",
        "from torch.utils.data._utils.collate import default_collate_fn_map\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, DataStructs, MACCSkeys\n",
        "\n",
        "import torchvision\n",
        "import typing\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from typing import Literal, Callable, List, ClassVar, Any, Mapping, Tuple\n",
        "\n",
        "MACCS_BITWIDTH = 167\n",
        "\n",
        "'''\n",
        "\n",
        "protac_dataset_src += inspect.getsource(get_fingerprint) + '\\n'\n",
        "protac_dataset_src += inspect.getsource(graph_collate) + '\\n'\n",
        "protac_dataset_src += inspect.getsource(custom_collate) + '\\n'\n",
        "protac_dataset_src += 'class ProtacDataset(Dataset): \\n'\n",
        "protac_dataset_src += inspect.getsource(ProtacDataset.__init__) + '\\n'\n",
        "protac_dataset_src += inspect.getsource(ProtacDataset.load) + '\\n'\n",
        "protac_dataset_src += inspect.getsource(ProtacDataset.__len__) + '\\n'\n",
        "protac_dataset_src += inspect.getsource(ProtacDataset.__getitem__)\n",
        "with open(os.path.join(src_dir, 'protac_dataset.py'), 'w') as f:\n",
        "    f.write(protac_dataset_src)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PP26f-VYH1Bh"
      },
      "source": [
        "**TODO: The number of node features might not be correct...**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo-i52kjIFmH"
      },
      "outputs": [],
      "source": [
        "test_dataset = ProtacDataset(val_df, include_smiles_as_graphs=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate)\n",
        "batch = next(iter(test_dataloader))\n",
        "NUM_NODE_FEATURES = num_node_features = batch['smiles_graph'].x.size()[-1]\n",
        "NODE_EDGE_DIM = node_edge_dim = batch['smiles_graph'].edge_attr.size()[-1]\n",
        "\n",
        "print(batch['e3_ligase'].size())\n",
        "print(batch['poi_seq'].size())\n",
        "print(batch)\n",
        "print(f'Number of node features: {NUM_NODE_FEATURES}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_dataset = ProtacDataset(val_bin_protac_pedia_df, include_smiles_as_graphs=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True, collate_fn=custom_collate)\n",
        "batch = next(iter(test_dataloader))\n",
        "\n",
        "print(test_dataset.hparams)\n",
        "print(batch['e3_ligase'].size())\n",
        "print(batch['poi_seq'].size())\n",
        "print(batch['labels'].size())\n",
        "print(batch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieve train and test PROTAC datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_datasets(task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                 use_upsampled: bool = False,\n",
        "                 regenerate_datasets: bool = False,\n",
        "                 dataset_name: str = '', \n",
        "                 get_DMatrix: bool = False,\n",
        "                 on_missing: Literal['error', 'ignore', 'regenerate'] = 'regenerate',\n",
        "                 save_datasets: bool = True,\n",
        "                 **protac_ds_kwargs):\n",
        "    '''Get train and test datasets for the given task.\n",
        "    Args:\n",
        "        task (str): Task to perform. One of 'predict_active_inactive', 'predict_pDC50', 'predict_pDC50_and_Dmax'.\n",
        "        use_upsampled (bool): Whether to use the upsampled training dataset for 'predict_active_inactive' task.\n",
        "        regenerate_datasets (bool): Whether to regenerate the datasets if already present on disk.\n",
        "        dataset_name (str): Trailing name of the dataset to generate. Useful for differentiating between different models. Example: f'train_pDC50_Dmax_dataset{dataset_name}.pt'\n",
        "        on_missing (bool): Raise an error if the dataset is not found on disk. If False, generate the dataset instead.\n",
        "        get_DMatrix (bool): TODO: Add support for XGBoost.\n",
        "        protac_ds_kwargs (dict): Keyword arguments to pass to the ProtacDataset class. Passed to all train/val/test datasets to be generated.\n",
        "    '''\n",
        "    # Function to rename task names\n",
        "    # TODO: I shall simply convert 'active_inactive' to 'bin' and the rest to 'regr'...\n",
        "    rename = lambda x: x.replace('predict_', '').replace('active_inactive', 'bin').replace('pDC50_and_Dmax', 'pDC50_Dmax')\n",
        "    # Setup dataframes\n",
        "    datasets = {\n",
        "        'train': dataframes['train_upsampled_bin'], # train_bin_df if not use_upsampled else train_upsampled_bin_df,\n",
        "        'val': dataframes['val_bin'], # val_bin_df,\n",
        "        'test': dataframes['test_bin'], # test_bin_df,\n",
        "        'train_protac_pedia': train_bin_protac_pedia_df,\n",
        "        'val_protac_pedia': val_bin_protac_pedia_df,\n",
        "    }\n",
        "    # Get regression datasets if required\n",
        "    if task == 'predict_pDC50_and_Dmax':\n",
        "        datasets['train'] = dataframes['train_regr'], # train_df\n",
        "        datasets['val'] = dataframes['val_regr'], # val_df\n",
        "        datasets['test'] = dataframes['test_regr'], # test_df\n",
        "    # Start generation/retrieval of datasets by \"overwriting\" dataframe keys\n",
        "    ret = {}\n",
        "    for k, df in datasets.items():\n",
        "        upsampled = '_upsampled' if use_upsampled else ''\n",
        "        filename = f'{k}{upsampled}_{rename(task)}_dataset{dataset_name}.pt'\n",
        "        filename = os.path.join(data_dir, 'protac', filename)\n",
        "        if os.path.exists(filename):\n",
        "            if regenerate_datasets:\n",
        "                ret[k] = ProtacDataset(df, task=task, **protac_ds_kwargs)\n",
        "                if save_datasets:\n",
        "                    torch.save(ret[k], filename)\n",
        "            else:\n",
        "                ret[k] = torch.load(filename)\n",
        "        else:\n",
        "            if on_missing == 'error':\n",
        "                raise FileNotFoundError(f'{k} dataset not found at: {filename}')\n",
        "            elif on_missing == 'ignore':\n",
        "                pass\n",
        "            else:\n",
        "                ret[k] = ProtacDataset(df, task=task, **protac_ds_kwargs)\n",
        "                # TODO: Add support for XGBoost datasets here\n",
        "                if save_datasets:\n",
        "                    torch.save(ret[k], filename)\n",
        "    return ret\n",
        "\n",
        "\n",
        "    # # Get namings\n",
        "    # if task == 'predict_pDC50_and_Dmax':\n",
        "    #     train_ds = os.path.join(data_dir, 'protac', f'train_pDC50_Dmax_dataset{dataset_name}.pt')\n",
        "    #     val_ds = os.path.join(data_dir, 'protac', f'val_pDC50_Dmax_dataset{dataset_name}.pt')\n",
        "    #     test_ds = os.path.join(data_dir, 'protac', f'test_pDC50_Dmax_dataset{dataset_name}.pt')\n",
        "    #     train_tmp_df = train_df\n",
        "    #     val_tmp_df = val_df\n",
        "    #     test_tmp_df = test_df\n",
        "    # if task == 'predict_pDC50':\n",
        "    #     # TODO\n",
        "    #     raise NotImplementedError\n",
        "    # elif task == 'predict_active_inactive':\n",
        "    #     val_ds = os.path.join(data_dir, 'protac', f'val_bin_dataset{dataset_name}.pt')\n",
        "    #     test_ds = os.path.join(data_dir, 'protac', f'test_bin_dataset{dataset_name}.pt')\n",
        "    #     val_tmp_df = val_bin_df\n",
        "    #     test_tmp_df = test_bin_df\n",
        "    #     if use_upsampled:\n",
        "    #         train_ds = os.path.join(data_dir, 'protac', f'train_upsampled_bin_dataset{dataset_name}.pt')\n",
        "    #         train_tmp_df = train_upsampled_bin_df\n",
        "    #     else:\n",
        "    #         train_ds = os.path.join(data_dir, 'protac', f'train_bin_dataset{dataset_name}.pt')\n",
        "    #         train_tmp_df = train_bin_df\n",
        "    # # Generate datasets if required or not already on disk\n",
        "    # if not os.path.exists(train_ds) and on_missing == 'error' and not regenerate_datasets:\n",
        "    #     raise FileNotFoundError(f'Train dataset not found at: {train_ds}')\n",
        "    # else:\n",
        "    #     if regenerate_datasets or not on_missing == 'error':\n",
        "    #         train_dataset = ProtacDataset(train_tmp_df, task=task,\n",
        "    #                                     **protac_ds_kwargs)\n",
        "    #         torch.save(train_dataset, train_ds)\n",
        "    #     # TODO: Add support for XGBoost\n",
        "    #     # if get_DMatrix:\n",
        "    #     #     dtrain = xgb.DMatrix(train_dataset.morgan_fp, label=train_dataset.active)\n",
        "    #     else:\n",
        "    #         train_dataset = torch.load(train_ds)\n",
        "    # if not os.path.exists(val_ds) and on_missing == 'error' and not regenerate_datasets:\n",
        "    #     raise FileNotFoundError(f'Val dataset not found at: {val_ds}')\n",
        "    # else:\n",
        "    #     if regenerate_datasets or not on_missing == 'error':\n",
        "    #         val_dataset = ProtacDataset(val_tmp_df, task=task,\n",
        "    #                                     **protac_ds_kwargs)\n",
        "    #         torch.save(val_dataset, val_ds)\n",
        "    #     else:\n",
        "    #         val_dataset = torch.load(val_ds)\n",
        "    # if not os.path.exists(test_ds) and on_missing == 'error' and not regenerate_datasets:\n",
        "    #     raise FileNotFoundError(f'Test dataset not found at: {test_ds}')\n",
        "    # else:\n",
        "    #     if regenerate_datasets or not on_missing == 'error':\n",
        "    #         test_dataset = ProtacDataset(test_tmp_df, task=task,\n",
        "    #                                     **protac_ds_kwargs)\n",
        "    #         torch.save(test_dataset, test_ds)\n",
        "    #     else:\n",
        "    #         test_dataset = torch.load(test_ds)\n",
        "    # return {\n",
        "    #     'train': train_dataset,\n",
        "    #     'val': val_dataset,\n",
        "    #     'test': test_dataset,\n",
        "    # }"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plotting Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = train_df[['pDC50', 'Dmax', 'cell_type', 'poi_gene_id', 'active']]\n",
        "# tmp.loc[tmp['active'].isna(), 'active'] = -1\n",
        "cols = {\n",
        "    'pDC50': '$pDC_{50}$',\n",
        "    'Dmax': '$D_{max}$ (%)',\n",
        "    'cell_type': 'Cell type',\n",
        "    'poi_gene_id': 'POI/Target',\n",
        "    'active': 'Active/Inactive',\n",
        "}\n",
        "tmp = tmp.rename(columns=cols)\n",
        "ax = sns.pairplot(data=tmp, diag_kind='hist', hue='Active/Inactive', palette='Set2', corner=False)\n",
        "# plt.show()\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = [\n",
        "    (protac_db_df.copy(), 'PROTAC-DB'),\n",
        "    (protac_pedia_df.copy(), 'PROTAC-Pedia'),\n",
        "    (test_df.copy(), 'PROTAC-Pedia-Test'),\n",
        "]\n",
        "for tmp, df_name in dfs:\n",
        "    tmp['pDC50'] = tmp['pDC50'].astype(float)\n",
        "    tmp['Dmax'] = tmp['Dmax'].astype(float) * 100\n",
        "    tmp['active'] = tmp['active'].replace({True: 'Active', False: 'Inactive'})\n",
        "    if 'PROTAC-Pedia' in df_name:\n",
        "        del tmp['Active/Inactive']\n",
        "    old2new_names = {\n",
        "        'pDC50': '$pDC_{50}$ ($-Log_{10}(M)$)',\n",
        "        'Dmax': '$D_{max}$ (%)',\n",
        "        'active': 'Active/Inactive',\n",
        "    }\n",
        "    tmp = tmp.rename(columns=old2new_names)\n",
        "\n",
        "    sns.scatterplot(data=tmp, x='$pDC_{50}$ ($-Log_{10}(M)$)', y='$D_{max}$ (%)',\n",
        "                    hue='Active/Inactive', hue_order=['Inactive', 'Active'])\n",
        "    plt.grid(axis='both', alpha=0.8)\n",
        "    plt.title(f'{df_name}' + ': $D_{max}$ vs. $pDC_{50}$')\n",
        "    # plt.xticks(rotation=90)\n",
        "    # plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
        "\n",
        "    f = os.path.join(fig_dir, f'scatter_{df_name.lower()}_active_entries')\n",
        "    plt.savefig(f + '.pdf', bbox_inches='tight')\n",
        "    plt.savefig(f + '.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "del dfs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODO:\n",
        "\n",
        "* try different binning size\n",
        "* try two-sided ANNOVA test in order to compare the distributions of the different bins. In this way, we might get some more information on how to split up the data\n",
        "* try bswarm plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfs = [\n",
        "    (protac_db_df.copy(), 'PROTAC-DB'),\n",
        "    (protac_pedia_df.copy(), 'PROTAC-Pedia'),\n",
        "    (test_df.copy(), 'PROTAC-Pedia-Test'),\n",
        "]\n",
        "for tmp, df_name in dfs:\n",
        "    tmp['pDC50'] = tmp['pDC50'].astype(float)\n",
        "    tmp['Dmax'] = tmp['Dmax'].astype(float) * 100\n",
        "    # Change the bin size by rounding\n",
        "    tmp = (tmp[['pDC50', 'Dmax']]).round(1)\n",
        "    old2new_names = {\n",
        "        'pDC50': '$pDC_{50}$ ($-Log_{10}(M)$)',\n",
        "        'Dmax': '$D_{max}$ (%)',\n",
        "    }\n",
        "    tmp = tmp.rename(columns=old2new_names)\n",
        "    # Change plot/figure size\n",
        "    plt.figure(figsize=(9, 6))\n",
        "    ax = sns.boxplot(data=tmp, x='$pDC_{50}$ ($-Log_{10}(M)$)', y='$D_{max}$ (%)')\n",
        "    plt.xticks(rotation=90)\n",
        "    # plt.xlim(0.0, 50.0)\n",
        "    plt.ylim(0., 105.)\n",
        "    plt.grid(axis='y', alpha=0.7)\n",
        "    plt.title(f'{df_name}' + ': $D_{max}$ vs. $pDC_{50}$')\n",
        "    f = os.path.join(fig_dir, f'boxplot_{df_name.lower()}_pDC50_vs_Dmax')\n",
        "    plt.savefig(f + '.pdf', bbox_inches='tight')\n",
        "    plt.savefig(f + '.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "del dfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For plotting the distribution of POI sequences, we employ an Ordinal encoder\n",
        "# trainer on all the POI sequences in all datasets. In this way, when we\n",
        "# transform the sequences for each dataset, we will get the same encoding\n",
        "# and so the classes will be consistent.\n",
        "tmp = pd.concat([protac_db_df, protac_pedia_df], axis=0)\n",
        "poi_seq_enc = sklearn.preprocessing.OrdinalEncoder()\n",
        "poi_seq_enc.fit(tmp['poi_seq'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "dfs = [\n",
        "    (protac_db_df.copy(), 'PROTAC-DB'),\n",
        "    (protac_pedia_df.copy(), 'PROTAC-Pedia'),\n",
        "    (test_df.copy(), 'PROTAC-Pedia-Test'),\n",
        "]\n",
        "common_poi = []\n",
        "for col in ['POI Class', 'E3 Ligase', 'Cell Type']:\n",
        "    for tmp, df_name in dfs:\n",
        "        tmp['cell_type'] = tmp['cell_type'].str.replace('esophagealcancercellline', '') # it's just too long to print...\n",
        "        tmp['POI Class'] = poi_seq_enc.transform(tmp['poi_seq'].to_numpy().reshape(-1, 1))\n",
        "        old2new_names = {\n",
        "            'e3_ligase': 'E3 Ligase',\n",
        "            'cell_type': 'Cell Type',\n",
        "        }\n",
        "        tmp = tmp.rename(columns=old2new_names)\n",
        "        print(f'Number or unique {col} in {df_name}: {len(tmp[col].unique())}')\n",
        "        # # Change plot/figure size\n",
        "        # if col == 'Cell Type':\n",
        "        #     plt.figure(figsize=(15, 6))\n",
        "        n = 20\n",
        "        top_n = tmp[col].value_counts().index[:n]\n",
        "        # print([poi_seq_enc.inverse_transform([[tmp.at[i, 'POI Class']]])[0][0] for i in top_n])\n",
        "        \n",
        "        if col == 'POI Class' and df_name != 'PROTAC-Pedia-Test':\n",
        "            pois = []\n",
        "            for i in top_n:\n",
        "                # poi_name = poi_seq_enc.inverse_transform([[int(i)]])[0][0]\n",
        "                # print(i, poi_name)\n",
        "                pois.append(i)\n",
        "            if common_poi == []:\n",
        "                common_poi = pois\n",
        "            common_poi = list(set(common_poi) & set(pois))\n",
        "        \n",
        "        ax = sns.countplot(data=tmp, x=col, order=top_n)\n",
        "        fmt = '{:0.0f}'\n",
        "        rot = 0 # 90 if col == 'Cell Type' else 0\n",
        "        for bars_group in ax.containers:\n",
        "            ax.bar_label(bars_group, padding=2, fmt=fmt, rotation=rot) # fontsize=12\n",
        "        plt.xticks(rotation=0 if col == 'E3 Ligase' else 90)\n",
        "        plt.grid(axis='y', alpha=0.7)\n",
        "        top_n = f' (Top-{n} most frequent)' if col != 'E3 Ligase' else ''\n",
        "        plt.title(f'{df_name}: {col} Distribution{top_n}')\n",
        "        t = col.lower().replace(' ', '_')\n",
        "        f = os.path.join(fig_dir, f'countplot_{df_name.lower()}_{t}_distribution')\n",
        "        plt.savefig(f + '.pdf', bbox_inches='tight')\n",
        "        plt.savefig(f + '.png', bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "del dfs\n",
        "\n",
        "for i in common_poi:\n",
        "    poi_name = poi_seq_enc.inverse_transform([[int(i)]])[0][0]\n",
        "    print(i, poi_name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from rdkit import Chem\n",
        "# from rdkit.Chem import Descriptors\n",
        "# from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "# from sklearn.decomposition import PCA\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # List of SMILES\n",
        "# smiles_list = [\"CCO\", \"CCN(C)C=O\", \"C1=CC=CC=C1\"]\n",
        "\n",
        "# smiles_list = protac_db_df['Smiles_nostereo'].to_list()\n",
        "\n",
        "# # Convert SMILES to RDKit molecules\n",
        "# mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
        "\n",
        "# # Calculate molecular descriptors\n",
        "# descriptor_names = [desc[0] for desc in Descriptors._descList]\n",
        "# descriptor_calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
        "# descriptors = [descriptor_calculator.CalcDescriptors(mol) for mol in mols]\n",
        "\n",
        "# # Perform Principal Component Analysis (PCA)\n",
        "# pca = PCA(n_components=2)\n",
        "# pca.fit(descriptors)\n",
        "# transformed = pca.transform(descriptors)\n",
        "\n",
        "# # Create a DataFrame for plotting\n",
        "# df = pd.DataFrame(transformed, columns=['PC1', 'PC2'])\n",
        "# df['SMILES'] = smiles_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %matplotlib\n",
        "# # Plot the chemical space\n",
        "# fig,ax = plt.subplots()\n",
        "\n",
        "# sc = plt.scatter(df['PC1'], df['PC2'])\n",
        "\n",
        "# annot = ax.annotate(\"\", xy=(0,0), xytext=(20,20), textcoords=\"offset points\",\n",
        "#                     bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
        "#                     arrowprops=dict(arrowstyle=\"->\"))\n",
        "# annot.set_visible(False)\n",
        "\n",
        "\n",
        "# def update_annot(ind, prev_ind=-1):\n",
        "#     if prev_ind == -1:\n",
        "#         prev_ind = ind[\"ind\"][0]\n",
        "#     if ind[\"ind\"][0] == prev_ind:\n",
        "#         prev_ind = ind[\"ind\"][0]\n",
        "#         pos = sc.get_offsets()[ind[\"ind\"][0]]\n",
        "#         annot.xy = pos\n",
        "#         # text = \"{}, {}\".format(\" \".join(list(map(str,ind[\"ind\"]))), \n",
        "#         #                     \" \".join([df.at[n, 'SMILES'] for n in ind[\"ind\"]]))\n",
        "#         text = \" \".join([df.at[n, 'SMILES'] for n in ind[\"ind\"]])\n",
        "#         annot.set_text(text)\n",
        "#         # annot.get_bbox_patch().set_facecolor(cmap(norm(c[ind[\"ind\"][0]])))\n",
        "#         annot.get_bbox_patch().set_alpha(0.4)\n",
        "    \n",
        "\n",
        "# prev_ind = -1\n",
        "# def hover(event):\n",
        "#     vis = annot.get_visible()\n",
        "#     if event.inaxes == ax:\n",
        "#         cont, ind = sc.contains(event)\n",
        "#         if cont:\n",
        "#             update_annot(ind, prev_ind)\n",
        "#             annot.set_visible(True)\n",
        "#             fig.canvas.draw_idle()\n",
        "#         else:\n",
        "#             if vis:\n",
        "#                 annot.set_visible(False)\n",
        "#                 fig.canvas.draw_idle()\n",
        "\n",
        "# fig.canvas.mpl_connect(\"motion_notify_event\", hover)\n",
        "\n",
        "# plt.xlabel('PC1')\n",
        "# plt.ylabel('PC2')\n",
        "# plt.title('Chemical Space')\n",
        "# plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RDKit molecular descriptors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors\n",
        "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_mol_descriptors(smiles_list):\n",
        "    # Convert SMILES to RDKit molecules\n",
        "    mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
        "    # Calculate molecular descriptors\n",
        "    descriptor_names = [desc[0] for desc in Descriptors._descList]\n",
        "    descriptor_calculator = MoleculeDescriptors.MolecularDescriptorCalculator(descriptor_names)\n",
        "    descriptors = [descriptor_calculator.CalcDescriptors(mol) for mol in mols]\n",
        "    return np.array(descriptors)\n",
        "\n",
        "print('Calculating molecular descriptors...')\n",
        "\n",
        "smiles_db_list = protac_db_df['Smiles_nostereo'].to_list()\n",
        "f = os.path.join(data_dir, 'protac', 'protac_db_descr.npy')\n",
        "if os.path.exists(f):\n",
        "    protac_db_descr = np.load(f)\n",
        "else:\n",
        "    protac_db_descr = get_mol_descriptors(smiles_db_list)\n",
        "    np.save(os.path.join(f, protac_db_descr))\n",
        "\n",
        "smiles_pedia_list = protac_pedia_df['Smiles_nostereo'].to_list()\n",
        "f = os.path.join(data_dir, 'protac', 'protac_pedia_descr.npy')\n",
        "if os.path.exists(f):\n",
        "    protac_pedia_descr = np.load(f)\n",
        "else:\n",
        "    protac_pedia_descr = get_mol_descriptors(smiles_pedia_list)\n",
        "    np.save(os.path.join(f, protac_pedia_descr))\n",
        "\n",
        "print('Done.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plt.ioff() # Turn off interactive mode like %matplotlib magic...\n",
        "\n",
        "\n",
        "def plot_tSNE(df, perplexity=0, descr='PROTAC-DB'):\n",
        "    fig, ax = plt.subplots()\n",
        "    # Get sub-plot and scatter plot\n",
        "    sc = plt.scatter(df['Dimension 1'], df['Dimension 2'], s=5, alpha=0.6)\n",
        "    # Create annotation\n",
        "    annot = ax.annotate('', xy=(0,0), xytext=(20,20),\n",
        "                        textcoords='offset points',\n",
        "                        bbox=dict(boxstyle='round', fc='w'),\n",
        "                        arrowprops=dict(arrowstyle='->'))\n",
        "    annot.set_visible(False)\n",
        "    # Function to update annotation text\n",
        "    def update_annot(ind, prev_ind=-1):\n",
        "        if prev_ind == -1:\n",
        "            prev_ind = ind['ind'][0]\n",
        "        if ind['ind'][0] == prev_ind:\n",
        "            prev_ind = ind['ind'][0]\n",
        "            pos = sc.get_offsets()[ind['ind'][0]]\n",
        "            annot.xy = pos\n",
        "            # text = '{}, {}'.format(' '.join(list(map(str,ind['ind']))), \n",
        "            #                     ' '.join([df.at[n, 'SMILES'] for n in ind['ind']]))\n",
        "            text = ' '.join([df.at[n, 'SMILES'] for n in ind['ind']])\n",
        "            annot.set_text(text)\n",
        "            # annot.get_bbox_patch().set_facecolor(cmap(norm(c[ind['ind'][0]])))\n",
        "            annot.get_bbox_patch().set_alpha(0.4)\n",
        "    # Function to show annotation on hover\n",
        "    prev_ind = -1\n",
        "    def hover(event):\n",
        "        vis = annot.get_visible()\n",
        "        if event.inaxes == ax:\n",
        "            cont, ind = sc.contains(event)\n",
        "            if cont:\n",
        "                update_annot(ind, prev_ind)\n",
        "                annot.set_visible(True)\n",
        "                fig.canvas.draw_idle()\n",
        "            else:\n",
        "                if vis:\n",
        "                    annot.set_visible(False)\n",
        "                    fig.canvas.draw_idle()\n",
        "    # fig.canvas.mpl_connect('motion_notify_event', hover)\n",
        "    plt.xlabel('Dimension 1')\n",
        "    plt.ylabel('Dimension 2')\n",
        "    plt.title(f'Chemical Space for {descr} (t-SNE), Perplexity={perplexity}')\n",
        "    plt.grid(alpha=0.8)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from bhtsne import tsne\n",
        "\n",
        "# Perplexity values to try\n",
        "perplexities = [5, 10, 20, 30, 50]\n",
        "\n",
        "# Plot chemical space for each perplexity\n",
        "for perplexity in perplexities:\n",
        "    transformed = tsne(protac_db_descr,\n",
        "                        perplexity=perplexity,\n",
        "                        dimensions=2,\n",
        "                        theta=0.5, # Original: 0.5\n",
        "                        rand_seed=42)\n",
        "    # Create a DataFrame for plotting\n",
        "    df = pd.DataFrame(transformed, columns=['Dimension 1', 'Dimension 2'])\n",
        "    plt.scatter(df['Dimension 1'], df['Dimension 2'], s=5, alpha=0.6, label='PROTAC-DB')\n",
        "    \n",
        "    transformed = tsne(protac_pedia_descr,\n",
        "                        perplexity=perplexity,\n",
        "                        dimensions=2,\n",
        "                        theta=0.5, # Original: 0.5\n",
        "                        rand_seed=42)\n",
        "    # Create a DataFrame for plotting\n",
        "    df = pd.DataFrame(transformed, columns=['Dimension 1', 'Dimension 2'])\n",
        "    plt.scatter(df['Dimension 1'], df['Dimension 2'], s=5, alpha=0.6, label='PROTAC-Pedia')\n",
        "    \n",
        "    plt.xlabel('Dimension 1')\n",
        "    plt.ylabel('Dimension 2')\n",
        "    plt.title(f'Chemical Space (t-SNE), Perplexity={perplexity}')\n",
        "    plt.legend()\n",
        "    plt.grid(alpha=0.8)\n",
        "    plt.show()\n",
        "\n",
        "    # for descr, descriptors, smiles_list in zip(['PROTAC-DB', 'PROTAC-PEDIA'], \n",
        "    #                                            [protac_db_descr, protac_pedia_descr], \n",
        "    #                                            [smiles_db_list, smiles_pedia_list]):\n",
        "    #     print(f'Plotting chemical space for {descr} (t-SNE), Perplexity={perplexity}...')\n",
        "    #     # Perform t-SNE\n",
        "    #     # tsne = TSNE(n_components=2,\n",
        "    #     #             n_iter=500,\n",
        "    #     #             n_iter_without_progress=20,\n",
        "    #     #             perplexity=perplexity,\n",
        "    #     #             random_state=42,\n",
        "    #     #             learning_rate='auto',\n",
        "    #     #             init='pca',\n",
        "    #     #             n_jobs=-1)\n",
        "    #     # transformed = tsne.fit_transform(np.array(descriptors))\n",
        "        \n",
        "    #     plot_tSNE(df, perplexity=perplexity, descr=descr)  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fingerprints via SKlearn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get_fingerprint(smiles: str, n_bits: int = 1024, fp_type: Literal['morgan', 'maccs', 'path'] = 'morgan',\n",
        "#                     min_path: int = 1, max_path: int = 2,\n",
        "#                     atomic_radius: int = 2)\n",
        "\n",
        "for fp_type in ['morgan', 'maccs']:\n",
        "    for n_bits in [1024, 2048, 4096]:\n",
        "        if fp_type == 'maccs' and n_bits != 1024:\n",
        "            # MACCS keys only have 167 bits\n",
        "            continue\n",
        "        # Get fingerprints\n",
        "        protac_db_descr = np.array([get_fingerprint(smiles, n_bits=n_bits, fp_type=fp_type) for smiles in smiles_db_list]).astype(np.float64)\n",
        "        protac_pedia_descr = np.array([get_fingerprint(smiles, n_bits=n_bits, fp_type=fp_type) for smiles in smiles_pedia_list]).astype(np.float64)\n",
        "        # Perplexity values to try\n",
        "        perplexities = [5, 10, 20, 30, 50]\n",
        "        # Plot chemical space for each perplexity\n",
        "        for perplexity in perplexities:\n",
        "            tsne = TSNE(n_components=2,\n",
        "                        n_iter=1000,\n",
        "                        perplexity=perplexity,\n",
        "                        random_state=42,\n",
        "                        learning_rate='auto',\n",
        "                        init='pca',\n",
        "                        n_jobs=-1)\n",
        "            transformed = tsne.fit_transform(protac_db_descr)\n",
        "            # Create a DataFrame for plotting\n",
        "            df = pd.DataFrame(transformed, columns=['Dimension 1', 'Dimension 2'])\n",
        "            plt.scatter(df['Dimension 1'], df['Dimension 2'], s=5, alpha=0.6, label='PROTAC-DB')\n",
        "            \n",
        "            transformed = tsne.fit_transform(protac_pedia_descr)\n",
        "            # Create a DataFrame for plotting\n",
        "            df = pd.DataFrame(transformed, columns=['Dimension 1', 'Dimension 2'])\n",
        "            plt.scatter(df['Dimension 1'], df['Dimension 2'], s=5, alpha=0.6, label='PROTAC-Pedia')\n",
        "            \n",
        "            descr = 'MACCS' if fp_type == 'maccs' else f'Morgan {n_bits} bits'\n",
        "            plt.title(f'Chemical Space from {descr} Fingerprints (t-SNE), Perplexity={perplexity}')\n",
        "            plt.xlabel('Dimension 1')\n",
        "            plt.ylabel('Dimension 2')\n",
        "            plt.legend()\n",
        "            plt.grid(alpha=0.8)\n",
        "            plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[1] K. M. Sakamoto, K. B. Kim, A. Kumagai, F. Mercurio, C. M. Crews, and R. J. Deshaies, ‚ÄúProtacs: chimeric molecules that target proteins to the Skp1-Cullin-F box complex for ubiquitination and degradation,‚Äù Proc Natl Acad Sci U S A, vol. 98, no. 15, pp. 8554‚Äì8559, Jul. 2001, doi: 10.1073/pnas.141230798."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TruncatedSVD:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# get_fingerprint(smiles: str, n_bits: int = 1024, fp_type: Literal['morgan', 'maccs', 'path'] = 'morgan',\n",
        "#                     min_path: int = 1, max_path: int = 2,\n",
        "#                     atomic_radius: int = 2)\n",
        "\n",
        "for fp_type in ['morgan', 'maccs']:\n",
        "    for n_bits in [1024, 2048, 4096]:\n",
        "        if fp_type == 'maccs' and n_bits != 1024:\n",
        "            # MACCS keys only have 167 bits\n",
        "            continue\n",
        "        # Get fingerprints\n",
        "        protac_db_descr = np.array([get_fingerprint(smiles, n_bits=n_bits, fp_type=fp_type) for smiles in smiles_db_list]).astype(np.float64)\n",
        "        protac_pedia_descr = np.array([get_fingerprint(smiles, n_bits=n_bits, fp_type=fp_type) for smiles in smiles_pedia_list]).astype(np.float64)\n",
        "        # Perplexity values to try\n",
        "        n_components = [2, 3]\n",
        "        # Plot chemical space for each number of components\n",
        "        for n in n_components:\n",
        "            # Perform TruncatedSVD\n",
        "            svd = TruncatedSVD(n_components=n, random_state=42, n_iter=100)\n",
        "            # Create a DataFrame for plotting\n",
        "            transformed = svd.fit_transform(protac_db_descr)\n",
        "            column_names = [f'Component {i+1}' for i in range(n)]\n",
        "            df_db = pd.DataFrame(transformed, columns=column_names)\n",
        "\n",
        "            transformed = svd.fit_transform(protac_pedia_descr)\n",
        "            column_names = [f'Component {i+1}' for i in range(n)]\n",
        "            df_pedia = pd.DataFrame(transformed, columns=column_names)\n",
        "\n",
        "            # Plot the chemical space\n",
        "            if n == 2:\n",
        "                plt.scatter(df_db['Component 1'], df_db['Component 2'], label='PROTAC-DB', s=5, alpha=0.6)\n",
        "                plt.scatter(df_pedia['Component 1'], df_pedia['Component 2'], label='PROTAC-Pedia', s=5, alpha=0.6)\n",
        "                # for i, row in df.iterrows():\n",
        "                #     plt.annotate(row['SMILES'], (row['Component 1'], row['Component 2']))\n",
        "                plt.xlabel('Component 1')\n",
        "                plt.ylabel('Component 2')\n",
        "                plt.legend()\n",
        "                plt.grid(alpha=0.8)\n",
        "                plt.title('Chemical Space (TruncatedSVD)')\n",
        "                descr = 'MACCS' if fp_type == 'maccs' else f'Morgan {n_bits} bits'\n",
        "                plt.title(f'Chemical Space from {descr} Fingerprints (TruncatedSVD), n.components={n}')\n",
        "            elif n == 3:\n",
        "                fig = plt.figure()\n",
        "                ax = fig.add_subplot(111, projection='3d')\n",
        "                ax.scatter(df_db['Component 1'], df_db['Component 2'], df_db['Component 3'], label='PROTAC-DB', s=5, alpha=0.6)\n",
        "                ax.scatter(df_pedia['Component 1'], df_pedia['Component 2'], df_pedia['Component 3'], label='PROTAC-Pedia', s=5, alpha=0.6)\n",
        "                # for i, row in df_db.iterrows():\n",
        "                #     ax.text(row['Component 1'], row['Component 2'], row['Component 3'], row['SMILES'])\n",
        "                ax.set_xlabel('Component 1')\n",
        "                ax.set_ylabel('Component 2')\n",
        "                ax.set_zlabel('Component 3')\n",
        "                plt.legend()\n",
        "                descr = 'MACCS' if fp_type == 'maccs' else f'Morgan {n_bits} bits'\n",
        "                plt.title(f'Chemical Space from {descr} Fingerprints (TruncatedSVD), n.components={n}')\n",
        "            else:\n",
        "                print(f\"Cannot plot chemical space for {n} components.\")\n",
        "            plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eW7nQAa4PG76"
      },
      "source": [
        "## ML Models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define global dictionary for the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiments_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_results(result, result_name):\n",
        "    with open(os.path.join(checkpoint_dir, result_name + '.pkl'), 'wb') as fp:\n",
        "        pickle.dump(result, fp)\n",
        "        print(f'Results {result_name} saved successfully to file.')\n",
        "\n",
        "def load_result(result_name):\n",
        "    if not os.path.exists(os.path.join(checkpoint_dir, result_name + '.pkl')):\n",
        "        print(f'WARNING: File {result_name} not found.')\n",
        "        return {}\n",
        "    with open(os.path.join(checkpoint_dir, result_name + '.pkl'), 'rb') as fp:\n",
        "        return pickle.load(fp)\n",
        "\n",
        "def print_dict(title, d, filter_keys=True):\n",
        "    print(f'{title}')\n",
        "    filters = ['prediction', 'labels', 'logits', 'fpr', 'tpr', 'confusion']\n",
        "    for k, v in d.items():\n",
        "        if filter_keys:\n",
        "            if not any([f in k for f in filters]):\n",
        "                print(f'\\t* {k}: {v}')\n",
        "        else:\n",
        "            print(f'\\t* {k}: {v}')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup/Shared Functions"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_eval_results(model: nn.Module,\n",
        "                     task: str = 'predict_active_inactive',\n",
        "                     num_gpus: int = 0,\n",
        "                     return_logits: bool = True,\n",
        "                     return_logits_only: bool = False,\n",
        "                     phase: Literal['train', 'val', 'test'] = ['val', 'test'],\n",
        "                     run_lightning_eval: bool = True,\n",
        "                     trainer: pl.Trainer | None = None) -> dict:\n",
        "    \"\"\"Get predictions from a model.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Model to evaluate.\n",
        "        task (str, optional): Task to perform. Defaults to 'predict_pDC50_and_Dmax'.\n",
        "        num_gpus (int, optional): Number of available GPUs. Defaults to 0.\n",
        "        run_lightning_eval (bool, optional): Do not run Pytorch Lightning evaluation, useful for retrieving predictions only by setting it to False. Defaults to True.\n",
        "        return_logits (bool, optional): Return predictions, e.g., TPR, FPR, et cetera. Defaults to True.\n",
        "        trainer (pl.Trainer | None, optional): Pytorch Trainer to handle the evaluation. If not supplied it will automatically instantiated. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        dict: Collected evaluation results.\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() and num_gpus else 'cpu')\n",
        "    model.eval()\n",
        "    if num_gpus > 0:\n",
        "        model = model.to(device)\n",
        "    if trainer is None:\n",
        "        if torch.cuda.is_available() and num_gpus > 0:\n",
        "            pl_devices = math.ceil(num_gpus)\n",
        "            accelerator = 'gpu'\n",
        "            precision = '16-mixed'\n",
        "        else:\n",
        "            pl_devices = 4\n",
        "            accelerator = 'auto'\n",
        "            precision = '32'\n",
        "        trainer = pl.Trainer(accelerator=accelerator,\n",
        "                             devices=pl_devices,\n",
        "                             precision=precision,\n",
        "                             enable_checkpointing=False,\n",
        "                             enable_progress_bar=False,\n",
        "                             enable_model_summary=False)\n",
        "    # NOTE: \"The length of the list corresponds to the number of test\n",
        "    # dataloaders used.\"\n",
        "    eval_results = {}\n",
        "    if run_lightning_eval:\n",
        "        if 'val' in phase:\n",
        "            eval_results.update(trainer.validate(model, verbose=0)[0])\n",
        "        if 'test' in phase:\n",
        "            eval_results.update(trainer.test(model, verbose=0)[0])\n",
        "    # trainer.test(model, model.test_dataloader())\n",
        "    if task == 'predict_pDC50_and_Dmax':\n",
        "        # TODO: Regression task. Example:\n",
        "        # preds = torch.concat(trainer.predict(model, model.test_dataloader()))\n",
        "        # degradation_predictions = np.array(preds[:, 0])\n",
        "        # concentration_predictions = np.array(preds[:, 1])\n",
        "        # degradation_labels = np.array(model.test_dataset.Dmax)\n",
        "        # concentration_labels = np.array(model.test_dataset.pDC50)\n",
        "        pass\n",
        "    elif task == 'predict_active_inactive':\n",
        "        if return_logits:\n",
        "            def get_logits(ds_name):\n",
        "                ds = model.val_dataset if ds_name == 'val' else model.test_dataset\n",
        "                dl = DataLoader(ds, batch_size=model.batch_size, shuffle=False,\n",
        "                                collate_fn=custom_collate)\n",
        "                preds = torch.concat(trainer.predict(model, dl)).to(device)\n",
        "                if return_logits_only:\n",
        "                    ret = {f'{ds_name}_logits': preds.cpu().numpy()}\n",
        "                    return ret\n",
        "                print(f'Getting additional information for {ds_name} set')\n",
        "                y = torch.concat([batch['labels'] for batch in dl])\n",
        "                y = y.to(device)\n",
        "                # Obtain binary predictions and ROC curve\n",
        "                sigmoid = nn.Sigmoid().to(device)\n",
        "                roc = ROC(task='binary').to(device)\n",
        "                if torch.cuda.is_available() and num_gpus > 0:\n",
        "                    y = y.to(torch.half)\n",
        "                    preds = preds.to(torch.half)\n",
        "                    sigmoid = sigmoid.to(torch.half)\n",
        "                    roc = roc.to(torch.half)\n",
        "                bin_preds = sigmoid(preds) >= 0.5\n",
        "                fpr, tpr, _ = roc(preds, y.to(torch.long))\n",
        "                cm = confusion_matrix(y.cpu().numpy().astype(int),\n",
        "                                    bin_preds.cpu().numpy().astype(int))\n",
        "                ret = {\n",
        "                    f'{ds_name}_prediction': bin_preds.cpu().numpy().astype(int),\n",
        "                    f'{ds_name}_logits': preds.cpu().numpy(),\n",
        "                    f'{ds_name}_labels': y.cpu().numpy(),\n",
        "                    f'{ds_name}_fpr': fpr.cpu().numpy(),\n",
        "                    f'{ds_name}_tpr': tpr.cpu().numpy(),\n",
        "                    f'{ds_name}_confusion_matrix': cm,\n",
        "                }\n",
        "                return ret\n",
        "            if 'val' in phase:\n",
        "                eval_results.update(get_logits('val'))\n",
        "            if 'test' in phase:\n",
        "                eval_results.update(get_logits('test'))\n",
        "    return eval_results"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Functions to plot the models predictions against the true values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_eval_degradation(degr_pred, degr_labels, score, descr='', filename=None):\n",
        "    sorted_idx = np.argsort(degr_labels)\n",
        "    line_descr = f'{descr}Predicted degr.(%) - Loss: {score:.5f}'\n",
        "    plt.plot(degr_pred[sorted_idx], label=line_descr)\n",
        "    plt.plot(degr_labels[sorted_idx], label='Reference degradation (%)')\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
        "    plt.grid(alpha=0.8)\n",
        "    plt.xlabel('Test ID (sorted by degradation)')\n",
        "    plt.ylabel('Degradation (%)')\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "def plot_eval_concentration(conc_pred, conc_labels, score, descr='', filename=None):\n",
        "    sorted_idx = np.argsort(conc_labels)\n",
        "    line_descr = f'{descr}Predicted conc. (-log10(M)) - Loss: {score:.5f}'\n",
        "    plt.plot(conc_pred[sorted_idx], label=line_descr)\n",
        "    plt.plot(conc_labels[sorted_idx], label='Reference conc. (-log10(M))')\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
        "    plt.grid(alpha=0.8)\n",
        "    plt.xlabel('Test ID (sorted by concentration)')\n",
        "    plt.ylabel('Concentration (-log10(M))')\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()\n",
        "\n",
        "def plot_eval_classification(pred, labels, score, descr='', filename=None):\n",
        "    sorted_idx = np.argsort(labels)\n",
        "    line_descr = f'{descr}Predicted - Accuracy: {score * 100:.2f}%'\n",
        "    plt.plot(pred[sorted_idx], label=line_descr)\n",
        "    plt.plot(labels[sorted_idx], label='Reference')\n",
        "    # dummy_acc = labels[labels > 0].sum() / len(labels)\n",
        "    # line_descr = f'Dummy Accuracy: {dummy_acc * 100:.2f}%'\n",
        "    # plt.plot([dummy_acc] * len(labels), '--', label=line_descr, color='black')\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
        "    plt.grid(alpha=0.8)\n",
        "    plt.xlabel('Test ID (sorted by activity)')\n",
        "    plt.ylabel('Active/Inactive')\n",
        "    if filename is not None:\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remove non-optimal models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, isdir, join\n",
        "\n",
        "def del_non_optimal_ckpt(checkpoint_root_dir: str, best_trial_names: List,\n",
        "                         model_name: str, logs_root_dir: str | None = None,\n",
        "                         verbose: int = 0):\n",
        "    \"\"\"Delete all checkpoints that are not the best ones.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_root_dir (str): Checkpoint root directory.\n",
        "        best_trial_names (List): List of best checkpoints.\n",
        "        model_name (str): Remove all checkpoints that contain this string.\n",
        "    \"\"\"\n",
        "    all_ckpt = [f for f in listdir(checkpoint_root_dir) if isfile(join(checkpoint_root_dir, f)) or isdir(join(checkpoint_root_dir, f))]\n",
        "    for ckpt in all_ckpt:\n",
        "        if not any([trial in ckpt for trial in best_trial_names]):\n",
        "            if model_name in ckpt:\n",
        "                filepath = os.path.join(checkpoint_root_dir, ckpt)\n",
        "                if verbose:\n",
        "                    print(f'Removing {filepath}')\n",
        "                if os.path.isdir(filepath):\n",
        "                    shutil.rmtree(filepath)\n",
        "                elif os.path.isfile(filepath):\n",
        "                    os.remove(filepath)\n",
        "                else:\n",
        "                    print(f'WARNING. \"{filepath}\" is a special file (socket, FIFO, device file)')\n",
        "    if logs_root_dir is not None:\n",
        "        all_logs = [f for f in listdir(logs_root_dir) if isfile(join(logs_root_dir, f)) or isdir(join(logs_root_dir, f))]\n",
        "        for logf in all_logs:\n",
        "            if not any([f'logs_{trial}' in logf for trial in best_trial_names]):\n",
        "                if model_name in logf:\n",
        "                    filepath = os.path.join(logs_root_dir, logf)\n",
        "                    if verbose:\n",
        "                        print(f'Removing {filepath}')\n",
        "                    if os.path.isdir(filepath):\n",
        "                        shutil.rmtree(filepath)\n",
        "                    elif os.path.isfile(filepath):\n",
        "                        os.remove(filepath)\n",
        "                    else:  \n",
        "                        print(f'WARNING. \"{filepath}\" is a special file (socket, FIFO, device file)')\n",
        "        "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ray Tune generic function to tune hyperparameters, given a trainable function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tune_model(train_fn_with_parameters: Callable,\n",
        "               config: dict,\n",
        "               num_epochs: int = 10,\n",
        "               num_samples: int = 10,\n",
        "               task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_pDC50_and_Dmax',\n",
        "               ray_local_dir: str = os.path.join(checkpoint_dir, 'ray'),\n",
        "               ray_run_name: str = 'tune_model',\n",
        "               params2report: List[str] | None = None,\n",
        "               gpus_per_trial: int = 0):\n",
        "    \"\"\"Tune hyperparameters of a model using Ray Tune.\n",
        "\n",
        "    Args:\n",
        "        train_fn_with_parameters (Callable): Trainable function that takes a dictionary of hyperparameters as input and returns a dictionary of metrics.\n",
        "        config (dict): Dictionary of hyperparameters to tune.\n",
        "        num_epochs (int, optional): Number of epochs to train. Defaults to 10.\n",
        "        num_samples (int, optional): Number of samples to explore/run in Ray Tune. Defaults to 10.\n",
        "        task (Literal[&#39;predict_active_inactive&#39;, &#39;predict_pDC50&#39;, &#39;predict_pDC50_and_Dmax&#39;], optional): Task to train the model for. Defaults to 'predict_pDC50_and_Dmax'.\n",
        "        ray_local_dir (str, optional): Ray checkpoint directory. Defaults to os.path.join(checkpoint_dir, 'ray').\n",
        "        ray_run_name (str, optional): Run-specific name. Defaults to 'tune_model'.\n",
        "        params2report (List[str] | None, optional): Parameters to report in logging. Defaults to None.\n",
        "        gpus_per_trial (int, optional): GPUs per single trial. Defaults to 0.\n",
        "\n",
        "    Returns:\n",
        "        ResultGrid: Ray Tune result grid wrapper.\n",
        "    \"\"\"\n",
        "    optim_metric = 'opt_score' if task == 'predict_active_inactive' else 'val_loss'\n",
        "    # optim_metric = 'acc' if task == 'predict_active_inactive' else 'loss'\n",
        "    optim_mode = 'max' if task == 'predict_active_inactive' else 'min'\n",
        "    # Setup reporting and logging\n",
        "    if task == 'predict_active_inactive':\n",
        "        metric_columns = [\n",
        "            'val_loss',\n",
        "            'val_acc',\n",
        "            'roc_auc',\n",
        "            'precision',\n",
        "            'recall',\n",
        "            'f1_score',\n",
        "            'training_iteration'\n",
        "        ]\n",
        "    else:\n",
        "        metric_columns = ['val_loss', 'training_iteration']\n",
        "    params2report = config.keys() if params2report is None else params2report\n",
        "    reporter = CLIReporter(\n",
        "        parameter_columns=params2report,\n",
        "        metric_columns=metric_columns,\n",
        "        # metric=optim_metric,\n",
        "        # mode=optim_mode,\n",
        "        # sort_by_metric=True,\n",
        "        )\n",
        "    # Setup scheduler\n",
        "    # scheduler = HyperBandScheduler(time_attr='training_iteration', max_t=200)\n",
        "    scheduler = ASHAScheduler(\n",
        "        max_t=num_epochs,\n",
        "        grace_period=1,\n",
        "        reduction_factor=2)\n",
        "    # Instantiate Ray Tune Tuner\n",
        "    tuner = tune.Tuner(\n",
        "        tune.with_resources(\n",
        "            train_fn_with_parameters,\n",
        "            resources={'cpu': 1, 'gpu': gpus_per_trial}\n",
        "        ),\n",
        "        tune_config=tune.TuneConfig(\n",
        "            metric=optim_metric,\n",
        "            mode=optim_mode,\n",
        "            scheduler=scheduler,\n",
        "            search_alg=ConcurrencyLimiter(OptunaSearch(), max_concurrent=8),\n",
        "            num_samples=num_samples\n",
        "        ),\n",
        "        run_config=air.RunConfig(\n",
        "            local_dir=ray_local_dir,\n",
        "            name=ray_run_name,\n",
        "            progress_reporter=reporter,\n",
        "            verbose=0, # Default: (Comment this line)\n",
        "            checkpoint_config=air.CheckpointConfig(\n",
        "                num_to_keep=1,\n",
        "                checkpoint_score_attribute=optim_metric,\n",
        "                checkpoint_score_order=optim_mode)\n",
        "        ),\n",
        "        param_space=config,\n",
        "    )\n",
        "    results = tuner.fit()\n",
        "    print(f'Best hyperparameters found were:')\n",
        "    for k, v in results.get_best_result().config.items():\n",
        "        print(f'\\t* {k}: {v}')\n",
        "    print(f'\\nBest metrics achieved:')\n",
        "    for k, v in results.get_best_result().metrics.items():\n",
        "        print(f'\\t* {k}: {v}')\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPxnQ6ihbQXi"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "\n",
        "# !export RAY_RUNTIME_ENV_WORKING_DIR_CACHE_SIZE_GB=0\n",
        "\n",
        "# ray.shutdown()\n",
        "# ray.init(runtime_env={'working_dir': '.', 'excludes': ['data/protac', 'data/protac/*.pt']}, logging_level=logging.ERROR)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom PytorchLightning Callbacks"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optuna pruning callback:\n",
        "\n",
        "(It needed to be adapted to the current version of PytorchLightning. Luckily, only one line was changed, hopefully maintaining the same functionality)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "from packaging import version\n",
        "\n",
        "import optuna\n",
        "from optuna.storages._cached_storage import _CachedStorage\n",
        "from optuna.storages._rdb.storage import RDBStorage\n",
        "\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "\n",
        "# Define key names of `Trial.system_attrs`.\n",
        "_PRUNED_KEY = \"ddp_pl:pruned\"\n",
        "_EPOCH_KEY = \"ddp_pl:epoch\"\n",
        "\n",
        "class CustomPyTorchLightningPruningCallback(Callback):\n",
        "    \"\"\"PyTorch Lightning callback to prune unpromising trials.\n",
        "\n",
        "    See `the example <https://github.com/optuna/optuna-examples/blob/\n",
        "    main/pytorch/pytorch_lightning_simple.py>`__\n",
        "    if you want to add a pruning callback which observes accuracy.\n",
        "\n",
        "    Args:\n",
        "        trial:\n",
        "            A :class:`~optuna.trial.Trial` corresponding to the current evaluation of the\n",
        "            objective function.\n",
        "        monitor:\n",
        "            An evaluation metric for pruning, e.g., ``val_loss`` or\n",
        "            ``val_acc``. The metrics are obtained from the returned dictionaries from e.g.\n",
        "            ``pytorch_lightning.LightningModule.training_step`` or\n",
        "            ``pytorch_lightning.LightningModule.validation_epoch_end`` and the names thus depend on\n",
        "            how this dictionary is formatted.\n",
        "\n",
        "    .. note::\n",
        "        For the distributed data parallel training, the version of PyTorchLightning needs to be\n",
        "        higher than or equal to v1.5.0. In addition, :class:`~optuna.study.Study` should be\n",
        "        instantiated with RDB storage.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, trial: optuna.trial.Trial, monitor: str) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self._trial = trial\n",
        "        self.monitor = monitor\n",
        "        self.is_ddp_backend = False\n",
        "\n",
        "    def on_init_start(self, trainer: Trainer) -> None:\n",
        "        self.is_ddp_backend = (\n",
        "            trainer._accelerator_connector.distributed_backend is not None  # type: ignore\n",
        "        )\n",
        "        if self.is_ddp_backend:\n",
        "            if version.parse(pl.__version__) < version.parse(\"1.5.0\"):  # type: ignore\n",
        "                raise ValueError(\"PyTorch Lightning>=1.5.0 is required in DDP.\")\n",
        "            if not (\n",
        "                isinstance(self._trial.study._storage, _CachedStorage)\n",
        "                and isinstance(self._trial.study._storage._backend, RDBStorage)\n",
        "            ):\n",
        "                raise ValueError(\n",
        "                    \"optuna.integration.PyTorchLightningPruningCallback\"\n",
        "                    \" supports only optuna.storages.RDBStorage in DDP.\"\n",
        "                )\n",
        "\n",
        "    def on_validation_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
        "\n",
        "        # When the trainer calls `on_validation_end` for sanity check,\n",
        "        # do not call `trial.report` to avoid calling `trial.report` multiple times\n",
        "        # at epoch 0. The related page is\n",
        "        # https://github.com/PyTorchLightning/pytorch-lightning/issues/1391.\n",
        "        if trainer.sanity_checking:\n",
        "            return\n",
        "\n",
        "        epoch = pl_module.current_epoch\n",
        "\n",
        "        current_score = trainer.callback_metrics.get(self.monitor)\n",
        "        if current_score is None:\n",
        "            message = (\n",
        "                \"The metric '{}' is not in the evaluation logs for pruning. \"\n",
        "                \"Please make sure you set the correct metric name.\".format(self.monitor)\n",
        "            )\n",
        "            warnings.warn(message)\n",
        "            return\n",
        "\n",
        "        should_stop = False\n",
        "        if trainer.is_global_zero:\n",
        "            self._trial.report(current_score.item(), step=epoch)\n",
        "            should_stop = self._trial.should_prune()\n",
        "        # TODO: The following line breaks the current version of Pytorch\n",
        "        # Lightning. But I suspect it's necessary in a distributed training\n",
        "        # environment... so it shouldn't matter for us...\n",
        "        # should_stop = trainer.training_type_plugin.broadcast(should_stop)\n",
        "        trainer.should_stop = should_stop\n",
        "        if not should_stop:\n",
        "            return\n",
        "\n",
        "        if not self.is_ddp_backend:\n",
        "            message = \"Trial was pruned at epoch {}.\".format(epoch)\n",
        "            raise optuna.TrialPruned(message)\n",
        "        else:\n",
        "            # Stop every DDP process if global rank 0 process decides to stop.\n",
        "            trainer.should_stop = True\n",
        "            if trainer.is_global_zero:\n",
        "                self._trial.storage.set_trial_system_attr(self._trial._trial_id, _PRUNED_KEY, True)\n",
        "                self._trial.storage.set_trial_system_attr(self._trial._trial_id, _EPOCH_KEY, epoch)\n",
        "\n",
        "    def on_fit_end(self, trainer: Trainer, pl_module: LightningModule) -> None:\n",
        "        if not self.is_ddp_backend:\n",
        "            return\n",
        "\n",
        "        # Because on_validation_end is executed in spawned processes,\n",
        "        # _trial.report is necessary to update the memory in main process, not to update the RDB.\n",
        "        _trial_id = self._trial._trial_id\n",
        "        _study = self._trial.study\n",
        "        _trial = _study._storage._backend.get_trial(_trial_id)  # type: ignore\n",
        "        _trial_system_attrs = _study._storage.get_trial_system_attrs(_trial_id)\n",
        "        is_pruned = _trial_system_attrs.get(_PRUNED_KEY)\n",
        "        epoch = _trial_system_attrs.get(_EPOCH_KEY)\n",
        "        intermediate_values = _trial.intermediate_values\n",
        "        for step, value in intermediate_values.items():\n",
        "            self._trial.report(value, step=step)\n",
        "\n",
        "        if is_pruned:\n",
        "            message = \"Trial was pruned at epoch {}.\".format(epoch)\n",
        "            raise optuna.TrialPruned(message)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thresholded early stopping callback:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks import Callback\n",
        "\n",
        "class ThresholdEarlyStopping(Callback):\n",
        "    \"\"\"PyTorch Lightning callback to stop training when a metric decreases after\n",
        "    having reached a threshold.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, monitor: str = 'val_acc', threshold: float = 0.9):\n",
        "        super().__init__()\n",
        "        self.monitor = monitor\n",
        "        self.threshold = threshold\n",
        "        self.reached_threshold = False\n",
        "\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        metrics = trainer.callback_metrics\n",
        "        score = metrics.get(self.monitor)\n",
        "\n",
        "        if score is not None:\n",
        "            if not self.reached_threshold and score >= self.threshold:\n",
        "                self.reached_threshold = True\n",
        "                # print(f\"Metric {self.monitor} reached the threshold ({self.threshold}).\")\n",
        "            elif self.reached_threshold and score < self.threshold:\n",
        "                trainer.should_stop = True\n",
        "                # print(f\"Metric {self.monitor} dropped below the threshold ({self.threshold}). Training will be stopped.\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate specific datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "fp_bits_options = [1024, 2048, 4096]\n",
        "upsampled = [False] # [True, False]\n",
        "fp_max_paths = list(range(8, 11))\n",
        "radii = list(range(2, 11))\n",
        "use_extra_features = [True, False]\n",
        "experiments = (tasks, fp_bits_options, fp_max_paths, radii, upsampled, use_extra_features)\n",
        "\n",
        "for subset in tqdm(list(itertools.product(*experiments))):\n",
        "    task, fp_bits, fp_max_path, radius, use_upsampled, use_extra_features = subset\n",
        "    protac_ds_kwargs = {\n",
        "        'precompute_fingerprints': True,\n",
        "        'use_morgan_fp': True,\n",
        "        'use_maccs_fp': True,\n",
        "        'use_path_fp': True,\n",
        "        'morgan_atomic_radius': radius,\n",
        "        'morgan_bits': fp_bits,\n",
        "        'path_bits': fp_bits,\n",
        "        'fp_min_path': 1,\n",
        "        'fp_max_path': fp_max_path,\n",
        "        'poi_gene_enc': poi_gene_enc,\n",
        "        'poi_vectorizer': poi_encoder, # poi_vectorizer,\n",
        "        'e3_ligase_enc': e3_encoder, # e3_ligase_enc,\n",
        "        'cell_type_enc': cell_encoder, # cell_type_enc,\n",
        "    }\n",
        "    dataset_name = f'_fp{fp_bits}_radius{radius}_path1-{fp_max_path}'\n",
        "    get_datasets(task,\n",
        "                 use_upsampled,\n",
        "                 dataset_name=dataset_name,\n",
        "                 regenerate_datasets=False,\n",
        "                 **protac_ds_kwargs)\n",
        "    # print(f'Finished generating \"protac-db{dataset_name}\" datasets.')\n",
        "print('Datasets are ready to use.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Optuna objective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from optuna.integration import XGBoostPruningCallback\n",
        "\n",
        "def xgb_objective(trial,\n",
        "                  fp_bits: int,\n",
        "                  num_round: int = 10,\n",
        "                  use_extra_features: bool | None = None,\n",
        "                  task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive'):\n",
        "    # Inspired by: https://github.com/optuna/optuna-examples/blob/main/xgboost/xgboost_integration.py\n",
        "    config = {\n",
        "        # Fingerprint-specific\n",
        "        'fp_type': trial.suggest_categorical('fp_type', ['morgan_fp', 'maccs_fp', 'path_fp']),\n",
        "        'fp_radius': trial.suggest_int('fp_radius', 2, 10),\n",
        "        'fp_max_path': trial.suggest_int('fp_max_path', 8, 10),\n",
        "        # XGBoost-specific\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
        "    }\n",
        "    if config['booster'] == 'gbtree' or config['booster'] == 'dart':\n",
        "        config['max_depth'] = trial.suggest_int('max_depth', 1, 16)\n",
        "        config['eta'] = trial.suggest_float('eta', 1e-8, 1.0, log=True)\n",
        "        config['gamma'] = trial.suggest_float('gamma', 1e-8, 1.0, log=True)\n",
        "        config['grow_policy'] = trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide'])\n",
        "    if config['booster'] == 'dart':\n",
        "        config['sample_type'] = trial.suggest_categorical('sample_type', ['uniform', 'weighted'])\n",
        "        config['normalize_type'] = trial.suggest_categorical('normalize_type', ['tree', 'forest'])\n",
        "        config['rate_drop'] = trial.suggest_float('rate_drop', 1e-8, 1.0, log=True)\n",
        "        config['skip_drop'] = trial.suggest_float('skip_drop', 1e-8, 1.0, log=True)\n",
        "    if use_extra_features is None:\n",
        "        config['fp_use_extra_features'] = trial.suggest_categorical('fp_use_extra_features', [True, False])\n",
        "    else:\n",
        "        config['fp_use_extra_features'] = use_extra_features\n",
        "    # Reporting\n",
        "    model_name = 'xgb_model'\n",
        "    fp_bits = MACCS_BITWIDTH if config['fp_type'] == 'maccs_fp' else fp_bits\n",
        "    eventid = f'{trial.datetime_start.strftime(\"%Y%m-%d%H-%M%S-\")}{uuid4()}'\n",
        "    trial_name = f'{config[\"fp_type\"]}-{fp_bits}-{trial.number}-{eventid}'    \n",
        "    model_checkpoint_dir = os.path.join(checkpoint_dir, 'xgboost')\n",
        "    model_checkpoint = f'{model_name}-{trial_name}.bin'\n",
        "    trial.set_user_attr('trial_name', trial_name)\n",
        "    trial.set_user_attr('model_checkpoint', model_checkpoint)\n",
        "    trial.set_user_attr('model_checkpoint_dir', model_checkpoint_dir)\n",
        "    trial.set_user_attr('model_name', model_name)\n",
        "    # Retrieve specific datasets\n",
        "    tmp = 1024 if config['fp_type'] == 'maccs_fp' else fp_bits\n",
        "    dataset_name = f'_fp{tmp}_radius{config[\"fp_radius\"]}_path1-{config[\"fp_max_path\"]}'\n",
        "    trial.set_user_attr('dataset_name', dataset_name)\n",
        "    ds = get_datasets(task, use_upsampled, dataset_name=dataset_name)\n",
        "    train_ds = ds['train']\n",
        "    val_ds = ds['val']\n",
        "    test_ds = ds['test']\n",
        "    # Setup XGBoost-specific datasets\n",
        "    train_fp_data = train_ds.get_fingerprint(config['fp_type'])\n",
        "    val_fp_data = val_ds.get_fingerprint(config['fp_type'])\n",
        "    test_fp_data = test_ds.get_fingerprint(config['fp_type'])\n",
        "    if config['fp_use_extra_features']:\n",
        "        # Get POI sequence\n",
        "        poi_seq_train = train_ds.poi_vectorizer.transform(train_ds.poi_seq)\n",
        "        poi_seq_val = val_ds.poi_vectorizer.transform(val_ds.poi_seq)\n",
        "        poi_seq_test = test_ds.poi_vectorizer.transform(test_ds.poi_seq)\n",
        "        poi_seq_train = poi_seq_train.toarray().astype(np.int32)\n",
        "        poi_seq_val = poi_seq_val.toarray().astype(np.int32)\n",
        "        poi_seq_test = poi_seq_test.toarray().astype(np.int32)\n",
        "        # Concatenate extra features\n",
        "        train_fp_data = np.concatenate([\n",
        "                                        train_fp_data,\n",
        "                                        np.array(train_ds.e3_ligase)[:, np.newaxis],\n",
        "                                        np.array(train_ds.cell_type)[:, np.newaxis],\n",
        "                                        poi_seq_train,\n",
        "                                        ], axis=-1)\n",
        "        test_fp_data = np.concatenate([\n",
        "                                        test_fp_data,\n",
        "                                        np.array(test_ds.e3_ligase)[:, np.newaxis],\n",
        "                                        np.array(test_ds.cell_type)[:, np.newaxis],\n",
        "                                        poi_seq_test,\n",
        "                                        ], axis=-1)\n",
        "        val_fp_data = np.concatenate([\n",
        "                                        val_fp_data,\n",
        "                                        np.array(val_ds.e3_ligase)[:, np.newaxis],\n",
        "                                        np.array(val_ds.cell_type)[:, np.newaxis],\n",
        "                                        poi_seq_val,\n",
        "                                        ], axis=-1)\n",
        "    dtrain = xgb.DMatrix(train_fp_data, label=train_ds.active)\n",
        "    dtest = xgb.DMatrix(test_fp_data, label=test_ds.active)\n",
        "    dval = xgb.DMatrix(val_fp_data, label=val_ds.active)\n",
        "    # Setup XGBoost-specific parameters\n",
        "    xgb_params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': ['logloss', 'auc'],\n",
        "        'seed': 42,\n",
        "        'verbosity': 0,\n",
        "        'silent': True,\n",
        "    }\n",
        "    xgb_params.update({k: config[k] for k in config.keys() if 'fp_' not in k})\n",
        "    evallist = [(dtrain, 'train'), (dval, 'eval')]\n",
        "    # Setup Optuna callback\n",
        "    pruning_callback = XGBoostPruningCallback(trial, 'eval-auc')\n",
        "    # Train XGBoost model via its training function\n",
        "    bst = xgb.train(params=xgb_params,\n",
        "                    dtrain=dtrain,\n",
        "                    num_boost_round=num_round,\n",
        "                    evals=evallist,\n",
        "                    early_stopping_rounds=5,\n",
        "                    callbacks=[pruning_callback],\n",
        "                    verbose_eval=False)\n",
        "    bst.save_model(os.path.join(model_checkpoint_dir, model_checkpoint))\n",
        "    # Get and report score metrics\n",
        "    def get_scores(phase):\n",
        "        ds = val_ds if phase == 'val' else test_ds\n",
        "        y = torch.tensor(ds.active.to_numpy()).flatten()\n",
        "        dxgb = dval if phase == 'val' else dtest\n",
        "        preds = torch.tensor(bst.predict(dxgb)).flatten()\n",
        "        acc = binary_accuracy(preds, y, threshold=0.5).cpu().numpy()\n",
        "        roc_auc = binary_auroc(preds, y.to(torch.long)).cpu().numpy()\n",
        "        precision = binary_precision(preds, y.to(torch.long)).cpu().numpy()\n",
        "        recall = binary_recall(preds, y.to(torch.long)).cpu().numpy()\n",
        "        f1_score = binary_f1_score(preds, y).cpu().numpy()\n",
        "        trial.set_user_attr(f'{phase}_acc', acc)\n",
        "        trial.set_user_attr(f'{phase}_roc_auc', roc_auc)\n",
        "        trial.set_user_attr(f'{phase}_precision', precision)\n",
        "        trial.set_user_attr(f'{phase}_recall', recall)\n",
        "        trial.set_user_attr(f'{phase}_f1_score', f1_score)\n",
        "        opt_score = acc + roc_auc\n",
        "        return opt_score\n",
        "    get_scores('test')\n",
        "    return get_scores('val')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run experiments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(os.path.join(checkpoint_dir, 'xgboost')):\n",
        "    os.makedirs(os.path.join(checkpoint_dir, 'xgboost'))\n",
        "\n",
        "# Define experiments design points\n",
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "fp_bits_options = [1024, 2048, 4096]\n",
        "upsampled = [False] # [True, False]\n",
        "use_extra_features = [True, False]\n",
        "experiments = (tasks, fp_bits_options, upsampled, use_extra_features)\n",
        "# Get all experiments combinations\n",
        "n_experiments = 0\n",
        "for subset in itertools.product(*experiments):\n",
        "    task, fp_bits, use_upsampled, use_extra_features = subset\n",
        "    if use_upsampled and task != 'predict_active_inactive':\n",
        "        continue\n",
        "    n_experiments += 1\n",
        "# Set fixed parameters\n",
        "num_round = 20\n",
        "num_samples = 50\n",
        "n_gpus = 1 if torch.cuda.is_available() else 0\n",
        "# Define specific results dictionary in the global one\n",
        "experiments_results['results_xgb'] = load_result('results_xgb')\n",
        "if RETRAIN_XGBOOST or not experiments_results['results_xgb']:\n",
        "    # Run experiments\n",
        "    pl.utilities.memory.garbage_collection_cuda()\n",
        "    i = 0\n",
        "    best_ckpt = []\n",
        "    for experiment_id in itertools.product(*experiments):\n",
        "        task, fp_bits, use_upsampled, use_extra_features = experiment_id\n",
        "        if use_upsampled and task != 'predict_active_inactive':\n",
        "            continue\n",
        "        print(f'-' * 80)\n",
        "        print(f'Experiment n.{i + 1} ({i / n_experiments * 100.0:.2f}% complete):')\n",
        "        print(f'\\ttask: {task}')\n",
        "        print(f'\\tfp_bits: {fp_bits}')\n",
        "        print(f'\\tuse_upsampled: {use_upsampled}')\n",
        "        print(f'-' * 80)\n",
        "        # Run Optuna study\n",
        "        direction = 'maximize' if task == 'predict_active_inactive' else 'minimize'\n",
        "        # optuna_pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
        "        optuna_pruner = optuna.pruners.HyperbandPruner(min_resource=5,\n",
        "                                                       max_resource=num_round,\n",
        "                                                       reduction_factor=3)\n",
        "        optuna_sampler = optuna.samplers.TPESampler(seed=42)\n",
        "        study = optuna.create_study(direction=direction,\n",
        "                                    pruner=optuna_pruner,\n",
        "                                    sampler=optuna_sampler)\n",
        "        study.optimize(lambda trial: xgb_objective(trial,\n",
        "                                                task=task,\n",
        "                                                fp_bits=fp_bits,\n",
        "                                                use_extra_features=use_extra_features,\n",
        "                                                num_round=num_round),\n",
        "                    n_trials=num_samples,\n",
        "                    timeout=600)\n",
        "        trial = study.best_trial\n",
        "        experiments_results['results_xgb'][experiment_id] = {}\n",
        "        experiments_results['results_xgb'][experiment_id]['trial'] = trial\n",
        "        experiments_results['results_xgb'][experiment_id]['fp_bits'] = fp_bits\n",
        "        experiments_results['results_xgb'][experiment_id]['task'] = task\n",
        "        experiments_results['results_xgb'][experiment_id]['use_upsampled'] = use_upsampled\n",
        "        experiments_results['results_xgb'][experiment_id]['use_extra_features'] = use_extra_features\n",
        "        # Reporting\n",
        "        print('-' * 80)\n",
        "        print(f'Experiment n.{i + 1} done ({(i + 1) / n_experiments * 100.0:.2f}% complete)')\n",
        "        print('Number of finished trials: {}'.format(len(study.trials)))\n",
        "        print(f'Best trial score: {trial.value}:')\n",
        "        print_dict('Experiment:', experiments_results['results_xgb'][experiment_id])\n",
        "        print_dict('Params:', trial.params)\n",
        "        print_dict('Attributes:', trial.user_attrs)\n",
        "        i += 1\n",
        "        # Remove non-optimal checkpoints\n",
        "        model_name = trial.user_attrs['model_name']\n",
        "        checkpoint_root_dir = trial.user_attrs['model_checkpoint_dir']\n",
        "        best_ckpt.append(trial.user_attrs['trial_name'])\n",
        "        del_non_optimal_ckpt(checkpoint_root_dir, best_ckpt, model_name)\n",
        "    # Save results\n",
        "    save_results(experiments_results['results_xgb'], result_name='results_xgb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for experiment_id, design_points in experiments_results['results_xgb'].items():\n",
        "    task = design_points['task']\n",
        "    trial = design_points['trial']\n",
        "    print(f'Experiment: {experiment_id}')\n",
        "    print_dict('Hyperparams:', trial.params)\n",
        "    print_dict('Attributes:', trial.user_attrs)\n",
        "    model = xgb.Booster()\n",
        "    model_checkpoint_dir = trial.user_attrs['model_checkpoint_dir']\n",
        "    model_checkpoint = trial.user_attrs['model_checkpoint']\n",
        "    model.load_model(os.path.join(model_checkpoint_dir, model_checkpoint))\n",
        "    print('-' * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for experiment_id, design_points in experiments_results['results_xgb'].items():\n",
        "    task = design_points['task']\n",
        "    trial = design_points['trial']\n",
        "    print(f'Experiment: {experiment_id}')\n",
        "    print_dict('Hyperparams:', trial.params)\n",
        "    print_dict('Attributes:', trial.user_attrs)\n",
        "    model = xgb.Booster()\n",
        "    model_checkpoint_dir = trial.user_attrs['model_checkpoint_dir']\n",
        "    model_checkpoint = trial.user_attrs['model_checkpoint']\n",
        "    model.load_model(os.path.join(model_checkpoint_dir, model_checkpoint))\n",
        "    print('-' * 80)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auc_results = {}\n",
        "confusion_matrices = {}\n",
        "\n",
        "for experiment_id, design_points in experiments_results['results_xgb'].items():\n",
        "    task = design_points['task']\n",
        "    trial = design_points['trial']\n",
        "    fp_bits = design_points['fp_bits']\n",
        "    use_upsampled = design_points['use_upsampled']\n",
        "    # Retrieve specific datasets\n",
        "    ds = get_datasets(task,\n",
        "                      use_upsampled,\n",
        "                      dataset_name=trial.user_attrs['dataset_name'],\n",
        "                      regenerate_datasets=False,\n",
        "                      **protac_ds_kwargs)\n",
        "    train_ds = ds['train']\n",
        "    val_ds = ds['val']\n",
        "    test_ds = ds['test']\n",
        "    # Load model\n",
        "    model_checkpoint_dir = trial.user_attrs['model_checkpoint_dir']\n",
        "    model_checkpoint = trial.user_attrs['model_checkpoint']\n",
        "    best_model = xgb.Booster()\n",
        "    best_model.load_model(os.path.join(model_checkpoint_dir, model_checkpoint))\n",
        "    # Setup XGBoost-specific datasets\n",
        "    test_fp_data = test_ds.get_fingerprint(trial.params['fp_type'])\n",
        "    val_fp_data = val_ds.get_fingerprint(trial.params['fp_type'])\n",
        "    if trial.params.get('fp_use_extra_features', False) or design_points.get('use_extra_features', False):\n",
        "        use_extra_features = True\n",
        "        poi_seq_train = train_ds.poi_vectorizer.transform(train_ds.poi_seq)\n",
        "        poi_seq_val = val_ds.poi_vectorizer.transform(val_ds.poi_seq)\n",
        "        poi_seq_test = test_ds.poi_vectorizer.transform(test_ds.poi_seq)\n",
        "        poi_seq_train = poi_seq_train.toarray().astype(np.int32)\n",
        "        poi_seq_val = poi_seq_val.toarray().astype(np.int32)\n",
        "        poi_seq_test = poi_seq_test.toarray().astype(np.int32)\n",
        "        test_fp_data = np.concatenate([\n",
        "            test_fp_data,\n",
        "            np.array(test_ds.e3_ligase)[:, np.newaxis],\n",
        "            np.array(test_ds.cell_type)[:, np.newaxis],\n",
        "            poi_seq_test,\n",
        "        ], axis=-1)\n",
        "        val_fp_data = np.concatenate([\n",
        "            val_fp_data,\n",
        "            np.array(val_ds.e3_ligase)[:, np.newaxis],\n",
        "            np.array(val_ds.cell_type)[:, np.newaxis],\n",
        "            poi_seq_val,\n",
        "        ], axis=-1)\n",
        "    else:\n",
        "        use_extra_features = False\n",
        "    auc_results[experiment_id] = {}\n",
        "    for phase in ['val', 'test']:\n",
        "        if phase == 'val':\n",
        "            bin_labels = val_ds.active.to_numpy().flatten()\n",
        "            dval = xgb.DMatrix(val_fp_data, label=val_ds.active)\n",
        "            # Get predictions\n",
        "            logits = best_model.predict(dval, iteration_range=(0, best_model.best_iteration + 1)).flatten()\n",
        "        if phase == 'test':\n",
        "            bin_labels = test_ds.active.to_numpy().flatten()\n",
        "            dtest = xgb.DMatrix(test_fp_data, label=test_ds.active)\n",
        "            # Get predictions\n",
        "            logits = best_model.predict(dtest, iteration_range=(0, best_model.best_iteration + 1)).flatten()\n",
        "        # Plot results\n",
        "        fp_type = trial.params['fp_type']\n",
        "        if task == 'predict_pDC50_and_Dmax':\n",
        "            pass\n",
        "        elif task == 'predict_pDC50':\n",
        "            pass\n",
        "        elif task == 'predict_active_inactive':\n",
        "            bin_pred = logits >= 0.5\n",
        "            descr = f'XGBoost [{fp_type.replace(\"_fp\", \"\").upper()} {fp_bits}bits'\n",
        "            descr += f'{\" + Extra Feat.]\" if use_extra_features else \"]\"}'\n",
        "            # Get confusion matrix data\n",
        "            cm = confusion_matrix(bin_labels.flatten().astype(int),\n",
        "                                bin_pred.flatten().astype(int))\n",
        "            confusion_matrices[experiment_id] = (ConfusionMatrixDisplay(cm), descr)\n",
        "            # Get ROC AUC data\n",
        "            fpr, tpr, _ = sklearn.metrics.roc_curve(bin_labels.flatten(), logits)\n",
        "            auc = sklearn.metrics.auc(fpr, tpr)\n",
        "            auc_results[experiment_id][phase] = (fpr, tpr, auc)\n",
        "print('All evaluation results gathered.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot ROC-AUC curve and confusion matrixes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for phase in ['val', 'test']:\n",
        "    # Dummy classifier\n",
        "    dummy_pred = torch.tensor([1.0] * len(bin_labels))\n",
        "    fpr, tpr, _ = sklearn.metrics.roc_curve(bin_labels.flatten(), dummy_pred)\n",
        "    auc = sklearn.metrics.roc_auc_score(bin_labels.flatten(), dummy_pred)\n",
        "    acc = binary_accuracy(dummy_pred, torch.tensor(bin_labels), threshold=0.5)\n",
        "    plt.plot(fpr, tpr, label=f'Dummy (AUC = {auc:.2f}, Accuracy = {acc * 100:.2f}%)', color='black', lw=0.8, linestyle='--')\n",
        "\n",
        "    # Plot other models results\n",
        "    for experiment_id, design_points in experiments_results['results_xgb'].items():\n",
        "        task = design_points['task']\n",
        "        trial = design_points['trial']\n",
        "        fp_bits = design_points['fp_bits']\n",
        "        use_upsampled = design_points['use_upsampled']\n",
        "        if task != 'predict_active_inactive':\n",
        "            continue\n",
        "        fp_type = trial.params['fp_type']\n",
        "        acc = trial.user_attrs[f'{phase}_acc']\n",
        "        fpr, tpr, auc = auc_results[experiment_id][phase]\n",
        "\n",
        "        if trial.params.get('fp_use_extra_features', False) or design_points.get('use_extra_features', False):\n",
        "            use_extra_features = True\n",
        "        else:\n",
        "            use_extra_features = False\n",
        "        descr = f'XGBoost [{fp_type.replace(\"_fp\", \"\").upper()} {fp_bits}bits'\n",
        "        descr += f'{\" + Extra Feat.]\" if use_extra_features else \"]\"}'\n",
        "        plt.plot(fpr, tpr, label=f'{descr} (AUC: {auc:.2f}, Accuracy: {acc * 100:.2f}%)')\n",
        "    plt.grid('both', alpha=0.7)\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1, fancybox=True) #, shadow=True)\n",
        "    plt.title(f'XGBoost {\"Validation\" if phase == \"val\" else \"Test\"} Set ROC Curve')\n",
        "\n",
        "    filename = os.path.join(fig_dir, f'roc_curve_{phase}_xgb')\n",
        "    plt.savefig(filename + '.pdf', bbox_inches='tight')\n",
        "    plt.savefig(filename + '.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Plot confusion matrixes\n",
        "    for i, (_, cm) in enumerate(confusion_matrices.items()):\n",
        "        disp, descr = cm\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(f'{descr}')\n",
        "        plt.savefig(os.path.join(fig_dir, f'confusion_matrix_{phase}_xgb_n{i}.pdf'), bbox_inches='tight')\n",
        "        plt.savefig(os.path.join(fig_dir, f'confusion_matrix_{phase}_xgb_n{i}.png'), bbox_inches='tight')\n",
        "        # plt.show()\n",
        "        plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract sub-molecule from fingerprint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Code generated with Google Bard, untested.\n",
        "def get_smiles_parts_from_morgan_fingerprint(smiles, fingerprint):\n",
        "    \"\"\"\n",
        "    Given a SMILES and its Morgan molecular fingerprint, returns the SMILES parts of the bits set to 1.\n",
        "\n",
        "    Args:\n",
        "        smiles: The SMILES of the molecule.\n",
        "        fingerprint: The Morgan molecular fingerprint of the molecule.\n",
        "\n",
        "    Returns:\n",
        "        A list of SMILES strings, each of which corresponds to a substructure of the molecule whose bit is set to 1 in the fingerprint.\n",
        "    \"\"\"\n",
        "    # Convert the SMILES to a molecule object.\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    # Get the bit info map for the fingerprint.\n",
        "    bit_info_map = fingerprint.GetBitInfoMap()\n",
        "    # Create a list to store the SMILES parts.\n",
        "    smiles_parts = []\n",
        "    # Iterate over the bits in the fingerprint.\n",
        "    for bit_id, atoms in bit_info_map.items():\n",
        "        # Get the submolecule corresponding to the bit.\n",
        "        submol = Chem.PathToSubmol(mol, atoms, atomMap={})\n",
        "        # Get the SMILES of the submolecule.\n",
        "        subsmiles = Chem.MolToSmiles(submol)\n",
        "        # Add the SMILES of the submolecule to the list.\n",
        "        smiles_parts.append(subsmiles)\n",
        "    # Return the list of SMILES parts.\n",
        "    return smiles_parts"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generic Wrapper Model\n",
        "\n",
        "[Instructions](https://github.com/Lightning-AI/lightning/discussions/7249#discussioncomment-677516) on how to save combined model hyperparameters (particularly useful when dealing with Transformers):\n",
        "\n",
        "1. Generate sub-model within the wrapper model via a generator function\n",
        "2. Save the sub-model as a separate model checkpoint\n",
        "3. Supply the sub-model checkpoint in order to retrieve it via the generator function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchmetrics import MetricCollection\n",
        "from typing import Type\n",
        "\n",
        "class WrapperModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 smiles_encoder: Type[nn.Module],\n",
        "                 smiles_encoder_args: Mapping | None = {},\n",
        "                 train_dataset: ProtacDataset = None,\n",
        "                 val_dataset: ProtacDataset = None,\n",
        "                 test_dataset: ProtacDataset = None,\n",
        "                 use_extra_features: bool = False,\n",
        "                 poi_seq_embedding_size: int = 0,\n",
        "                 hidden_channels_extra_features: List[int] = [32, 32],\n",
        "                 norm_layer: object = nn.BatchNorm1d,\n",
        "                 task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                 freeze_smiles_encoder: bool = False,\n",
        "                 dropout: float = 0.5,\n",
        "                 batch_size: int = 64,\n",
        "                 learning_rate: float = 1e-3,\n",
        "                 loss_function: Callable | object = nn.HuberLoss(),\n",
        "                 **model_kwargs):\n",
        "        \"\"\"Wrapper class to make prediction on PROTAC data.\n",
        "\n",
        "        Args:\n",
        "            smiles_encoder_generator (Callable | None, optional): Function to generate and retrieve the SMILES encoder nn.Module. Defaults to None.\n",
        "            smiles_encoder_generator_args (Mapping | None, optional): Arguments to the SMILES encoder generator function. NOTE: The arguments will be saved as hyperparameters. Defaults to None.\n",
        "            smiles_encoder_checkpoint_path (str | None, optional): Additional argument suppied to the SMILES encoder generator function. NOTE: It should allow the generator function to retrieve the pretrained nn.Module object. Defaults to None.\n",
        "            smiles_embedding_size (int, optional): SMILES embedding size, i.e., output dimension of the SMILES encoder. Defaults to 1.\n",
        "            train_dataset (ProtacDataset, optional): Train dataset. Defaults to None.\n",
        "            test_dataset (ProtacDataset, optional): Test dataset. Defaults to None.\n",
        "            use_extra_features (bool, optional): Whether to include an additional MLP branch to process extra features. Defaults to False.\n",
        "            hidden_channels_extra_features (List[int], optional): MLP hidden channels sizes of the extra features branch. Defaults to [32, 32].\n",
        "            norm_layer (object, optional): Normalization layer to use in the extra features branch. Defaults to nn.BatchNorm1d.\n",
        "            task (Literal[&#39;predict_active_inactive&#39;, &#39;predict_pDC50&#39;, &#39;predict_pDC50_and_Dmax&#39;], optional): Task to perform. Defaults to 'predict_active_inactive'.\n",
        "            freeze_smiles_encoder (bool, optional): Whether to train the SMILES encoder parameters. Defaults to False.\n",
        "            dropout (float, optional): Dropout factor for the extra features branch. Defaults to 0.5.\n",
        "            batch_size (int, optional): Batch size. Defaults to 64.\n",
        "            learning_rate (float, optional): Learning rate. Defaults to 1e-3.\n",
        "            loss_function (Callable | object, optional): Loss function to be used for regression tasks. Defaults to nn.HuberLoss().\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # Set our init args as class attributes\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        # Save the arguments passed to init\n",
        "        ignore_args_as_hyperparams = [\n",
        "            'train_dataset',\n",
        "            'test_dataset',\n",
        "            'val_dataset',\n",
        "            'loss_function',\n",
        "        ]\n",
        "        self.save_hyperparameters(ignore=ignore_args_as_hyperparams) \n",
        "        # Define or load SMILES encoder sub-model if not supplied\n",
        "        self.smiles_encoder = smiles_encoder(**smiles_encoder_args)\n",
        "        if freeze_smiles_encoder:\n",
        "            self.smiles_encoder.freeze()\n",
        "        # Define sub-model branch for processing \"extra features\"\n",
        "        if use_extra_features:\n",
        "            extra_features_size = 2 # Cell type and E3 ligase\n",
        "            if self.poi_seq_embedding_size <= 0:\n",
        "                if train_dataset is not None:\n",
        "                    self.poi_seq_embedding_size = train_dataset.get_poi_seq_emb_size()\n",
        "                if test_dataset is not None:\n",
        "                    assert train_dataset.get_poi_seq_emb_size() == test_dataset.get_poi_seq_emb_size(), 'POI sequence embedding size mismatch between train and test datasets.'\n",
        "                    self.poi_seq_embedding_size = test_dataset.get_poi_seq_emb_size()\n",
        "                if val_dataset is not None:\n",
        "                    assert train_dataset.get_poi_seq_emb_size() == val_dataset.get_poi_seq_emb_size(), 'POI sequence embedding size mismatch between train and val datasets.'\n",
        "                    self.poi_seq_embedding_size = val_dataset.get_poi_seq_emb_size()\n",
        "            extra_features_size += self.poi_seq_embedding_size\n",
        "            self.extra_features_encoder = MLP(in_channels=extra_features_size,\n",
        "                                              hidden_channels=hidden_channels_extra_features,\n",
        "                                              norm_layer=norm_layer,\n",
        "                                              inplace=False,\n",
        "                                              dropout=dropout)\n",
        "        # Define prediction head\n",
        "        head_inputs = self.smiles_encoder.get_smiles_embedding_size()\n",
        "        if use_extra_features:\n",
        "            head_inputs += hidden_channels_extra_features[-1]\n",
        "        num_outputs = 2 if task == 'predict_pDC50_and_Dmax' else 1\n",
        "        self.head = nn.Linear(head_inputs, num_outputs)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        # Losses\n",
        "        self.regr_loss = loss_function\n",
        "        self.bin_loss = nn.BCEWithLogitsLoss()\n",
        "        # Metrics, a separate metrics collection is defined for each phase\n",
        "        # NOTE: According to the PyTorch Lightning docs, \"similar\" metrics,\n",
        "        # i.e., requiring the same computation, should be optimized w/in a\n",
        "        # metrics collection.\n",
        "        phases = ['train_metrics', 'val_metrics', 'test_metrics']\n",
        "        self.metrics = nn.ModuleDict({p: MetricCollection({\n",
        "            'acc': Accuracy(task='binary'),\n",
        "            'roc_auc': AUROC(task='binary'),\n",
        "            'precision': Precision(task='binary'),\n",
        "            'recall': Recall(task='binary'),\n",
        "            'f1_score': F1Score(task='binary'),\n",
        "            'opt_score': Accuracy(task='binary') + F1Score(task='binary'),\n",
        "            'hp_metric': Accuracy(task='binary'),\n",
        "        }, prefix=p.replace('metrics', '')) for p in phases})\n",
        "        # Misc\n",
        "        self.missing_dataset_error = \\\n",
        "            '''Class variable `{0}` is None. If the model was loaded from a checkpoint, the dataset must be set manually:\n",
        "            \n",
        "            model = {1}.load_from_checkpoint('checkpoint.ckpt')\n",
        "            model.{0} = my_{0}\n",
        "            '''\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        if self.use_extra_features:\n",
        "            e3_ligase = x_in['e3_ligase']\n",
        "            cell_type = x_in['cell_type']\n",
        "            if self.poi_seq_embedding_size > 0:\n",
        "                x = torch.cat((e3_ligase, cell_type, x_in['poi_seq']), dim=-1)\n",
        "            else:\n",
        "                x = torch.cat((e3_ligase, cell_type), dim=-1)\n",
        "            extra_emb = self.extra_features_encoder(x)\n",
        "            smiles_emb = self.smiles_encoder(x_in)\n",
        "            x = torch.cat((extra_emb, smiles_emb), dim=-1)\n",
        "        else:\n",
        "            x = self.smiles_encoder(x_in)\n",
        "        return self.head(x)\n",
        "\n",
        "    def step(self, batch, phase='train'):\n",
        "        y = batch['labels']\n",
        "        preds = self.forward(batch)\n",
        "        if self.task == 'predict_active_inactive':\n",
        "            loss = self.bin_loss(preds, y)\n",
        "            self.metrics[f'{phase}_metrics'].update(preds, y)\n",
        "            self.log(f'{phase}_loss', loss, on_epoch=True, prog_bar=True)\n",
        "            self.log_dict(self.metrics[f'{phase}_metrics'], on_epoch=True)\n",
        "        else:\n",
        "            loss = self.regr_loss(preds, y)\n",
        "            self.log(f'{phase}_loss', loss, on_epoch=True, prog_bar=True)\n",
        "            if phase == 'val':\n",
        "                self.log('hp_metric', loss)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        return self.step(batch, phase='train')\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.step(batch, phase='val')\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.step(batch, phase='test')\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def load_smiles_encoder(self, checkpoint_path):\n",
        "        ckpt = torch.load(checkpoint_path, map_location=self.device)\n",
        "        self.smiles_encoder.load_state_dict(ckpt, strict=False)\n",
        "\n",
        "    # def prepare_data(self):\n",
        "    #     train_ds = os.path.join(data_dir, 'protac', f'train_dataset_fp{self.fp_bits}.pt')\n",
        "    #     test_ds = os.path.join(data_dir, 'protac', f'test_dataset_fp{self.fp_bits}.pt')\n",
        "    #     self.train_dataset = torch.load(train_ds)\n",
        "    #     self.train_dataset = torch.load(train_ds)\n",
        "    #     self.test_dataset = torch.load(test_ds)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        if self.train_dataset is None:\n",
        "            format = 'train_dataset', self.__class__.__name__\n",
        "            raise ValueError(self.missing_dataset_error.format(*format))\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=True, collate_fn=custom_collate,\n",
        "                          drop_last=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        if self.val_dataset is None:\n",
        "            format = 'val_dataset', self.__class__.__name__\n",
        "            raise ValueError(self.missing_dataset_error.format(*format))\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=False, collate_fn=custom_collate)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        if self.test_dataset is None:\n",
        "            format = 'test_dataset', self.__class__.__name__\n",
        "            raise ValueError(self.missing_dataset_error.format(*format))\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size,\n",
        "                          shuffle=False, collate_fn=custom_collate)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training function for generic wrapper model to be used either standalone for bare Pytorch Lightning training or for hyperparameter tuning via Optuna (or Ray Tune):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trial_set_dict(trial: optuna.trial.Trial, d: dict) -> None:\n",
        "    \"\"\"Set a dictionary of user parameters on a Optuna trial object.\"\"\"\n",
        "    for k, v in d.items():\n",
        "        trial.set_user_attr(k, v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(reporting_config: dict,\n",
        "                smiles_encoder: Type[nn.Module],\n",
        "                smiles_encoder_args: Mapping,\n",
        "                train_dataset: ProtacDataset,\n",
        "                val_dataset: ProtacDataset,\n",
        "                test_dataset: ProtacDataset,\n",
        "                num_epochs: int = 10,\n",
        "                task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                loss_func: Callable | object = nn.HuberLoss(),\n",
        "                num_gpus: int = 0,\n",
        "                use_raytune: bool = False,\n",
        "                trial: optuna.trial.Trial | None = None,\n",
        "                accumulate_grad_batches: int = 1,\n",
        "                enable_checkpointing: bool = True,\n",
        "                enable_tensorboard_logging: bool = False,\n",
        "                model: nn.Module | None = None,\n",
        "                **model_kwargs: Mapping | None) -> float | None:\n",
        "    \"\"\"Training function for generic wrapper model to be used either standalone for bare Pytorch Lightning training or for hyperparameter tuning via Optuna (or Ray Tune).\n",
        "    TODO: Add kwargs for Pytorch Lightning Trainer class.\n",
        "\n",
        "    Args:\n",
        "        reporting_config (dict): Dictionary for checkpoint naming and reporting.\n",
        "        smiles_encoder (Callable): Generator function for the sub-model, to be passed to the wrapper model.\n",
        "        smiles_encoder_args (Mapping): Arguments to the sub-model generator function.\n",
        "        smiles_embedding_size (int): Size of the sub-model's output embedding.\n",
        "        train_dataset (ProtacDataset): The training dataset.\n",
        "        test_dataset (ProtacDataset): The test dataset.\n",
        "        num_epochs (int, optional): Number of epochs to train to model to. Defaults to 10.\n",
        "        task (Literal[&#39;predict_active_inactive&#39;, &#39;predict_pDC50&#39;, &#39;predict_pDC50_and_Dmax&#39;], optional): Task to configure the model to. Defaults to 'predict_active_inactive'.\n",
        "        loss_func (Callable | object, optional): Loss function for regression tasks. Defaults to nn.HuberLoss().\n",
        "        num_gpus (int, optional): Number of GPUs to use for training. Defaults to 0.\n",
        "        use_raytune (bool, optional): Use Ray Tune for training. DEPRECATED. Defaults to True.\n",
        "        trial (optuna.trial.Trial | None, optional): Optuna trial object. Defaults to None.\n",
        "        smiles_encoder_save_function (Callable | None, optional): Custom function to save SMILES encoder sub-model. Defaults to None.\n",
        "        smiles_encoder_save_function_kwargs (Mapping, optional): Arguments to the saving functions of the SMILES encoder. Defaults to {}.\n",
        "    \"\"\"\n",
        "    # TODO: The dataset is currently not loaded from disk but passed as\n",
        "    # argument. The problem lies in the definition of ProtacDataset, which is\n",
        "    # not recognized by ray.tune. This should be fixed in the future.\n",
        "\n",
        "    # Namings\n",
        "    # if use_raytune:\n",
        "    #     trial_name = f'{config[\"fp_type\"]}-{fp_bits}-{tune.get_trial_id()}'\n",
        "    lightning_dir = reporting_config['lightning_dir']\n",
        "    model_checkpoint_dir = reporting_config['model_checkpoint_dir']\n",
        "    model_checkpoint = reporting_config['model_checkpoint']\n",
        "    tensorboard_dir = reporting_config['tensorboard_dir']\n",
        "    trial_name = reporting_config['trial_name']\n",
        "    model_name = reporting_config['model_name']\n",
        "    # Setup Pytorch Lightning wrapper model\n",
        "    poi_seq_embedding_size = 0\n",
        "    if model_kwargs is not None:\n",
        "        if model_kwargs.get('use_extra_features', False):\n",
        "            assert train_dataset.get_poi_seq_emb_size() == val_dataset.get_poi_seq_emb_size() == test_dataset.get_poi_seq_emb_size(), f'POI sequence embedding sizes of train, val and test dataset must match.'\n",
        "            poi_seq_embedding_size = train_dataset.get_poi_seq_emb_size()\n",
        "    if model is None:\n",
        "        model = WrapperModel(task=task,\n",
        "                            smiles_encoder=smiles_encoder,\n",
        "                            smiles_encoder_args=smiles_encoder_args,\n",
        "                            poi_seq_embedding_size=poi_seq_embedding_size,\n",
        "                            train_dataset=train_dataset,\n",
        "                            val_dataset=val_dataset,\n",
        "                            test_dataset=test_dataset,\n",
        "                            loss_function=loss_func,\n",
        "                            norm_layer=nn.BatchNorm1d,\n",
        "                            **model_kwargs)\n",
        "        # TODO: Pytorch compile not yet supported on Windows\n",
        "        if os.name != 'nt':\n",
        "            model = torch.compile(model)\n",
        "    # Configure Pytorch Lightning loggers\n",
        "    loggers = []\n",
        "    if enable_tensorboard_logging:\n",
        "        loggers.append(TensorBoardLogger(save_dir=tensorboard_dir,\n",
        "                                         name=trial_name,\n",
        "                                         version='.',\n",
        "                                         default_hp_metric=True))\n",
        "    if not use_raytune and trial is not None:\n",
        "        save_dir = os.path.join(lightning_dir, 'logs', f'logs_{model_name}-{trial_name}')\n",
        "        csv_logger = CSVLogger(save_dir=save_dir)\n",
        "        loggers.append(csv_logger)\n",
        "    # Setup Pytorch Lightning callbacks\n",
        "    if task == 'predict_active_inactive':\n",
        "        # Keep track of additional metrics when predicting active/inactive\n",
        "        # NOTE: Key == Ray Tune name, Value == Pytorch Lightning name\n",
        "        metrics = {\n",
        "            'train_loss': 'train_loss',\n",
        "            'train_acc': 'train_acc',\n",
        "            'val_loss': 'val_loss',\n",
        "            'val_acc': 'val_acc',\n",
        "            'val_opt_score': 'val_opt_score',\n",
        "            'val_roc_auc': 'val_roc_auc',\n",
        "            'val_precision': 'val_precision',\n",
        "            'val_recall': 'val_recall',\n",
        "            'val_f1_score': 'val_f1_score',\n",
        "        }\n",
        "        monitor = 'val_acc'\n",
        "        mode = 'max'\n",
        "    else:\n",
        "        metrics = {'val_loss': 'val_loss', 'train_loss': 'train_loss'}\n",
        "        monitor = 'val_loss'\n",
        "        mode = 'min'\n",
        "    callbacks = []\n",
        "    if use_raytune:\n",
        "        callbacks.append(\n",
        "            TuneReportCheckpointCallback(metrics,\n",
        "                                         filename='checkpoint.ckpt',\n",
        "                                         on='validation_end'),\n",
        "            # TuneReportCallback(metrics, on='validation_end'),\n",
        "        )\n",
        "    else:\n",
        "        save_top_k = 1 if enable_checkpointing else 0\n",
        "        callbacks.append(ModelCheckpoint(dirpath=model_checkpoint_dir,\n",
        "                                         filename=model_checkpoint,\n",
        "                                         save_top_k=save_top_k,\n",
        "                                         monitor=monitor,\n",
        "                                         mode=mode))\n",
        "        if trial is not None:\n",
        "            callbacks.append(\n",
        "                CustomPyTorchLightningPruningCallback(trial, monitor=monitor)\n",
        "            )\n",
        "    callbacks.extend([\n",
        "        EarlyStopping(monitor='val_loss', mode='min', patience=5, check_finite=True),\n",
        "        EarlyStopping(monitor='val_acc', mode='max', patience=5),\n",
        "    ])\n",
        "    # Instantiate Pytorch Lightning Trainer\n",
        "    if torch.cuda.is_available() and num_gpus > 0:\n",
        "        pl_devices = math.ceil(num_gpus)\n",
        "        accelerator = 'gpu'\n",
        "        precision = '16-mixed'\n",
        "    else:\n",
        "        pl_devices = 4\n",
        "        accelerator = 'auto'\n",
        "        precision = '32'\n",
        "    trainer = pl.Trainer(max_epochs=num_epochs,\n",
        "                         gradient_clip_val=1.0,\n",
        "                         gradient_clip_algorithm='norm',\n",
        "                         accumulate_grad_batches=accumulate_grad_batches,\n",
        "                         log_every_n_steps=8,\n",
        "                         callbacks=callbacks,\n",
        "                         accelerator=accelerator,\n",
        "                         devices=pl_devices,\n",
        "                         precision=precision,\n",
        "                         enable_checkpointing=True, # not use_raytune,\n",
        "                         logger=loggers,\n",
        "                         enable_progress_bar=False,\n",
        "                         enable_model_summary=False)\n",
        "    # Finally, start training\n",
        "    trainer.fit(model)\n",
        "\n",
        "    # # Reload best model checkpoint\n",
        "    # # NOTE: We need to reload the best model because the checkpointing callback\n",
        "    # # automatically saves the model with best accuracy achieved DURING training,\n",
        "    # # not necessarily the model AT THE END of training.\n",
        "    # if enable_checkpointing:\n",
        "    #     best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "    #     model = WrapperModel.load_from_checkpoint(best_model_path)\n",
        "    #     model.train_dataset = train_dataset\n",
        "    #     model.val_dataset = val_dataset\n",
        "    #     model.test_dataset = test_dataset\n",
        "\n",
        "    # Report metrics and, if using Optuna, return the trained model score\n",
        "    if not use_raytune and trial is not None:\n",
        "        trainer_log_dir = trainer.loggers[-1].log_dir\n",
        "        trial.set_user_attr('trainer_log_dir', trainer_log_dir)\n",
        "        for metric in metrics.values():\n",
        "            trial.set_user_attr(metric, trainer.callback_metrics[metric].item())\n",
        "        if enable_checkpointing:\n",
        "            best_model_path = trainer.checkpoint_callback.best_model_path\n",
        "            trial.set_user_attr('model_checkpoint', best_model_path)\n",
        "        # Return in case the function is used as an optimization func. in Optuna\n",
        "        if task == 'predict_active_inactive':\n",
        "            if enable_checkpointing:\n",
        "                eval_results = get_eval_results(model, task, num_gpus,\n",
        "                                            trainer=trainer, return_logits=False)\n",
        "                trial_set_dict(trial, eval_results)\n",
        "                return eval_results['val_acc']\n",
        "            else:\n",
        "                metrics_path = os.path.join(trainer_log_dir, 'metrics.csv')\n",
        "                best_score = pd.read_csv(metrics_path)[monitor].astype(float).max()\n",
        "                return best_score\n",
        "        else:\n",
        "            return trainer.callback_metrics['val_loss'].item()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generic objective body:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective_body(trial: optuna.trial.Trial,\n",
        "                   model_name: str,\n",
        "                   trial_name: str,\n",
        "                   dataset_name: str,\n",
        "                   smiles_encoder: Type[nn.Module],\n",
        "                   smiles_encoder_gen_args: Mapping,\n",
        "                   model_kwargs: Mapping,\n",
        "                   num_epochs: int = 10,\n",
        "                   task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                   enable_checkpointing: bool = True,\n",
        "                   loss_func: Callable | object = nn.HuberLoss(),\n",
        "                   use_upsampled: bool = False,\n",
        "                   num_gpus: int = 0,\n",
        "                   ) -> float:\n",
        "    ds = get_datasets(task, use_upsampled, dataset_name=dataset_name)\n",
        "    train_dataset = ds['train']\n",
        "    val_dataset = ds['val']\n",
        "    test_dataset = ds['test']\n",
        "    trial.set_user_attr('dataset_name', dataset_name)\n",
        "    # Standard namings for reporting\n",
        "    lightning_dir = os.path.join(checkpoint_dir, 'lightning')\n",
        "    model_checkpoint_dir = os.path.join(lightning_dir, 'models')\n",
        "    model_checkpoint = f'{model_name}-{trial_name}'\n",
        "    tensorboard_dir = os.path.join(lightning_dir, 'tensorboard', f'{model_name}_{task}')\n",
        "    reporting_config = {\n",
        "        'trial_name': trial_name,\n",
        "        'model_name': model_name,\n",
        "        'lightning_dir': lightning_dir,\n",
        "        'model_checkpoint_dir': model_checkpoint_dir,\n",
        "        'model_checkpoint': model_checkpoint,\n",
        "        'tensorboard_dir': tensorboard_dir,\n",
        "    }\n",
        "    trial_set_dict(trial, reporting_config)\n",
        "    # Train model via its generic function\n",
        "    return train_model(reporting_config=reporting_config,\n",
        "                       smiles_encoder=smiles_encoder,\n",
        "                       smiles_encoder_args=smiles_encoder_gen_args,\n",
        "                       train_dataset=train_dataset,\n",
        "                       val_dataset=val_dataset,\n",
        "                       test_dataset=test_dataset,\n",
        "                       # Optional arguments\n",
        "                       num_epochs=num_epochs,\n",
        "                       task=task,\n",
        "                       loss_func=loss_func,\n",
        "                       num_gpus=num_gpus,\n",
        "                       use_raytune=False,\n",
        "                       enable_checkpointing=enable_checkpointing,\n",
        "                       trial=trial,\n",
        "                       **model_kwargs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot training curves:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_training_curves(trainer_logs: str, experiment: str = '', figpath: str | None = None):\n",
        "    metrics = pd.read_csv(os.path.join(trainer_logs, 'metrics.csv'))\n",
        "    del metrics['step']\n",
        "    del metrics['val_hp_metric']\n",
        "    metrics = metrics.set_index('epoch').groupby('epoch').max()\n",
        "    train_cols = [\n",
        "        'train_loss_epoch',\n",
        "        'train_acc_epoch',\n",
        "    ]\n",
        "    val_cols = [\n",
        "        'val_loss',\n",
        "        'val_acc',\n",
        "    ]\n",
        "    test_cols = [\n",
        "        'test_loss',\n",
        "        'test_acc',\n",
        "    ]\n",
        "    # display(metrics[train_cols + val_cols + test_cols].dropna(axis=1, how='all'))\n",
        "    print(metrics[train_cols + val_cols + test_cols].dropna(axis=1, how='all'))\n",
        "    ax = sns.relplot(data=metrics[train_cols + val_cols], kind='line')\n",
        "    # Plot legend in a nicer way...\n",
        "    ax._legend.remove()\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1) #, fancybox=True, shadow=True)\n",
        "    plt.title(f'Training curves{experiment}')\n",
        "    plt.grid(alpha=0.7)\n",
        "    if figpath is not None:\n",
        "        plt.savefig(figpath + '.pdf', bbox_inches='tight')\n",
        "        plt.savefig(figpath + '.png', bbox_inches='tight')\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_gpus = 1 if torch.cuda.is_available() else 0\n",
        "\n",
        "def evaluate_experiment(dataset_name: str,\n",
        "                        task: str,\n",
        "                        descr: str = '',\n",
        "                        plot_dummy: bool = False,\n",
        "                        model_checkpoint: str | None = None,\n",
        "                        plot_auc: bool = True,\n",
        "                        phase: Literal['train', 'val', 'test'] = ['val', 'test'],\n",
        "                        best_model: nn.Module | None = None) -> Tuple | None:\n",
        "    \"\"\"Evaluate a trained model on a specific dataset.\n",
        "\n",
        "    Args:\n",
        "        descr (str): Model description. Used for plotting.\n",
        "        dataset_name (str): Dataset to retrieve via `get_datasets`.\n",
        "        task (str): Task to evaluate.\n",
        "        plot_dummy (bool, optional): Whether to plot the Dummy classifier. Defaults to False.\n",
        "        model_checkpoint (str | None, optional): Model checkpoint to load. Defaults to None.\n",
        "        plot_auc (bool, optional): Whether to plot the AUC curve. Defaults to True.\n",
        "        best_model (nn.Module | None, optional): Model to evaluate. Defaults to None.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: In case no model nor checkpoint is provided.\n",
        "\n",
        "    Returns:\n",
        "        Tuple | None: If binary classification: dictionary with evaluation results and Confusion matrix display.\n",
        "    \"\"\"\n",
        "    # Load model\n",
        "    if best_model is None:\n",
        "        if model_checkpoint is not None:\n",
        "            best_model = WrapperModel.load_from_checkpoint(model_checkpoint)\n",
        "        else:\n",
        "            raise ValueError('Either best_model or model_checkpoint must be provided.')\n",
        "    # Retrieve specific datasets and setup train/test datasets to run evaluation\n",
        "    ds = get_datasets(task, use_upsampled, dataset_name=dataset_name)    \n",
        "    best_model.train_dataset = ds['train']\n",
        "    best_model.val_dataset = ds['val']\n",
        "    best_model.test_dataset = ds['test']\n",
        "    # Get predictions    \n",
        "    preds = get_eval_results(best_model, task, phase=phase, num_gpus=n_gpus)\n",
        "    # Plot results\n",
        "    if task == 'predict_pDC50_and_Dmax':\n",
        "        # TODO: Regression task\n",
        "        pass\n",
        "    elif task == 'predict_active_inactive':\n",
        "        best_guess = 1.0 if phase == 'test' else 0.0\n",
        "        bin_labels = preds[f'{phase}_labels'].flatten().astype(int)\n",
        "        if plot_auc:\n",
        "            # Plot Dummy classifier\n",
        "            if plot_dummy:\n",
        "                dummy_pred = torch.tensor([best_guess] * len(bin_labels))\n",
        "                fpr, tpr, _ = sklearn.metrics.roc_curve(bin_labels, dummy_pred)\n",
        "                auc = sklearn.metrics.roc_auc_score(bin_labels, dummy_pred)\n",
        "                acc = binary_accuracy(dummy_pred, torch.tensor(bin_labels))\n",
        "                dummy_descr = f'Dummy (AUC = {auc:.2f}, Accuracy = {acc * 100:.2f}%)'\n",
        "                plt.plot(fpr, tpr, label=dummy_descr, color='black', lw=0.8, linestyle='--')\n",
        "            # ROC-AUC curve plotting\n",
        "            l = f'{descr} (AUC: {preds[f\"{phase}_roc_auc\"]:.2f}, Accuracy: {preds[f\"{phase}_acc\"] * 100:.2f}%)'\n",
        "            plt.plot(preds[f\"{phase}_fpr\"], preds[f\"{phase}_tpr\"], label=l)\n",
        "        return preds, ConfusionMatrixDisplay(preds[f'{phase}_confusion_matrix'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PfhucrAmPWUq"
      },
      "source": [
        "### SMILES as Fingerprints - MLPs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the MLP-based fingerprint sub-model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FingerprintSubModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 fp_type: Literal['morgan_fp', 'maccs_fp', 'path_fp'] = 'morgan_fp',\n",
        "                 fp_bits: int = 1024,\n",
        "                 hidden_channels: List[int] = [128, 128],\n",
        "                 norm_layer: object = nn.BatchNorm1d,\n",
        "                 dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        # Set our init args as class attributes\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        self.save_hyperparameters()\n",
        "        self.fp_bits = MACCS_BITWIDTH if fp_type == 'maccs_fp' else fp_bits\n",
        "        # Define PyTorch model\n",
        "        self.fp_encoder = MLP(in_channels=self.fp_bits,\n",
        "                              hidden_channels=hidden_channels,\n",
        "                              norm_layer=norm_layer,\n",
        "                              inplace=False,\n",
        "                              dropout=dropout)\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        return self.fp_encoder(x_in[self.fp_type])\n",
        "\n",
        "    def get_smiles_embedding_size(self):\n",
        "        return self.hidden_channels[-1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate experiment-specific datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "fp_bits_options = [1024, 2048, 4096]\n",
        "upsampled = [False] # [True, False]\n",
        "fp_max_paths = list(range(8, 11))\n",
        "radii = list(range(2, 11))\n",
        "experiments = (tasks, fp_bits_options, fp_max_paths, radii, upsampled)\n",
        "\n",
        "for subset in tqdm(list(itertools.product(*experiments))):\n",
        "    task, fp_bits, fp_max_path, radius, use_upsampled = subset\n",
        "    protac_ds_kwargs = {\n",
        "        'precompute_fingerprints': True,\n",
        "        'use_morgan_fp': True,\n",
        "        'use_maccs_fp': True,\n",
        "        'use_path_fp': True,\n",
        "        'morgan_atomic_radius': radius,\n",
        "        'morgan_bits': fp_bits,\n",
        "        'path_bits': fp_bits,\n",
        "        'fp_min_path': 1,\n",
        "        'fp_max_path': fp_max_path,\n",
        "        'poi_gene_enc': poi_gene_enc,\n",
        "        'poi_vectorizer': poi_encoder, # poi_vectorizer,\n",
        "        'e3_ligase_enc': e3_encoder, # e3_ligase_enc,\n",
        "        'cell_type_enc': cell_encoder, # cell_type_enc,\n",
        "    }\n",
        "    dataset_name = f'_fp{fp_bits}_radius{radius}_path1-{fp_max_path}'\n",
        "    get_datasets(task,\n",
        "                 use_upsampled,\n",
        "                 dataset_name=dataset_name,\n",
        "                 regenerate_datasets=False,\n",
        "                 **protac_ds_kwargs)\n",
        "    # print(f'Finished generating \"protac-db{dataset_name}\" datasets.')\n",
        "print('Datasets are ready to use.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Optuna objective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fp_objective(trial,\n",
        "                 fp_bits: int,\n",
        "                 num_epochs:int = 10,\n",
        "                 task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                 loss_func: Callable | object = nn.HuberLoss(),\n",
        "                 enable_checkpointing: bool = True,\n",
        "                 use_upsampled: bool = False,\n",
        "                 num_gpus: int = 0):\n",
        "    # ==========================================================================\n",
        "    # Model-specific objective code\n",
        "    # ==========================================================================\n",
        "    fp_radius = trial.suggest_int('radius', 2, 10)\n",
        "    fp_max_path = trial.suggest_int('fp_max_path', 8, 10)\n",
        "    # Setup SMILES Encoder arguments\n",
        "    num_layers = trial.suggest_int('num_layers', 2, 8)\n",
        "    hidden_channels = [\n",
        "        trial.suggest_int(f'smiles_enc_kwargs_layer_{i}_size', 32, 1024, step=32) for i in range(num_layers)\n",
        "    ]\n",
        "    smiles_encoder_gen_args = {\n",
        "        'fp_type': trial.suggest_categorical('smiles_enc_kwargs_fp_type', ['morgan_fp', 'maccs_fp', 'path_fp']),\n",
        "        'fp_bits': fp_bits,\n",
        "        'hidden_channels': hidden_channels,\n",
        "        'norm_layer': nn.BatchNorm1d,\n",
        "        'dropout': trial.suggest_float('smiles_enc_kwargs_dropout', 0.1, 0.8),\n",
        "    }\n",
        "    smiles_encoder = FingerprintSubModel\n",
        "    # Setup Wrapper Model arguments\n",
        "    num_layers_extra = trial.suggest_int('num_layers_extra', 2, 8)\n",
        "    hidden_channels_extra_features = [\n",
        "        trial.suggest_int(f'model_kwargs_layer_{i}_size', 32, 1024, step=32) for i in range(num_layers_extra)\n",
        "    ]\n",
        "    model_kwargs = {\n",
        "        'use_extra_features': True, # trial.suggest_categorical('use_extra_features', [True, False]),\n",
        "        'hidden_channels_extra_features': hidden_channels_extra_features,\n",
        "        'dropout': trial.suggest_float('model_kwargs_dropout', 0.1, 0.8),\n",
        "        'learning_rate': trial.suggest_float('model_kwargs_learning_rate', 1e-5, 1e-2, log=True),\n",
        "        'batch_size': trial.suggest_categorical('model_kwargs_batch_size', [16, 32, 64, 128]),\n",
        "    }\n",
        "    # Retrieve specific datasets\n",
        "    tmp = 1024 if smiles_encoder_gen_args['fp_type'] == 'maccs_fp' else fp_bits\n",
        "    dataset_name = f'_fp{tmp}_radius{fp_radius}_path1-{fp_max_path}'\n",
        "    # Model-specific namings for reporting\n",
        "    model_name = 'fp_model'\n",
        "    fp_bits = MACCS_BITWIDTH if smiles_encoder_gen_args['fp_type'] == 'maccs_fp' else fp_bits\n",
        "    eventid = f'{trial.datetime_start.strftime(\"%Y%m%d-%H-%M-%S-\")}{uuid4()}'\n",
        "    trial_name = f'{smiles_encoder_gen_args[\"fp_type\"]}-{fp_bits}-{trial.number}-{eventid}'\n",
        "    \n",
        "    \n",
        "    # ==========================================================================\n",
        "    # Standard and common code for all objectives\n",
        "    # ==========================================================================\n",
        "    ds = get_datasets(task, use_upsampled, dataset_name=dataset_name)\n",
        "    train_dataset = ds['train']\n",
        "    val_dataset = ds['val']\n",
        "    test_dataset = ds['test']\n",
        "    trial.set_user_attr('dataset_name', dataset_name)\n",
        "    # Standard namings for reporting\n",
        "    lightning_dir = os.path.join(checkpoint_dir, 'lightning')\n",
        "    model_checkpoint_dir = os.path.join(lightning_dir, 'models')\n",
        "    model_checkpoint = f'{model_name}-{trial_name}'\n",
        "    tensorboard_dir = os.path.join(lightning_dir, 'tensorboard', f'{model_name}_{task}')\n",
        "    reporting_config = {\n",
        "        'trial_name': trial_name,\n",
        "        'model_name': model_name,\n",
        "        'lightning_dir': lightning_dir,\n",
        "        'model_checkpoint_dir': model_checkpoint_dir,\n",
        "        'model_checkpoint': model_checkpoint,\n",
        "        'tensorboard_dir': tensorboard_dir,\n",
        "    }\n",
        "    trial_set_dict(trial, reporting_config)\n",
        "    # Train model via its generic function\n",
        "    return train_model(reporting_config=reporting_config,\n",
        "                       smiles_encoder=smiles_encoder,\n",
        "                       smiles_encoder_args=smiles_encoder_gen_args,\n",
        "                       train_dataset=train_dataset,\n",
        "                       val_dataset=val_dataset,\n",
        "                       test_dataset=test_dataset,\n",
        "                       # Optional arguments\n",
        "                       num_epochs=num_epochs,\n",
        "                       task=task,\n",
        "                       loss_func=loss_func,\n",
        "                       num_gpus=num_gpus,\n",
        "                       use_raytune=False,\n",
        "                       enable_checkpointing=enable_checkpointing,\n",
        "                       trial=trial,\n",
        "                       **model_kwargs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run experiments:\n",
        "\n",
        "* NOTE: Somehow, automagically, Raytune takes care of the PytorchLighting Dataloaders, eventually generating mess\n",
        "* NOTE: Batch size of 32 creates a last batch of size 1, thus breaking the batch norm layer. Setting `drop_last=True` should help, but somehow RayTune fails anyway...\n",
        "* NOTE: Also having a too large batch size breaks RayTune... Maybe because it's unable to set it to a proper size which doesn't exceed the actual dataset size (like Pythorch does by default)\n",
        "\n",
        "That's why, I abandoned RayTune for now, and I'm using just Optuna instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define experiments design points\n",
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "fp_bits_options = [1024, 2048, 4096]\n",
        "upsampled = [False] # [True, False]\n",
        "experiments = (tasks, fp_bits_options, upsampled)\n",
        "# Get all experiments combinations\n",
        "n_experiments = 0\n",
        "for subset in itertools.product(*experiments):\n",
        "    task, fp_bits, use_upsampled = subset  \n",
        "    if use_upsampled and task != 'predict_active_inactive':\n",
        "        continue\n",
        "    n_experiments += 1\n",
        "# Set fixed parameters\n",
        "num_epochs = 15\n",
        "num_samples = 20 # 1000\n",
        "n_gpus = 1 if torch.cuda.is_available() else 0\n",
        "# loss_func = mean_absolute_error\n",
        "# loss_func = mean_squared_error\n",
        "loss_func = nn.HuberLoss(reduction='mean', delta=0.8) # Default 1.0\n",
        "# Define specific results dictionary in the global one\n",
        "experiments_results['results_fp'] = load_result('results_fp')\n",
        "if RETRAIN_FP_MODEL or not experiments_results['results_fp']:\n",
        "    # Run experiments\n",
        "    i = 0\n",
        "    best_ckpt = [] # Used for removing non-optimal checkpoints\n",
        "    for experiment_id in itertools.product(*experiments):\n",
        "        task, fp_bits, use_upsampled = experiment_id\n",
        "        if use_upsampled and task != 'predict_active_inactive':\n",
        "            continue\n",
        "        print(f'-' * 80)\n",
        "        print(f'Experiment n.{i + 1} ({i / n_experiments * 100.0:.2f}% complete):')\n",
        "        print(f'\\ttask: {task}')\n",
        "        print(f'\\tfp_bits: {fp_bits}')\n",
        "        print(f'\\tuse_upsampled: {use_upsampled}')\n",
        "        print(f'-' * 80)\n",
        "        # Run Optuna study\n",
        "        direction = 'maximize' if task == 'predict_active_inactive' else 'minimize'\n",
        "        # optuna_pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
        "        optuna_pruner = optuna.pruners.HyperbandPruner(min_resource=2,\n",
        "                                                       max_resource=num_epochs,\n",
        "                                                       reduction_factor=3)\n",
        "        optuna_sampler = optuna.samplers.TPESampler(seed=42)\n",
        "        study = optuna.create_study(direction=direction,\n",
        "                                    pruner=optuna_pruner,\n",
        "                                    sampler=optuna_sampler)    \n",
        "        study.optimize(lambda trial: fp_objective(trial,\n",
        "                                                task=task,\n",
        "                                                fp_bits=fp_bits,\n",
        "                                                num_epochs=num_epochs,\n",
        "                                                loss_func=loss_func,\n",
        "                                                enable_checkpointing=False,\n",
        "                                                num_gpus=n_gpus),\n",
        "                    n_trials=num_samples,\n",
        "                    timeout=600 * 2)\n",
        "        trial = study.best_trial\n",
        "        experiments_results['results_fp'][experiment_id] = {}\n",
        "        experiments_results['results_fp'][experiment_id]['trial'] = trial\n",
        "        experiments_results['results_fp'][experiment_id]['fp_bits'] = fp_bits\n",
        "        experiments_results['results_fp'][experiment_id]['task'] = task\n",
        "        experiments_results['results_fp'][experiment_id]['use_upsampled'] = use_upsampled\n",
        "        # ======================================================================\n",
        "        # Retrain best model and store its checkpoint\n",
        "        # ======================================================================\n",
        "        # Setup SMILES Encoder arguments\n",
        "        num_layers = trial.params['num_layers']\n",
        "        hidden_channels = [\n",
        "            trial.params[f'smiles_enc_kwargs_layer_{i}_size'] for i in range(num_layers)\n",
        "        ]\n",
        "        smiles_encoder_gen_args = {\n",
        "            'fp_type': trial.params['smiles_enc_kwargs_fp_type'],\n",
        "            'fp_bits': fp_bits,\n",
        "            'hidden_channels': hidden_channels,\n",
        "            'norm_layer': nn.BatchNorm1d,\n",
        "            'dropout': trial.params['smiles_enc_kwargs_dropout'],\n",
        "        }\n",
        "        smiles_encoder = FingerprintSubModel\n",
        "        smiles_embedding_size = hidden_channels[-1]\n",
        "        # Setup Wrapper Model arguments\n",
        "        num_layers_extra = trial.params['num_layers_extra']\n",
        "        hidden_channels_extra_features = [\n",
        "            trial.params[f'model_kwargs_layer_{i}_size'] for i in range(num_layers_extra)\n",
        "        ]\n",
        "        model_kwargs = {\n",
        "            'use_extra_features': True,\n",
        "            'hidden_channels_extra_features': hidden_channels_extra_features,\n",
        "            'dropout': trial.params['model_kwargs_dropout'],\n",
        "            'learning_rate': trial.params['model_kwargs_learning_rate'],\n",
        "            'batch_size': trial.params['model_kwargs_batch_size'],\n",
        "        }\n",
        "        ds = get_datasets(task, use_upsampled, dataset_name=trial.user_attrs['dataset_name'])\n",
        "        reporting_config = {\n",
        "            'trial_name': trial.user_attrs['trial_name'],\n",
        "            'model_name': trial.user_attrs['model_name'],\n",
        "            'lightning_dir': trial.user_attrs['lightning_dir'],\n",
        "            'model_checkpoint_dir': trial.user_attrs['model_checkpoint_dir'],\n",
        "            'model_checkpoint': trial.user_attrs['model_checkpoint'],\n",
        "            'tensorboard_dir': trial.user_attrs['tensorboard_dir'],\n",
        "        }\n",
        "        train_model(reporting_config=reporting_config,\n",
        "                    smiles_encoder=smiles_encoder,\n",
        "                    smiles_encoder_args=smiles_encoder_gen_args,\n",
        "                    train_dataset=ds['train'],\n",
        "                    val_dataset=ds['val'],\n",
        "                    test_dataset=ds['test'],\n",
        "                    # Optional arguments\n",
        "                    num_epochs=num_epochs,\n",
        "                    task=task,\n",
        "                    loss_func=loss_func,\n",
        "                    num_gpus=n_gpus,\n",
        "                    use_raytune=False,\n",
        "                    enable_checkpointing=True,\n",
        "                    trial=trial,\n",
        "                    **model_kwargs)\n",
        "        # Reporting\n",
        "        print('-' * 80)\n",
        "        print(f'Experiment n.{i + 1} done ({(i + 1) / n_experiments * 100.0:.2f}% complete)')\n",
        "        print('Number of finished trials: {}'.format(len(study.trials)))\n",
        "        print(f'Best trial score: {trial.value}:')\n",
        "        print_dict('Experiment:', experiments_results['results_fp'][experiment_id])\n",
        "        print_dict('Params:', trial.params)\n",
        "        print_dict('Attributes:', trial.user_attrs)\n",
        "        i += 1\n",
        "        # Remove non-optimal checkpoints\n",
        "        model_name = trial.user_attrs['model_name']\n",
        "        checkpoint_root_dir = trial.user_attrs['model_checkpoint_dir']\n",
        "        best_ckpt.append(trial.user_attrs['trial_name'])\n",
        "        del_non_optimal_ckpt(checkpoint_root_dir, best_ckpt, model_name)\n",
        "        # Plotting training curves\n",
        "        trainer_logs = trial.user_attrs['trainer_log_dir']\n",
        "        descr=f' for {fp_bits}bit'\n",
        "        figpath = os.path.join(fig_dir, f'training_curves_{task}_fp{fp_bits}')\n",
        "        plot_training_curves(trainer_logs, experiment=descr, figpath=figpath)\n",
        "    save_results(experiments_results['results_fp'], result_name='results_fp')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for phase in ['val', 'test']:\n",
        "    confusion_matrices = {}\n",
        "    plot_dummy = True\n",
        "\n",
        "    for experiment_id, design_points in experiments_results['results_fp'].items():\n",
        "        trial = design_points['trial']\n",
        "        task = design_points['task']\n",
        "        # Model-specific description\n",
        "        fp_bits = design_points['fp_bits']\n",
        "        use_upsampled = design_points['use_upsampled']\n",
        "        fp_type = trial.params['smiles_enc_kwargs_fp_type']\n",
        "        descr = f'MLP [{fp_type.replace(\"_fp\", \"\").upper()} {fp_bits}bits]'\n",
        "        preds, cm = evaluate_experiment(task=task,\n",
        "                                        descr=descr,\n",
        "                                        dataset_name=trial.user_attrs['dataset_name'],\n",
        "                                        model_checkpoint=trial.user_attrs['model_checkpoint'],\n",
        "                                        plot_dummy=plot_dummy,\n",
        "                                        phase=phase,\n",
        "                                        plot_auc=True)\n",
        "        experiments_results['results_fp'][experiment_id]['trial'].user_attrs.update(preds)\n",
        "        save_results(experiments_results['results_fp'],\n",
        "                     result_name='results_fp')\n",
        "        confusion_matrices[experiment_id] = (cm, descr)\n",
        "        plot_dummy = False\n",
        "        print_dict(f'Evaluation results for {descr}:', preds)\n",
        "        print('-' * 80)\n",
        "    plt.grid('both', alpha=0.7)\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1, fancybox=True) #, shadow=True)\n",
        "    plt.title(f'MLP {\"Validation\" if phase == \"val\" else \"Test\"} Set ROC Curve')\n",
        "\n",
        "    filename = os.path.join(fig_dir, f'roc_curve_{phase}_fp')\n",
        "    plt.savefig(filename + '.pdf', bbox_inches='tight')\n",
        "    plt.savefig(filename + '.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Plot confusion matrixes:\n",
        "    for i, (_, (disp, descr)) in enumerate(confusion_matrices.items()):\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(f'{descr}')\n",
        "        filename = os.path.join(fig_dir, f'confusion_matrix_{phase}_fp_n{i}')\n",
        "        plt.savefig(filename + '.pdf', bbox_inches='tight')\n",
        "        plt.savefig(filename + '.png', bbox_inches='tight')\n",
        "        # plt.show()\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %tensorboard --logdir {checkpoint_dir}/lightning/tensorboard/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SMILES as Graphs - GNNs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pre-made Models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate sub-model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GnnSubModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 model_type: Literal['gin', 'gat', 'gcn', 'attentivefp'] = 'gin',\n",
        "                 hidden_channels: int = 32,\n",
        "                 num_layers: int = 3,\n",
        "                 out_channels: int = 8,\n",
        "                 dropout: float = 0.1,\n",
        "                 act: Literal['relu', 'elu'] = 'relu',\n",
        "                 jk: Literal['max', 'last', 'cat', 'lstm'] = 'max',\n",
        "                 norm: Literal['batch', 'layer'] = 'batch',\n",
        "                 num_timesteps: int = 16):\n",
        "        super().__init__()\n",
        "        # Set our init args as class attributes\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        self.save_hyperparameters()\n",
        "        self.smiles_embedding_size = out_channels\n",
        "        if model_type == 'gin':\n",
        "            self.smiles_embedding_size = hidden_channels\n",
        "            self.gnn = geom_nn.models.GIN(in_channels=num_node_features,\n",
        "                                          hidden_channels=hidden_channels,\n",
        "                                          num_layers=num_layers,\n",
        "                                          dropout=dropout,\n",
        "                                          act=act,\n",
        "                                          norm=norm,\n",
        "                                          jk=jk)\n",
        "        elif model_type == 'gat':\n",
        "            self.gnn = geom_nn.models.GAT(in_channels=num_node_features,\n",
        "                                          hidden_channels=hidden_channels,\n",
        "                                          num_layers=num_layers,\n",
        "                                          out_channels=out_channels,\n",
        "                                          dropout=dropout,\n",
        "                                          act=act,\n",
        "                                          norm=norm,\n",
        "                                          jk=jk)\n",
        "        elif model_type == 'gcn':\n",
        "            self.gnn = geom_nn.models.GCN(in_channels=num_node_features,\n",
        "                                          hidden_channels=hidden_channels,\n",
        "                                          num_layers=num_layers,\n",
        "                                          out_channels=out_channels,\n",
        "                                          dropout=dropout,\n",
        "                                          act=act,\n",
        "                                          norm=norm,\n",
        "                                          jk=jk)\n",
        "        elif model_type == 'attentivefp':\n",
        "            self.gnn = geom_nn.models.AttentiveFP(in_channels=num_node_features,\n",
        "                                                  hidden_channels=hidden_channels,\n",
        "                                                  out_channels=out_channels,\n",
        "                                                  edge_dim=node_edge_dim,\n",
        "                                                  num_layers=num_layers,\n",
        "                                                  num_timesteps=num_timesteps,\n",
        "                                                  dropout=dropout)\n",
        "        else:\n",
        "            raise ValueError(f'Unknown model type: {model_type}. Available: gin, gat, gcn, attentivefp')\n",
        "        \n",
        "        \n",
        "    def forward(self, batch):\n",
        "        if self.model_type == 'gin':\n",
        "            x = self.gnn(batch['smiles_graph'].x,\n",
        "                         batch['smiles_graph'].edge_index)\n",
        "            smiles_emb = geom_nn.global_add_pool(x, batch['smiles_graph'].batch)\n",
        "        elif self.model_type == 'gat':\n",
        "            x = self.gnn(x=batch['smiles_graph'].x.to(torch.float),\n",
        "                         edge_index=batch['smiles_graph'].edge_index,\n",
        "                         edge_attr=batch['smiles_graph'].edge_attr)\n",
        "            smiles_emb = geom_nn.global_add_pool(x, batch['smiles_graph'].batch)\n",
        "        elif self.model_type == 'gcn':\n",
        "            x = self.gnn(x=batch['smiles_graph'].x.to(torch.float),\n",
        "                         edge_index=batch['smiles_graph'].edge_index,\n",
        "                         edge_attr=batch['smiles_graph'].edge_attr)\n",
        "            smiles_emb = geom_nn.global_add_pool(x, batch['smiles_graph'].batch)\n",
        "        elif self.model_type == 'attentivefp':\n",
        "            smiles_emb = self.gnn(batch['smiles_graph'].x.to(torch.float),\n",
        "                                  batch['smiles_graph'].edge_index,\n",
        "                                  batch['smiles_graph'].edge_attr,\n",
        "                                  batch['smiles_graph'].batch)\n",
        "        return smiles_emb\n",
        "    \n",
        "    def get_smiles_embedding_size(self):\n",
        "        return self.smiles_embedding_size"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate experiment-specific datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "upsampled = [False] # [True, False]\n",
        "experiments = (tasks, upsampled)\n",
        "\n",
        "for subset in itertools.product(*experiments):\n",
        "    task, use_upsampled = subset\n",
        "    protac_ds_kwargs = {\n",
        "        'precompute_smiles_as_graphs': True,\n",
        "        'poi_vectorizer': poi_vectorizer,\n",
        "        'e3_ligase_enc': e3_ligase_enc,\n",
        "        'poi_gene_enc': poi_gene_enc,\n",
        "        'cell_type_enc': cell_type_enc,\n",
        "    }\n",
        "    dataset_name = f'_{task}{\"_upsampled\" if use_upsampled else \"\"}_graph'\n",
        "    get_datasets(task,\n",
        "                 use_upsampled,\n",
        "                 dataset_name=dataset_name,\n",
        "                 regenerate_datasets=False,\n",
        "                 **protac_ds_kwargs)\n",
        "print('Datasets are ready to use.')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Optuna objective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gnn_objective(trial,\n",
        "                  gnn_type: Literal['gin', 'gat', 'gcn', 'attentivefp'] = 'gin',\n",
        "                  num_epochs: int = 10,\n",
        "                  task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                  loss_func: Callable | object = nn.HuberLoss(),\n",
        "                  enable_checkpointing: bool = True,\n",
        "                  num_gpus: int = 0) -> float:\n",
        "    # ==========================================================================\n",
        "    # Model-specific objective code\n",
        "    # ==========================================================================\n",
        "    # Setup SMILES Encoder arguments\n",
        "    trial.set_user_attr('gnn_type', gnn_type)\n",
        "    layer_sizes = [64, 128, 256, 512, 768]\n",
        "    smiles_encoder_gen_args = {\n",
        "        'hidden_channels': trial.suggest_int('hidden_channels', 64, 768, step=64), # trial.suggest_categorical('hidden_channels', layer_sizes),\n",
        "        'num_layers': trial.suggest_int('num_layers', 2, 8),\n",
        "        'dropout': trial.suggest_float('dropout', 0.01, 0.8),\n",
        "    }\n",
        "    if gnn_type != 'gin':\n",
        "        smiles_encoder_gen_args['out_channels'] = trial.suggest_categorical('out_channels', layer_sizes)    \n",
        "    if gnn_type == 'attentivefp':\n",
        "        smiles_encoder_gen_args['num_timesteps'] = trial.suggest_categorical('num_timesteps', [8, 16, 32] + layer_sizes)\n",
        "    else:\n",
        "        smiles_encoder_gen_args['jk'] = trial.suggest_categorical('jk', ['max', 'last', 'cat', 'lstm'])\n",
        "    smiles_encoder_gen_args['model_type'] = gnn_type\n",
        "    smiles_encoder = GnnSubModel\n",
        "    # Setup Wrapper Model arguments\n",
        "    num_layers_extra = trial.suggest_int('num_layers_extra', 2, 8)\n",
        "    hidden_channels_extra_features = [\n",
        "        trial.suggest_int(f'model_kwargs_layer_{i}_size', 64, 512, step=32) for i in range(num_layers_extra)\n",
        "    ]\n",
        "    model_kwargs = {\n",
        "        'use_extra_features': True, # trial.suggest_categorical('use_extra_features', [True, False]),\n",
        "        'hidden_channels_extra_features': hidden_channels_extra_features,\n",
        "        'dropout': trial.suggest_float('model_kwargs_dropout', 0.01, 0.8),\n",
        "        'learning_rate': trial.suggest_float('model_kwargs_learning_rate', 1e-5, 1e-2, log=True),\n",
        "        'batch_size': trial.suggest_categorical('model_kwargs_batch_size', [4, 8]),\n",
        "    }\n",
        "    accumulate_grad_batches = trial.suggest_categorical('accumulate_grad_batches', [1, 2, 4, 8])\n",
        "    # Retrieve specific datasets\n",
        "    use_upsampled = False\n",
        "    dataset_name = f'_{task}{\"_upsampled\" if use_upsampled else \"\"}_graph'\n",
        "    trial.set_user_attr('dataset_name', dataset_name)\n",
        "    ds = get_datasets(task, use_upsampled, dataset_name=dataset_name)\n",
        "    train_dataset = ds['train']\n",
        "    val_dataset = ds['val']\n",
        "    test_dataset = ds['test']\n",
        "    # Model-specific namings for reporting\n",
        "    model_name = 'gnn_model'\n",
        "    eventid = f'{trial.datetime_start.strftime(\"%Y%m%d-%H-%M-%S-\")}{uuid4()}'\n",
        "    trial_name = f'{gnn_type}-{trial.number}-{eventid}'\n",
        "    # ==========================================================================\n",
        "    # Standard and common code for all objectives\n",
        "    # ==========================================================================\n",
        "    # Standard namings for reporting\n",
        "    lightning_dir = os.path.join(checkpoint_dir, 'lightning')\n",
        "    model_checkpoint_dir = os.path.join(lightning_dir, 'models')\n",
        "    model_checkpoint = f'{model_name}-{trial_name}'\n",
        "    tensorboard_dir = os.path.join(lightning_dir, 'tensorboard', f'{model_name}_{task}')\n",
        "    reporting_config = {\n",
        "        'trial_name': trial_name,\n",
        "        'model_name': model_name,\n",
        "        'lightning_dir': lightning_dir,\n",
        "        'model_checkpoint_dir': model_checkpoint_dir,\n",
        "        'model_checkpoint': model_checkpoint,\n",
        "        'tensorboard_dir': tensorboard_dir,\n",
        "    }\n",
        "    trial_set_dict(trial, reporting_config)\n",
        "    # Train model via its generic function\n",
        "    return train_model(reporting_config=reporting_config,\n",
        "                       smiles_encoder=smiles_encoder,\n",
        "                       smiles_encoder_args=smiles_encoder_gen_args,\n",
        "                       train_dataset=train_dataset,\n",
        "                       val_dataset=val_dataset,\n",
        "                       test_dataset=test_dataset,\n",
        "                       # Optional arguments\n",
        "                       num_epochs=num_epochs,\n",
        "                       task=task,\n",
        "                       loss_func=loss_func,\n",
        "                       num_gpus=num_gpus,\n",
        "                       use_raytune=False,\n",
        "                       enable_checkpointing=enable_checkpointing,\n",
        "                       accumulate_grad_batches=accumulate_grad_batches,\n",
        "                       trial=trial,\n",
        "                       **model_kwargs)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run experiments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define experiments design points\n",
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "upsampled = [False] # [True, False]\n",
        "gnn_types = [\n",
        "    'attentivefp',\n",
        "    'gat',\n",
        "    'gcn',\n",
        "    'gin',\n",
        "]\n",
        "experiments = (tasks, upsampled, gnn_types)\n",
        "# Get all experiments combinations\n",
        "n_experiments = 0\n",
        "for subset in itertools.product(*experiments):\n",
        "    task, use_upsampled, gnn_type = subset\n",
        "    if use_upsampled and task != 'predict_active_inactive':\n",
        "        continue\n",
        "    n_experiments += 1\n",
        "# Set fixed parameters\n",
        "num_epochs = 50\n",
        "num_samples = 1000\n",
        "n_gpus = 1 if torch.cuda.is_available() else 0\n",
        "# loss_func = mean_absolute_error\n",
        "# loss_func = mean_squared_error\n",
        "loss_func = nn.HuberLoss(reduction='mean', delta=0.8) # Default 1.0\n",
        "# Define specific results dictionary in the global one\n",
        "experiments_results['results_gnn'] = load_result('results_gnn')\n",
        "if RETRAIN_GNN_MODEL or not experiments_results['results_gnn']:\n",
        "    # Run experiments\n",
        "    pl.utilities.memory.garbage_collection_cuda()\n",
        "    i = 0\n",
        "    best_ckpt = []\n",
        "    for experiment_id in itertools.product(*experiments):\n",
        "        task, use_upsampled, gnn_type = experiment_id\n",
        "        if use_upsampled and task != 'predict_active_inactive':\n",
        "            continue\n",
        "        print(f'-' * 80)\n",
        "        print(f'Experiment n.{i + 1} ({i / n_experiments * 100.0:.2f}% complete):')\n",
        "        experiments_results['results_gnn'][experiment_id] = {}\n",
        "        experiments_results['results_gnn'][experiment_id]['task'] = task\n",
        "        experiments_results['results_gnn'][experiment_id]['use_upsampled'] = use_upsampled\n",
        "        experiments_results['results_gnn'][experiment_id]['gnn_type'] = gnn_type\n",
        "        print_dict('Experiment:', experiments_results['results_gnn'][experiment_id])\n",
        "        print(f'-' * 80)\n",
        "        # Run Optuna study\n",
        "        direction = 'maximize' if task == 'predict_active_inactive' else 'minimize'\n",
        "        # optuna_pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
        "        optuna_pruner = optuna.pruners.HyperbandPruner(min_resource=2,\n",
        "                                                       max_resource=num_epochs,\n",
        "                                                       reduction_factor=3)\n",
        "        optuna_sampler = optuna.samplers.TPESampler(seed=42)\n",
        "        study = optuna.create_study(direction=direction,\n",
        "                                    pruner=optuna_pruner,\n",
        "                                    sampler=optuna_sampler)\n",
        "        study.optimize(lambda trial: gnn_objective(trial,\n",
        "                                                   task=task,\n",
        "                                                   gnn_type=gnn_type,\n",
        "                                                   num_epochs=num_epochs,\n",
        "                                                   loss_func=loss_func,\n",
        "                                                   enable_checkpointing=True,\n",
        "                                                   num_gpus=n_gpus),\n",
        "                       n_trials=num_samples,\n",
        "                       timeout=600)\n",
        "        trial = study.best_trial\n",
        "        experiments_results['results_gnn'][experiment_id]['trial'] = trial\n",
        "        # Reporting\n",
        "        print('-' * 80)\n",
        "        print(f'Experiment n.{i + 1} done ({(i + 1) / n_experiments * 100.0:.2f}% complete)')\n",
        "        print('Number of finished trials: {}'.format(len(study.trials)))\n",
        "        print(f'Best trial score: {trial.value}:')\n",
        "        print_dict('Experiment:', experiments_results['results_gnn'][experiment_id])\n",
        "        print_dict('Params:', trial.params)\n",
        "        print_dict('Attributes:', trial.user_attrs)\n",
        "        # Remove non-optimal checkpoints\n",
        "        model_name = trial.user_attrs['model_name']\n",
        "        checkpoint_root_dir = trial.user_attrs['model_checkpoint_dir']\n",
        "        best_ckpt.append(trial.user_attrs['trial_name'])\n",
        "        del_non_optimal_ckpt(checkpoint_root_dir, best_ckpt, model_name)\n",
        "        # Plotting training curves\n",
        "        trainer_logs = trial.user_attrs['trainer_log_dir']\n",
        "        descr = f' for GNN ({gnn_type.upper()})'\n",
        "        figpath = os.path.join(fig_dir, f'training_curves_{task}_{gnn_type}')\n",
        "        plot_training_curves(trainer_logs, experiment=descr, figpath=figpath)\n",
        "        i += 1\n",
        "    save_results(experiments_results['results_gnn'], result_name='results_gnn')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for phase in ['val', 'test']:\n",
        "    confusion_matrices = {}\n",
        "    plot_dummy = True\n",
        "\n",
        "    for experiment_id, design_points in experiments_results['results_gnn'].items():\n",
        "        trial = design_points['trial']\n",
        "        task = design_points['task']\n",
        "        # Model-specific description\n",
        "        gnn_type = trial.user_attrs[\"gnn_type\"]\n",
        "        descr = f'GNN ({gnn_type[0].upper()}{gnn_type[1:]})'\n",
        "        preds, cm = evaluate_experiment(task=task,\n",
        "                                        descr=descr,\n",
        "                                        dataset_name=trial.user_attrs['dataset_name'],\n",
        "                                        model_checkpoint=trial.user_attrs['model_checkpoint'],\n",
        "                                        plot_dummy=plot_dummy,\n",
        "                                        phase=phase,\n",
        "                                        plot_auc=True)\n",
        "        experiments_results['results_gnn'][experiment_id]['trial'].user_attrs.update(preds)\n",
        "        save_results(experiments_results['results_gnn'],\n",
        "                     result_name='results_gnn')\n",
        "        confusion_matrices[experiment_id] = (cm, descr)\n",
        "        plot_dummy = False\n",
        "        print_dict(f'Evaluation results for {descr}:', preds)\n",
        "        print('-' * 80)\n",
        "    plt.grid('both', alpha=0.7)\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1, fancybox=True) #, shadow=True)\n",
        "    plt.title(f'GNN {\"Validation\" if phase == \"val\" else \"Test\"} Set ROC Curve')\n",
        "\n",
        "    filename = os.path.join(fig_dir, f'roc_curve_{phase}_gnn')\n",
        "    plt.savefig(filename + '.pdf', bbox_inches='tight')\n",
        "    plt.savefig(filename + '.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Plot confusion matrixes:\n",
        "    for i, (_, (disp, descr)) in enumerate(confusion_matrices.items()):\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(f'{descr}')\n",
        "        filename = os.path.join(fig_dir, f'confusion_matrix_{phase}_gnn_n{i}')\n",
        "        plt.savefig(filename + '.pdf', bbox_inches='tight')\n",
        "        plt.savefig(filename + '.png', bbox_inches='tight')\n",
        "        # plt.show()\n",
        "        plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SMILES as Sentences - Transformers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tdLKYaCEQRk2"
      },
      "source": [
        "#### SSL via Finetuning MLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ssl_df = pd.read_csv(os.path.join(data_dir, 'protac', 'protac-db_ssl.csv'))\n",
        "ssl_df = ssl_df.dropna(subset=['Smiles_nostereo'])\n",
        "print(f'Length of SSL dataframe before removing SMILES duplicates: {len(ssl_df)}')\n",
        "print(ssl_df.shape)\n",
        "print(len(train_bin_df))\n",
        "ssl_df = pd.concat([ssl_df, train_bin_df], axis=0)\n",
        "print(ssl_df.shape)\n",
        "ssl_df = ssl_df.drop_duplicates(subset=['Smiles_nostereo'])\n",
        "print(f'Length of SSL dataframe after removing SMILES duplicates: {len(ssl_df)}')\n",
        "print(ssl_df.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load Tokenizer and setup PROTAC dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForMaskedLM,\n",
        "    TrainingArguments, Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    RobertaTokenizerFast,\n",
        "    RobertaForMaskedLM,    \n",
        ")\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "PRETRAINED_NLP_MODEL = 'seyonec/ChemBERTa-zinc-base-v1'\n",
        "# PRETRAINED_NLP_MODEL = 'DeepChem/ChemBERTa-10M-MTR'\n",
        "CHEMBERT_MLM_FOR_PROTACS = os.path.join(checkpoint_dir, 'chembert_mlm_for_protacs_' + PRETRAINED_NLP_MODEL.split('/')[-1])\n",
        "\n",
        "pretrained_bert_models = [\n",
        "    'entropy/roberta_zinc_480m',\n",
        "    'seyonec/ChemBERTa-zinc-base-v1',\n",
        "    'DeepChem/ChemBERTa-10M-MTR',\n",
        "]\n",
        "ssl_bert_models = ['SSL_' + b.split('/')[-1] for b in pretrained_bert_models]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Perplexity Score\n",
        "\n",
        "Refer to this [StackOverflow question](https://stackoverflow.com/questions/70464428/how-to-calculate-perplexity-of-a-sentence-using-huggingface-masked-language-mode).\n",
        "\n",
        "> From the huggingface documentation [here](https://huggingface.co/docs/transformers/perplexity) they mentioned that perplexity \"is not well defined for masked language models like BERT\".\n",
        ">\n",
        "> There is a paper [Masked Language Model Scoring](https://arxiv.org/abs/1910.14659) that explores pseudo-perplexity from masked language models and shows that pseudo-perplexity, while not being theoretically well justified, still performs well for comparing \"naturalness\" of texts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# def perplexity_score(model, tokenizer, sentence):\n",
        "#     tensor_input = tokenizer.encode(sentence, return_tensors='pt')\n",
        "#     print(f'tensor_input: {tensor_input}')\n",
        "#     repeat_input = tensor_input.repeat(tensor_input.size(-1) - 2, 1)\n",
        "#     mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
        "#     masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
        "#     labels = repeat_input.masked_fill(masked_input != tokenizer.mask_token_id, -100)\n",
        "    \n",
        "#     masked_input = masked_input.to(device)\n",
        "#     labels = labels.to(device)\n",
        "#     with torch.inference_mode():\n",
        "#         loss = model(masked_input, labels=labels).loss\n",
        "#     return np.exp(loss.item())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Scaled perplexity score over the entire dataset.\n",
        "\n",
        "> Typically, averaging occurs before exponentiation (which corresponds to the geometric average of exponentiated losses). The rationale is that we consider individual sentences as statistically independent, and so their joint probability is the product of their individual probability. Thus, by computing the geometric average of individual perplexities, we in some sense spread this joint probability evenly across sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perplexity_score(model, tokenizer, dataset):\n",
        "    loss = torch.zeros(1)\n",
        "    for elem in dataset:\n",
        "        tensor_input = tokenizer.encode(elem['smiles'], return_tensors='pt')\n",
        "        repeat_input = tensor_input.repeat(tensor_input.size(-1) - 2, 1)\n",
        "        mask = torch.ones(tensor_input.size(-1) - 1).diag(1)[:-2]\n",
        "        masked_input = repeat_input.masked_fill(mask == 1, tokenizer.mask_token_id)\n",
        "        labels = repeat_input.masked_fill(masked_input != tokenizer.mask_token_id, -100)\n",
        "        masked_input = masked_input.to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.inference_mode():\n",
        "            loss += model(masked_input, labels=labels).loss.item()\n",
        "    loss /= len(dataset)\n",
        "    return np.exp(loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from datasets import load_metric\n",
        "# import evaluate\n",
        "\n",
        "# # metric = evaluate.load('perplexity')\n",
        "# metric = load_metric('perplexity')\n",
        "# metric.compute(model_id=PRETRAINED_NLP_MODEL, input_texts=test_dataset)['mean_perplexity']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### SSL Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiments_results['results_transformer_ssl'] = load_result('results_transformer_ssl')\n",
        "# experiments_results['results_transformer_ssl'] = None\n",
        "\n",
        "if RETRAIN_SSL_MODEL or experiments_results['results_transformer_ssl'] is None:\n",
        "    experiments_results['results_transformer_ssl'] = {}\n",
        "    for bert_model, ssl_bert_model in zip(pretrained_bert_models, ssl_bert_models):\n",
        "        chembert_mlm_for_protacs = os.path.join(checkpoint_dir, ssl_bert_model)\n",
        "        # if os.path.exists(chembert_mlm_for_protacs):\n",
        "        #     continue\n",
        "\n",
        "        # Load pretrained model and tokenizer\n",
        "        if bert_model == 'entropy/roberta_zinc_480m':\n",
        "            tokenizer = RobertaTokenizerFast.from_pretrained(bert_model,\n",
        "                                                             max_len=128)\n",
        "            model = RobertaForMaskedLM.from_pretrained(bert_model)\n",
        "        else:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
        "            model = AutoModelForMaskedLM.from_pretrained(bert_model,\n",
        "                                                         output_hidden_states=True)\n",
        "        # Create a data collator (used in Trainer)\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer,\n",
        "                                                        mlm_probability=0.15)\n",
        "        # Generate PROTAC-Datasets\n",
        "        ssl_df['active'] = None\n",
        "        ssl_dataset = ProtacDataset(ssl_df,\n",
        "                                    use_for_ssl=True,\n",
        "                                    smiles_tokenizer=tokenizer)\n",
        "        val_dataset = ProtacDataset(val_df,\n",
        "                                    use_for_ssl=True,\n",
        "                                    smiles_tokenizer=tokenizer)\n",
        "        # Get perplexity score BEFORE training\n",
        "        model.to(device)\n",
        "        # Setup the Trainer\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=chembert_mlm_for_protacs,\n",
        "            evaluation_strategy='epoch',\n",
        "            learning_rate=2e-5,\n",
        "            num_train_epochs=5,\n",
        "            weight_decay=0.01,\n",
        "            optim='adamw_torch',\n",
        "            gradient_accumulation_steps=4,\n",
        "            per_device_train_batch_size=32,\n",
        "            per_device_eval_batch_size=16,\n",
        "            log_level='info',\n",
        "            logging_strategy='steps',\n",
        "            logging_steps=20,\n",
        "            push_to_hub=False,\n",
        "            fp16=torch.cuda.is_available(),\n",
        "            report_to='all',\n",
        "            seed=42,\n",
        "        )\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=ssl_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            data_collator=data_collator,\n",
        "        )\n",
        "        # Evaluate model BEFORE training\n",
        "        model.eval()\n",
        "        eval_results = trainer.evaluate()\n",
        "        train_perplexity = perplexity_score(model, tokenizer, ProtacDataset(train_df, use_for_ssl=True))\n",
        "        val_perplexity = perplexity_score(model, tokenizer, ProtacDataset(val_df, use_for_ssl=True))\n",
        "        print(f\"{bert_model} MLM Perplexity BEFORE training (Huggingface): {math.exp(eval_results['eval_loss']):.2f}\")\n",
        "        print(f'{bert_model} MLM perplexity on train BEFORE training: {train_perplexity:.2f}')\n",
        "        print(f'{bert_model} MLM perplexity on test BEFORE training: {val_perplexity:.2f}')\n",
        "        experiments_results['results_transformer_ssl'][ssl_bert_model] = {\n",
        "            'perplexity_huggingface_before': math.exp(eval_results['eval_loss']),\n",
        "            'train_perplexity_before': train_perplexity,\n",
        "            'val_perplexity_before': val_perplexity,\n",
        "        }\n",
        "        # Train the model and save it\n",
        "        pl.utilities.memory.garbage_collection_cuda()\n",
        "        model.train()\n",
        "        trainer.train()\n",
        "        trainer.save_model()\n",
        "        tokenizer.save_pretrained(chembert_mlm_for_protacs)\n",
        "        # Evaluate model AFTER training\n",
        "        model.eval()\n",
        "        eval_results = trainer.evaluate()\n",
        "        train_perplexity = perplexity_score(model, tokenizer, ProtacDataset(train_df, use_for_ssl=True))\n",
        "        val_perplexity = perplexity_score(model, tokenizer, ProtacDataset(val_df, use_for_ssl=True))\n",
        "        tmp = {\n",
        "            'perplexity_huggingface_after': math.exp(eval_results['eval_loss']),\n",
        "            'train_perplexity_after': train_perplexity,\n",
        "            'val_perplexity_after': val_perplexity,\n",
        "        }\n",
        "        experiments_results['results_transformer_ssl'][ssl_bert_model].update(tmp)\n",
        "        print_dict('Training scores:', eval_results)\n",
        "        print(f\"{bert_model} MLM Perplexity AFTER training (Huggingface): {math.exp(eval_results['eval_loss']):.2f}\")\n",
        "        print(f'{bert_model} MLM perplexity on train dataset AFTER training: {train_perplexity:.2f}')\n",
        "        print(f'{bert_model} MLM perplexity on test dataset AFTER training: {val_perplexity:.2f}')\n",
        "        print_dict('Perplexity:', experiments_results['results_transformer_ssl'][ssl_bert_model])\n",
        "        print('-' * 80)\n",
        "    save_results(experiments_results['results_transformer_ssl'], result_name='results_transformer_ssl')\n",
        "else:\n",
        "    print_dict('SSL Results:', experiments_results['results_transformer_ssl'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k, v in load_result('results_transformer_ssl').items():\n",
        "    print_dict(k, v)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Train BERT-based Model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate experiment-specific datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for task in ['predict_active_inactive']: # 'predict_pDC50_and_Dmax',\n",
        "    for bert_model, ssl_bert_model in zip(pretrained_bert_models, ssl_bert_models):\n",
        "        # Generate PROTAC-Datasets for pretrained BERT model\n",
        "        if bert_model == 'entropy/roberta_zinc_480m':\n",
        "            tokenizer = RobertaTokenizerFast.from_pretrained(bert_model,\n",
        "                                                             max_len=128)\n",
        "        else:\n",
        "            tokenizer = AutoTokenizer.from_pretrained(bert_model)\n",
        "        print(f'Tokenizer: {tokenizer}')\n",
        "        dataset_name = f'_tokenized_{bert_model.split(\"/\")[-1]}'\n",
        "        protac_ds_kwargs = {\n",
        "            'poi_vectorizer': poi_vectorizer,\n",
        "            'e3_ligase_enc': e3_ligase_enc,\n",
        "            'poi_gene_enc': poi_gene_enc,\n",
        "            'cell_type_enc': cell_type_enc,\n",
        "        }\n",
        "        if task == 'predict_active_inactive':\n",
        "            for upsampled in [False]: # [False, True]\n",
        "                protac_ds_kwargs['smiles_tokenizer'] = tokenizer\n",
        "                ds = get_datasets(task,\n",
        "                             upsampled,\n",
        "                             dataset_name=dataset_name,\n",
        "                             regenerate_datasets=True,\n",
        "                             **protac_ds_kwargs)\n",
        "                dl = DataLoader(ds['train'], batch_size=8, collate_fn=custom_collate, drop_last=True)\n",
        "                # batch = next(iter(dl))\n",
        "                # for k, v in batch.items():\n",
        "                #     if k == 'smiles_tokenized':\n",
        "                #         # print_dict(k, v)\n",
        "                #         for k, v in v.items():\n",
        "                #             print(k, v.size())\n",
        "                #     else:\n",
        "                #         print(k, v.size())\n",
        "                # print('')\n",
        "        else:\n",
        "            protac_ds_kwargs['smiles_tokenizer'] = tokenizer\n",
        "            ds = get_datasets(task,\n",
        "                         dataset_name=dataset_name,\n",
        "                         regenerate_datasets=True,\n",
        "                         **protac_ds_kwargs)\n",
        "        # Generate PROTAC-Datasets for SSL-ed BERT model\n",
        "        chembert_mlm_for_protacs = os.path.join(checkpoint_dir, ssl_bert_model)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(chembert_mlm_for_protacs)\n",
        "        print(f'Tokenizer (from SSL): {tokenizer}')\n",
        "        \n",
        "        dataset_name = f'_tokenized_{ssl_bert_model}'\n",
        "        protac_ds_kwargs['smiles_tokenizer'] = tokenizer\n",
        "        if task == 'predict_active_inactive':\n",
        "            for upsampled in [False]: # [False, True]\n",
        "                ds = get_datasets(task,\n",
        "                             upsampled,\n",
        "                             dataset_name=dataset_name,\n",
        "                             regenerate_datasets=True,\n",
        "                             **protac_ds_kwargs)\n",
        "                dl = DataLoader(ds['train'], batch_size=1, collate_fn=custom_collate, drop_last=True)\n",
        "                # batch = next(iter(dl))\n",
        "                # for k, v in batch.items():\n",
        "                #     if k == 'smiles_tokenized':\n",
        "                #         # print_dict(k, v)\n",
        "                #         for k, v in v.items():\n",
        "                #             print(k, v.size())\n",
        "                #     else:\n",
        "                #         print(k, v.size())\n",
        "                # print('')\n",
        "        else:\n",
        "            get_datasets(task,\n",
        "                         dataset_name=dataset_name,\n",
        "                         regenerate_datasets=True,\n",
        "                         **protac_ds_kwargs)\n",
        "print('Datasets ready to use.')    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate and restore ChemBERT model functions:\n",
        "\n",
        "(Check the this [question](https://datascience.stackexchange.com/questions/107212/get-sentence-embeddings-of-transformer-based-models) for the intuition and implementation behind `mean_pooling()`, which obtains a single SMILES embedding out of the ones generated by the RoBERTa model.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "\n",
        "def mean_pooling(model_output, attention_mask):\n",
        "    # First element of model_output contains all token embeddings\n",
        "    token_embeddings = model_output['last_hidden_state']\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
        "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
        "    return sum_embeddings / sum_mask\n",
        "\n",
        "\n",
        "class TransformerSubModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, checkpoint_path: str = 'seyonec/ChemBERTa-zinc-base-v1'):\n",
        "        super().__init__()\n",
        "        # Save the arguments passed to init\n",
        "        self.save_hyperparameters()\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        # ChemBERT for SMILES\n",
        "        self.config = AutoConfig.from_pretrained(checkpoint_path,\n",
        "                                                 output_hidden_states=True,\n",
        "                                                 num_labels=1)\n",
        "        self.chembert = AutoModelForSequenceClassification.from_pretrained(\n",
        "            checkpoint_path,\n",
        "            config=self.config\n",
        "        ).roberta\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        # Run ChemBert over the toeknized SMILES\n",
        "        input_ids = x_in['smiles_tokenized']['input_ids'].squeeze(dim=1)\n",
        "        attention_mask = x_in['smiles_tokenized']['attention_mask'].squeeze(dim=1)\n",
        "        smiles_embedding = self.chembert(input_ids, attention_mask)\n",
        "        # NOTE: Due to multi-head attention, the output of the Transformer is a\n",
        "        # sequence of hidden states, one for each input token. The following\n",
        "        # takes the mean of all token embeddings to get a single embedding.\n",
        "        smiles_embedding = mean_pooling(smiles_embedding, attention_mask)\n",
        "        return smiles_embedding\n",
        "    \n",
        "    def get_smiles_embedding_size(self):\n",
        "        return self.config.to_dict()['hidden_size']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Optuna objective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_bert_model(config,\n",
        "                     trial_name,\n",
        "                     trial = None,\n",
        "                     enable_checkpointing: bool = False,\n",
        "                     bert_model: str = 'seyonec/ChemBERTa-zinc-base-v1',\n",
        "                     num_epochs: int = 5,\n",
        "                     task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                     loss_func: Callable | object = nn.HuberLoss(),\n",
        "                     num_gpus: int = 0):\n",
        "    # Namings for reporting\n",
        "    model_name = 'transformer_model'\n",
        "    lightning_dir = os.path.join(checkpoint_dir, 'lightning')\n",
        "    model_checkpoint_dir = os.path.join(lightning_dir, 'models')\n",
        "    model_checkpoint = f'{model_name}-{trial_name}'\n",
        "    tensorboard_dir = os.path.join(lightning_dir, 'tensorboard', f'{model_name}_{task}')\n",
        "    reporting_config = {\n",
        "        'trial_name': trial_name,\n",
        "        'lightning_dir': lightning_dir,\n",
        "        'model_name': model_name,\n",
        "        'model_checkpoint_dir': model_checkpoint_dir,\n",
        "        'model_checkpoint': model_checkpoint,\n",
        "        'tensorboard_dir': tensorboard_dir,\n",
        "    }\n",
        "    if trial is not None:\n",
        "        trial_set_dict(trial, reporting_config)\n",
        "    # Setup arguments for Wrapper model\n",
        "    model_kwargs = {\n",
        "        'freeze_smiles_encoder': config['freeze_smiles_encoder'],\n",
        "        'use_extra_features': config['use_extra_features'],\n",
        "        'freeze_smiles_encoder': config['freeze_smiles_encoder'],\n",
        "        'hidden_channels_extra_features': config['hidden_channels_extra_features'],\n",
        "        'dropout': config['dropout'],\n",
        "        'learning_rate': config['learning_rate'],\n",
        "        'batch_size': config['batch_size'],\n",
        "    }\n",
        "    # Setup arguments for SMILES Encoder generator function\n",
        "    bert_model_path = os.path.join(checkpoint_dir, bert_model)\n",
        "    if os.path.exists(bert_model_path):\n",
        "        generator_args = {'checkpoint_path': bert_model_path}\n",
        "    else:\n",
        "        generator_args = {'checkpoint_path': bert_model}\n",
        "    # Get specific tokenized datasets for current BERT model\n",
        "    bert_model_stripped = bert_model.split('/')[-1]\n",
        "    dataset_name = f'_tokenized_{bert_model_stripped}'\n",
        "    ds = get_datasets(task, use_upsampled, dataset_name=dataset_name)\n",
        "    # Train model via its generic function\n",
        "    return train_model(reporting_config=reporting_config,\n",
        "                       smiles_encoder=TransformerSubModel,\n",
        "                       smiles_encoder_args=generator_args,\n",
        "                       train_dataset=ds['train'],\n",
        "                       val_dataset=ds['val'],\n",
        "                       test_dataset=ds['test'],\n",
        "                       num_epochs=num_epochs,\n",
        "                       task=task,\n",
        "                       loss_func=loss_func,\n",
        "                       num_gpus=num_gpus,\n",
        "                       use_raytune=False,\n",
        "                       trial=trial,\n",
        "                       accumulate_grad_batches=config['accumulate_grad_batches'],\n",
        "                       enable_checkpointing=enable_checkpointing,\n",
        "                       **model_kwargs)\n",
        "    \n",
        "\n",
        "def bert_objective(trial,\n",
        "                   bert_model: str = 'seyonec/ChemBERTa-zinc-base-v1',\n",
        "                   num_epochs: int = 5,\n",
        "                   task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                   loss_func: Callable | object = nn.HuberLoss(),\n",
        "                   num_gpus: int = 0):\n",
        "    # Setup Wrapper Model arguments\n",
        "    num_layers_extra = trial.suggest_int('num_layers_extra', 2, 8)\n",
        "    hidden_channels_extra_features = [\n",
        "        trial.suggest_int(f'layer_{i}_size', 64, 512, step=32) for i in range(num_layers_extra)\n",
        "    ]\n",
        "    config = {\n",
        "        'use_extra_features': True, # trial.suggest_categorical('use_extra_features', [True, False]),\n",
        "        'freeze_smiles_encoder': False, # trial.suggest_categorical('freeze_smiles_encoder', [True, False]),\n",
        "        'hidden_channels_extra_features': hidden_channels_extra_features,\n",
        "        'dropout': trial.suggest_float('dropout', 0.01, 0.8),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True),\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [4, 8]),\n",
        "        'accumulate_grad_batches': trial.suggest_categorical('accumulate_grad_batches', [1, 2, 4, 8]),\n",
        "    }\n",
        "    # Namings for reporting\n",
        "    eventid = f'{trial.datetime_start.strftime(\"%Y%m-%d%H-%M%S-\")}{uuid4()}'\n",
        "    trial_name = f'{\"freezed-\" if config[\"freeze_smiles_encoder\"] else \"\"}{trial.number}-{eventid}'\n",
        "    bert_model_stripped = bert_model.split('/')[-1]\n",
        "    dataset_name = f'_tokenized_{bert_model_stripped}'\n",
        "    trial.set_user_attr('bert_type', bert_model_stripped)\n",
        "    trial.set_user_attr('dataset_name', dataset_name)\n",
        "    # Finally train the BERT-based model\n",
        "    return train_bert_model(config=config,\n",
        "                            trial=trial,\n",
        "                            trial_name=trial_name,\n",
        "                            enable_checkpointing=False,\n",
        "                            bert_model=bert_model,\n",
        "                            num_epochs=num_epochs,\n",
        "                            task=task,\n",
        "                            loss_func=loss_func,\n",
        "                            num_gpus=num_gpus)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run experiments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define experiments design points\n",
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "upsampled = [False] # [True, False]\n",
        "bert_models_list = ssl_bert_models + pretrained_bert_models\n",
        "experiments = (tasks, upsampled, bert_models_list)\n",
        "# Get all experiments combinations\n",
        "n_experiments = 0\n",
        "for subset in itertools.product(*experiments):\n",
        "    task, use_upsampled, _ = subset  \n",
        "    if use_upsampled and task != 'predict_active_inactive':\n",
        "        continue\n",
        "    n_experiments += 1\n",
        "# Set fixed parameters\n",
        "num_epochs = 15\n",
        "num_samples = 1000\n",
        "n_gpus = 1 if torch.cuda.is_available() else 0\n",
        "# loss_func = mean_absolute_error\n",
        "# loss_func = mean_squared_error\n",
        "loss_func = nn.HuberLoss(reduction='mean', delta=0.8) # Default 1.0\n",
        "# Define specific results dictionary in the global one\n",
        "experiments_results['results_transformer'] = load_result('results_transformer')\n",
        "if RETRAIN_BERT_MODEL or experiments_results['results_transformer'] is None:\n",
        "    # Run experiments\n",
        "    i = 0\n",
        "    best_ckpt = []\n",
        "    for experiment_id in itertools.product(*experiments):\n",
        "        task, use_upsampled, bert_model = experiment_id\n",
        "        if use_upsampled and task != 'predict_active_inactive':\n",
        "            continue\n",
        "        print(f'-' * 80)\n",
        "        print(f'Experiment n.{i + 1}/{n_experiments} ({i / n_experiments * 100.0:.2f}% complete):')\n",
        "        print(f'\\ttask: {task}')\n",
        "        print(f'\\tuse_upsampled: {use_upsampled}')\n",
        "        print(f'\\tbert_model: {bert_model}')\n",
        "        print(f'-' * 80)\n",
        "        # Run Optuna study\n",
        "        direction = 'maximize' if task == 'predict_active_inactive' else 'minimize'\n",
        "        # optuna_pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
        "        optuna_pruner = optuna.pruners.HyperbandPruner(min_resource=2,\n",
        "                                                       max_resource=num_epochs,\n",
        "                                                       reduction_factor=3)\n",
        "        optuna_sampler = optuna.samplers.TPESampler(seed=42)\n",
        "        study = optuna.create_study(direction=direction,\n",
        "                                    pruner=optuna_pruner,\n",
        "                                    sampler=optuna_sampler)\n",
        "        study.optimize(lambda trial: bert_objective(trial,\n",
        "                                                    task=task,\n",
        "                                                    bert_model=bert_model,\n",
        "                                                    num_epochs=num_epochs,\n",
        "                                                    loss_func=loss_func,\n",
        "                                                    num_gpus=n_gpus),\n",
        "                    n_trials=num_samples,\n",
        "                    timeout=600 * 2)\n",
        "        best_trial = study.best_trial\n",
        "        # Reporting\n",
        "        print('-' * 80)\n",
        "        print(f'Experiment n.{i + 1}/{n_experiments} done ({(i + 1) / n_experiments * 100.0:.2f}% complete)')\n",
        "        print(f'Number of finished trials: {len(study.trials)}')\n",
        "        print(f'Best trial value: {best_trial.value}')\n",
        "        # Retrain model with best hyperparameters\n",
        "        # NOTE: We are training at the end in order to not pollute the disk with\n",
        "        # non-optimal checkpoints\n",
        "        # NOTE: Set the non-optimized parameters to the fixed ones\n",
        "        print_dict('Hyperparams:', best_trial.params)\n",
        "        print('Retraining model with best hyperparameters...', end='')\n",
        "        config = best_trial.params.copy()\n",
        "        num_layers_extra = config['num_layers_extra']\n",
        "        hidden_channels_extra_features = [\n",
        "            config[f'layer_{i}_size'] for i in range(num_layers_extra)\n",
        "        ]\n",
        "        config['use_extra_features'] = True\n",
        "        config['freeze_smiles_encoder'] = False\n",
        "        config['hidden_channels_extra_features'] = hidden_channels_extra_features\n",
        "        train_bert_model(config=config,\n",
        "                         trial_name=best_trial.user_attrs['trial_name'],\n",
        "                         trial=best_trial,\n",
        "                         enable_checkpointing=True, # This time enable checkpointing\n",
        "                         bert_model=bert_model,\n",
        "                         num_epochs=num_epochs,\n",
        "                         task=task,\n",
        "                         loss_func=loss_func,\n",
        "                         num_gpus=n_gpus)\n",
        "        print('done')\n",
        "        # Update experiment results\n",
        "        # NOTE: The function `train_bert_model` updates the `best_trial` object\n",
        "        experiments_results['results_transformer'][experiment_id] = {}\n",
        "        experiments_results['results_transformer'][experiment_id]['task'] = task\n",
        "        experiments_results['results_transformer'][experiment_id]['trial'] = best_trial\n",
        "        experiments_results['results_transformer'][experiment_id]['use_upsampled'] = use_upsampled\n",
        "        print_dict('Experiment:', experiments_results['results_transformer'][experiment_id])\n",
        "        print_dict('Hyperparams:', best_trial.params)\n",
        "        print_dict('Attributes:', best_trial.user_attrs)\n",
        "        # Plotting training curves\n",
        "        trainer_logs = best_trial.user_attrs['trainer_log_dir']\n",
        "        descr = f' for Transformer ({best_trial.user_attrs[\"bert_type\"]})'\n",
        "        figpath = os.path.join(fig_dir, f'training_curves_{task}_{best_trial.user_attrs[\"bert_type\"]}')\n",
        "        plot_training_curves(trainer_logs, experiment=descr, figpath=figpath)\n",
        "        # Remove non-optimal checkpoints\n",
        "        model_name = best_trial.user_attrs['model_name']\n",
        "        checkpoint_root_dir = best_trial.user_attrs['model_checkpoint_dir']\n",
        "        best_ckpt.append(best_trial.user_attrs['trial_name'])\n",
        "        del_non_optimal_ckpt(checkpoint_root_dir, best_ckpt, model_name)\n",
        "        i += 1\n",
        "    # Save results\n",
        "    save_results(experiments_results['results_transformer'],\n",
        "                result_name='results_transformer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiments_results['results_transformer'] = load_result('results_transformer')\n",
        "if experiments_results['results_transformer'] is not None:\n",
        "    for experiment_id, design_points in experiments_results['results_transformer'].items():\n",
        "        task = design_points['task']\n",
        "        trial = design_points['trial']\n",
        "        use_upsampled = design_points['use_upsampled']\n",
        "        print(f'Experiment: {experiment_id}')\n",
        "        print_dict('Hyperparams:', trial.params)\n",
        "        print_dict('Attributes:', trial.user_attrs)\n",
        "        model_checkpoint = trial.user_attrs['model_checkpoint']\n",
        "        model = WrapperModel.load_from_checkpoint(model_checkpoint)\n",
        "        print('-' * 80)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for phase in ['val', 'test']:\n",
        "    confusion_matrices = {}\n",
        "    plot_dummy = True\n",
        "\n",
        "    for experiment_id, design_points in experiments_results['results_transformer'].items():\n",
        "        trial = design_points['trial']\n",
        "        task = design_points['task']\n",
        "        # Model-specific description\n",
        "        descr = f'Transformer [{trial.user_attrs[\"bert_type\"]}]'\n",
        "        preds, cm = evaluate_experiment(task=task,\n",
        "                                        descr=descr,\n",
        "                                        dataset_name=trial.user_attrs['dataset_name'],\n",
        "                                        model_checkpoint=trial.user_attrs['model_checkpoint'],\n",
        "                                        plot_dummy=plot_dummy,\n",
        "                                        phase=phase,\n",
        "                                        plot_auc=True)\n",
        "        experiments_results['results_transformer'][experiment_id]['trial'].user_attrs.update(preds)\n",
        "        save_results(experiments_results['results_transformer'],\n",
        "                     result_name='results_transformer')\n",
        "        confusion_matrices[experiment_id] = (cm, descr)\n",
        "        plot_dummy = False\n",
        "        print_dict(f'Evaluation results for {descr}:', preds)\n",
        "        print('-' * 80)\n",
        "    plt.grid('both', alpha=0.7)\n",
        "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1, fancybox=True) #, shadow=True)\n",
        "    plt.title(f'Transformers {\"Validation\" if phase == \"val\" else \"Test\"} Set ROC Curve')\n",
        "\n",
        "    filename = os.path.join(fig_dir, f'roc_curve_{phase}_transformers')\n",
        "    plt.savefig(filename + '.pdf', bbox_inches='tight')\n",
        "    plt.savefig(filename + '.png', bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    # Plot confusion matrixes:\n",
        "    for i, (_, (disp, descr)) in enumerate(confusion_matrices.items()):\n",
        "        disp.plot(cmap=plt.cm.Blues)\n",
        "        plt.title(f'{descr}')\n",
        "        filename = os.path.join(fig_dir, f'confusion_matrix_{phase}_transformers_n{i}')\n",
        "        plt.savefig(filename + '.pdf', bbox_inches='tight')\n",
        "        plt.savefig(filename + '.png', bbox_inches='tight')\n",
        "        # plt.show()\n",
        "        plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Active Learning and Semi-Supervised Learning\n",
        "\n",
        "[Interesting thesis about the subject](https://odr.chalmers.se/server/api/core/bitstreams/356f3738-b743-4c5a-ab5e-233503f69024/content)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "TODOs:\n",
        "\n",
        "* The SSL data are missing `poi_seq` and `cell_type`: maybe move the parsing at the end of the data cleaning process?\n",
        "* Implement the training loop suggested by ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ssl_df = pd.read_csv(os.path.join(data_dir, 'protac', 'protac-db_ssl.csv'))\n",
        "ssl_df = ssl_df.dropna(subset=['Smiles_nostereo'])\n",
        "ssl_df = ssl_df.rename(columns={'E3ligase': 'e3_ligase'})\n",
        "ssl_df['active'] = False\n",
        "protac_ds_kwargs = {\n",
        "        'precompute_fingerprints': False,\n",
        "        'use_morgan_fp': True,\n",
        "        'morgan_bits': 4096,\n",
        "        'morgan_atomic_radius': 2,\n",
        "        'poi_vectorizer': poi_vectorizer,\n",
        "        'e3_ligase_enc': e3_ligase_enc,\n",
        "        'poi_gene_enc': poi_gene_enc,\n",
        "        'cell_type_enc': cell_type_enc,\n",
        "    }\n",
        "# train_dataset = ProtacDataset(train_bin_df, **protac_ds_kwargs)\n",
        "# val_dataset = ProtacDataset(ssl_df, **protac_ds_kwargs)\n",
        "# test_dataset = ProtacDataset(test_bin_df, **protac_ds_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = 'fp_model_protac_pedia'\n",
        "trial_name = 'v0'\n",
        "dataset_name = '_fp2048_radius2_path1-8'\n",
        "num_epochs = 15\n",
        "num_samples = 20\n",
        "# Setup SMILES Encoder arguments\n",
        "smiles_encoder_gen_args = {\n",
        "    'fp_type': 'morgan_fp',\n",
        "    'fp_bits': 2048,\n",
        "    'hidden_channels': [128, 128, 128],\n",
        "    'norm_layer': nn.BatchNorm1d,\n",
        "    'dropout': 0.3,\n",
        "}\n",
        "smiles_encoder = FingerprintSubModel\n",
        "# Setup Wrapper Model arguments\n",
        "model_kwargs = {\n",
        "    'use_extra_features': True, # trial.suggest_categorical('use_extra_features', [True, False]),\n",
        "    'hidden_channels_extra_features': [128, 64],\n",
        "    'dropout': 0.3,\n",
        "    'learning_rate': 1e-4,\n",
        "    'batch_size': 128,\n",
        "}\n",
        "protac_ds_kwargs = {\n",
        "    'precompute_fingerprints': True,\n",
        "    'use_morgan_fp': True,\n",
        "    'use_maccs_fp': True,\n",
        "    'use_path_fp': True,\n",
        "    'morgan_atomic_radius': 2,\n",
        "    'morgan_bits': 2048,\n",
        "    'path_bits': 2048,\n",
        "    'fp_min_path': 1,\n",
        "    'fp_max_path': 8,\n",
        "    'poi_vectorizer': poi_vectorizer,\n",
        "    'e3_ligase_enc': e3_ligase_enc,\n",
        "    'poi_gene_enc': poi_gene_enc,\n",
        "    'cell_type_enc': cell_type_enc,\n",
        "}\n",
        "ds = get_datasets(task, use_upsampled, dataset_name=dataset_name, regenerate_datasets=False, **protac_ds_kwargs)\n",
        "# Standard namings for reporting\n",
        "lightning_dir = os.path.join(checkpoint_dir, 'lightning')\n",
        "model_checkpoint_dir = os.path.join(lightning_dir, 'models')\n",
        "model_checkpoint = f'{model_name}-{trial_name}'\n",
        "tensorboard_dir = os.path.join(lightning_dir, 'tensorboard', f'{model_name}_{task}')\n",
        "reporting_config = {\n",
        "    'trial_name': trial_name,\n",
        "    'model_name': model_name,\n",
        "    'lightning_dir': lightning_dir,\n",
        "    'model_checkpoint_dir': model_checkpoint_dir,\n",
        "    'model_checkpoint': model_checkpoint,\n",
        "    'tensorboard_dir': tensorboard_dir,\n",
        "}\n",
        "trial = optuna.trial.FixedTrial({})\n",
        "# Train model via its generic function\n",
        "train_model(reporting_config=reporting_config,\n",
        "            smiles_encoder=smiles_encoder,\n",
        "            smiles_encoder_args=smiles_encoder_gen_args,\n",
        "            train_dataset=ds['train'],\n",
        "            val_dataset=ds['val'],\n",
        "            test_dataset=ds['test'],\n",
        "            # Optional arguments\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=1,\n",
        "            use_raytune=False,\n",
        "            enable_checkpointing=True,\n",
        "            trial=trial,\n",
        "            **model_kwargs)\n",
        "descr = ' MLP'\n",
        "plot_training_curves(trial.user_attrs['trainer_log_dir'], experiment=descr)\n",
        "\n",
        "model = WrapperModel.load_from_checkpoint(trial.user_attrs['model_checkpoint'])\n",
        "model.train_dataset = ds['train']\n",
        "model.val_dataset = ds['val']\n",
        "model.test_dataset = ds['test']\n",
        "# model.learning_rate = 1e-3\n",
        "# num_epochs = 10\n",
        "\n",
        "# train_model(reporting_config=reporting_config,\n",
        "#             smiles_encoder=smiles_encoder,\n",
        "#             smiles_encoder_args=smiles_encoder_gen_args,\n",
        "#             train_dataset=ds['train'],\n",
        "#             val_dataset=ds['val'],\n",
        "#             test_dataset=ds['test'],\n",
        "#             model=model,\n",
        "#             # Optional arguments\n",
        "#             num_epochs=num_epochs,\n",
        "#             num_gpus=1,\n",
        "#             enable_checkpointing=True,\n",
        "#             trial=trial,\n",
        "#             **model_kwargs)\n",
        "# descr = ' for MLP'\n",
        "# plot_training_curves(trial.user_attrs['trainer_log_dir'], experiment=descr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example implementation of calculate_uncertainty_scores using entropy\n",
        "def calculate_uncertainty_scores(predictions):\n",
        "    probabilities = torch.sigmoid(predictions)\n",
        "    entropy = -torch.mean((probabilities * torch.log(probabilities + 1e-8)) + ((1 - probabilities) * torch.log(1 - probabilities + 1e-8)), dim=1)\n",
        "    return entropy\n",
        "\n",
        "model.train_dataset = ds['train']\n",
        "model.val_dataset = ds['val_protac_pedia']\n",
        "model.test_dataset = ds['test']\n",
        "preds = get_eval_results(model, num_gpus=1, run_lightning_eval=False, return_logits_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "len(ConcatDataset([ds['train'], ds['train_protac_pedia']]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[Maybe a relevant paper...](https://ieeexplore.ieee.org/document/9533839)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = load_result('results_fp')[('predict_active_inactive', 4096, False)]\n",
        "trial = res['trial']\n",
        "oracle = WrapperModel.load_from_checkpoint(trial.user_attrs['model_checkpoint'])\n",
        "print(oracle.smiles_encoder.hparams)\n",
        "protac_ds_kwargs = {\n",
        "    'precompute_fingerprints': True,\n",
        "    'use_morgan_fp': True,\n",
        "    'use_maccs_fp': True,\n",
        "    'use_path_fp': True,\n",
        "    'morgan_atomic_radius': trial.params['radius'],\n",
        "    'morgan_bits': oracle.smiles_encoder.hparams['fp_bits'],\n",
        "    'path_bits': oracle.smiles_encoder.hparams['fp_bits'],\n",
        "    'fp_min_path': 1,\n",
        "    'fp_max_path': trial.params['fp_max_path'],\n",
        "    'poi_vectorizer': poi_vectorizer,\n",
        "    'e3_ligase_enc': e3_ligase_enc,\n",
        "    'poi_gene_enc': poi_gene_enc,\n",
        "    'cell_type_enc': cell_type_enc,\n",
        "}\n",
        "ds = get_datasets(dataset_name=trial.user_attrs['dataset_name'], regenerate_datasets=False, **protac_ds_kwargs)\n",
        "# oracle.train_dataset = ds['train']\n",
        "# oracle.val_dataset = ds['val']\n",
        "# oracle.test_dataset = ds['test']\n",
        "\n",
        "# preds = get_eval_results(oracle, num_gpus=1, run_lightning_eval=False, return_logits_only=True)\n",
        "# predictions = torch.sigmoid(torch.Tensor(preds['val_logits']))\n",
        "# # predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tmp = ProtacDataset(ds['train_protac_pedia'].dataframe[:25], **ds['train_protac_pedia'].hparams)\n",
        "print(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "def active_learning(num_iterations=1, confidence_threshold=0.7, warmup_steps=5):\n",
        "    # Initialize the oracle model (pretrained model)\n",
        "    res = load_result('results_fp')[('predict_active_inactive', 4096, False)]\n",
        "    trial = res['trial']\n",
        "    oracle = WrapperModel.load_from_checkpoint(trial.user_attrs['model_checkpoint'])\n",
        "    # oracle.smiles_encoder.hparams\n",
        "    ds = get_datasets(dataset_name=trial.user_attrs['dataset_name'])\n",
        "    train_dataset = ds['train']\n",
        "    val_dataset = ds['val']\n",
        "    test_dataset = ds['test']\n",
        "    train_dataset_al = ds['train_protac_pedia']\n",
        "    val_dataset_al = ds['val_protac_pedia']\n",
        "    \n",
        "    num_epochs = 10\n",
        "    smiles_encoder_gen_args = {\n",
        "        'fp_type': 'morgan_fp',\n",
        "        'fp_bits': 4096,\n",
        "        'hidden_channels': [128, 128, 128],\n",
        "        'norm_layer': nn.BatchNorm1d,\n",
        "        'dropout': 0.3,\n",
        "    }\n",
        "    smiles_encoder = FingerprintSubModel\n",
        "    # Setup Wrapper Model arguments\n",
        "    model_kwargs = {\n",
        "        'use_extra_features': True, # trial.suggest_categorical('use_extra_features', [True, False]),\n",
        "        'hidden_channels_extra_features': [128, 64],\n",
        "        'dropout': 0.3,\n",
        "        'learning_rate': 1e-4,\n",
        "        'batch_size': 128,\n",
        "    }\n",
        "    train_model(reporting_config=reporting_config,\n",
        "            smiles_encoder=smiles_encoder,\n",
        "            smiles_encoder_args=smiles_encoder_gen_args,\n",
        "            train_dataset=train_dataset,\n",
        "            val_dataset=val_dataset,\n",
        "            test_dataset=test_dataset,\n",
        "            # Optional arguments\n",
        "            num_epochs=num_epochs,\n",
        "            num_gpus=1,\n",
        "            use_raytune=False,\n",
        "            enable_checkpointing=True,\n",
        "            trial=trial,\n",
        "            **model_kwargs)\n",
        "    descr = ' MLP (starting)'\n",
        "    plot_training_curves(trial.user_attrs['trainer_log_dir'], experiment=descr)\n",
        "    initial_model = WrapperModel.load_from_checkpoint(trial.user_attrs['model_checkpoint'])\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        # Setup Oracle val dataset as AL dataset to get predictions\n",
        "        oracle.val_dataset = train_dataset_al\n",
        "        oracle.test_dataset = test_dataset\n",
        "        # Get predictions from oracle\n",
        "        preds = get_eval_results(oracle, num_gpus=1, run_lightning_eval=False, return_logits_only=True)\n",
        "        predictions = torch.sigmoid(torch.Tensor(preds['val_logits'])).flatten()\n",
        "        # Get pseudo-labels from the oracle on AL dataset:\n",
        "        pseudo_labels = torch.zeros_like(predictions) - 1.0\n",
        "        pseudo_labels[predictions > confidence_threshold] = 1.0\n",
        "        pseudo_labels[(1 - predictions) > confidence_threshold] = 0.0\n",
        "        print(f'Iter.N.{i}) Active:   {len(pseudo_labels[pseudo_labels == 1.0])}')\n",
        "        print(f'Iter.N.{i}) Inactive: {len(pseudo_labels[pseudo_labels == 0.0])}')\n",
        "\n",
        "        high_confidence_idx = (pseudo_labels != -1).flatten().numpy()\n",
        "        # Update labels accordingly\n",
        "        train_dataset_al.dataframe.iloc[pseudo_labels == 1.0]['active'] = True\n",
        "        train_dataset_al.dataframe.iloc[pseudo_labels == 0.0]['active'] = False\n",
        "        high_confidence_df = train_dataset_al.dataframe[high_confidence_idx]\n",
        "        low_confidence_df = train_dataset_al.dataframe[~high_confidence_idx]\n",
        "        \n",
        "        new_labeled_ds = ProtacDataset(high_confidence_df, **train_dataset_al.hparams)\n",
        "        train_dataset_al = ProtacDataset(low_confidence_df, **train_dataset_al.hparams)\n",
        "        \n",
        "        train_df = pd.concat([train_dataset.dataframe, new_labeled_ds.dataframe])\n",
        "        train_dataset = ProtacDataset(train_df, **train_dataset.hparams)\n",
        "        print(f'Iter.N.{i}) Len Train dataset: {len(train_dataset)}')\n",
        "        \n",
        "        if i == 0:\n",
        "            oracle = initial_model\n",
        "        oracle.train_dataset = train_dataset\n",
        "        oracle.val_dataset = val_dataset\n",
        "        oracle.test_dataset = test_dataset\n",
        "        \n",
        "        train_model(reporting_config=reporting_config,\n",
        "                    smiles_encoder=smiles_encoder,\n",
        "                    smiles_encoder_args=smiles_encoder_gen_args,\n",
        "                    train_dataset=train_dataset,\n",
        "                    val_dataset=val_dataset,\n",
        "                    test_dataset=test_dataset,\n",
        "                    model=oracle,\n",
        "                    # Optional arguments\n",
        "                    num_epochs=num_epochs,\n",
        "                    num_gpus=1,\n",
        "                    enable_checkpointing=True,\n",
        "                    trial=trial,\n",
        "                    **model_kwargs)\n",
        "        descr = ' for MLP'\n",
        "        plot_training_curves(trial.user_attrs['trainer_log_dir'], experiment=descr)\n",
        "        oracle = WrapperModel.load_from_checkpoint(trial.user_attrs['model_checkpoint'])\n",
        "        # Update train dataset with confident pseudo-labels\n",
        "        # Remove confident pseudo-labels from AL train dataset\n",
        "        # Train AL model on updated train dataset\n",
        "        # if AL model accuracy > Oracle accuracy:\n",
        "        #   break or oracle = AL model?\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "#     oracle.train_dataset = ds['train']\n",
        "#     oracle.val_dataset = ds['val']\n",
        "#     oracle.test_dataset = ds['test']\n",
        "    \n",
        "    \n",
        "#     # Randomly select initial samples\n",
        "#     initial_indices = torch.randperm(len(train_dataset))[:num_initial_samples]\n",
        "#     train_loader = DataLoader(train_dataset, batch_size=64, sampler=SubsetRandomSampler(initial_indices))\n",
        "    \n",
        "#     # Train the oracle model on initial samples\n",
        "#     trainer = pl.Trainer(max_epochs=num_epochs)\n",
        "#     trainer.fit(oracle, train_loader)\n",
        "    \n",
        "#     # Extend the dataset using pseudo-labeling from the oracle\n",
        "#     unlabeled_indices = torch.tensor(list(set(range(len(train_dataset))) - set(initial_indices.tolist()))))\n",
        "#     unlabeled_loader = DataLoader(train_dataset, batch_size=64, sampler=SubsetRandomSampler(unlabeled_indices))\n",
        "    \n",
        "#     pseudo_labels = []\n",
        "#     confident_indices = []\n",
        "    \n",
        "#     for images, _ in unlabeled_loader:\n",
        "#         with torch.no_grad():\n",
        "#             outputs = oracle(images)\n",
        "#             probabilities = torch.softmax(outputs, dim=1)\n",
        "        \n",
        "#         confident_mask = (probabilities[:, 1] > confidence_threshold)  # Select confident positive examples\n",
        "#         confident_indices.extend(unlabeled_indices[confident_mask].tolist())\n",
        "#         pseudo_labels.extend((probabilities[:, 1] >= 0.5).long()[confident_mask].tolist())\n",
        "        \n",
        "#     train_dataset.targets = torch.cat((train_dataset.targets, torch.tensor(pseudo_labels)))\n",
        "#     train_dataset.data = torch.cat((train_dataset.data, unlabeled_loader.dataset.data[confident_indices]))\n",
        "    \n",
        "#     # Train the model on the extended dataset\n",
        "#     model = Classifier()  # Replace with your binary classification model\n",
        "#     train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "#     trainer.fit(model, train_loader)\n",
        "    \n",
        "#     return model\n",
        "\n",
        "# # Run the active learning loop\n",
        "# confidence_threshold = 0.9  # Adjust the threshold as needed\n",
        "# model = active_learning(num_initial_samples=100, num_queries=10, num_epochs=5, confidence_threshold=confidence_threshold)\n",
        "\n",
        "active_learning(num_iterations=3, confidence_threshold=0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define your active learning function\n",
        "def active_learning(datasets, model, num_iterations, batch_size):\n",
        "    # Create a DataLoader for the unlabeled dataset\n",
        "    unlabeled_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    # Initialize an empty list to store the selected samples\n",
        "    selected_samples = []\n",
        "    \n",
        "    \n",
        "    train_dataset = datasets['train']\n",
        "    val_dataset = datasets['val']\n",
        "    test_dataset = datasets['test']\n",
        "    train_dataset_active = datasets['train_protac_pedia']\n",
        "    val_dataset_active = datasets['val_protac_pedia']\n",
        "    \n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        model.train_dataset = ds['train']\n",
        "        model.val_dataset = ds['val_protac_pedia']\n",
        "        model.test_dataset = ds['test']\n",
        "        # Get predictions for all unlabeled samples\n",
        "        preds = get_eval_results(model, num_gpus=1, run_lightning_eval=False,\n",
        "                                 return_logits_only=True)\n",
        "        predictions = torch.Tensor(preds['val_logits'])\n",
        "\n",
        "        # Calculate uncertainty scores (e.g., entropy) for each prediction\n",
        "        uncertainty_scores = calculate_uncertainty_scores(predictions)\n",
        "\n",
        "        # Select the samples with the highest uncertainty scores\n",
        "        num_samples_to_select = min(batch_size, len(dataset))\n",
        "        selected_indices = torch.topk(uncertainty_scores, num_samples_to_select).indices\n",
        "\n",
        "        # Add the selected samples to the training set\n",
        "        selected_samples.extend(dataset[selected_indices])\n",
        "        # Remove the selected samples from the unlabeled set\n",
        "        dataset.remove_samples(selected_indices)\n",
        "\n",
        "        # Train the model on the updated training set\n",
        "        trainer = pl.Trainer(max_epochs=10)  # Modify the parameters as needed\n",
        "        model = Classifier()  # Create a new instance of the model\n",
        "        trainer.fit(model, DataLoader(dataset, batch_size=batch_size))\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "        trial = optuna.trial.FixedTrial({})\n",
        "        # Train model via its generic function\n",
        "        train_model(reporting_config=reporting_config,\n",
        "                    model=model,\n",
        "                    train_dataset=ds['train'],\n",
        "                    val_dataset=ds['val'],\n",
        "                    test_dataset=ds['test'],\n",
        "                    # Optional arguments\n",
        "                    num_epochs=num_epochs,\n",
        "                    num_gpus=1,\n",
        "                    use_raytune=False,\n",
        "                    enable_checkpointing=True,\n",
        "                    trial=trial,\n",
        "                    **model_kwargs)\n",
        "        descr = ' MLP (active learning)'\n",
        "        plot_training_curves(trial.user_attrs['trainer_log_dir'], experiment=descr)\n",
        "\n",
        "        model = WrapperModel.load_from_checkpoint(trial.user_attrs['model_checkpoint'])\n",
        "        model.train_dataset = ds['train']\n",
        "        model.val_dataset = ds['val']\n",
        "        model.test_dataset = ds['test']\n",
        "\n",
        "\n",
        "    return selected_samples"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6gG70zGRPiUi"
      },
      "source": [
        "### SMILES as Graphs - GNNs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Via GNN Layers\n",
        "\n",
        "Following this [tutorial](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial7/GNN_overview.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gnn_layer_by_name = {\n",
        "    'GCN': geom_nn.GCNConv,\n",
        "    'GAT': geom_nn.GATConv,\n",
        "    'GraphConv': geom_nn.GraphConv\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 c_in: int,\n",
        "                 c_hidden: int,\n",
        "                 c_out: int,\n",
        "                 num_layers: int = 2,\n",
        "                 layer_name: Literal['GCN', 'GAT', 'GraphConv'] = 'GCN',\n",
        "                 dp_rate: float = 0.1,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of the output features. Usually number of classes in classification\n",
        "            num_layers - Number of \"hidden\" graph layers\n",
        "            layer_name - String of the graph layer to use\n",
        "            dp_rate - Dropout rate to apply throughout the network\n",
        "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        gnn_layer = gnn_layer_by_name[layer_name]\n",
        "\n",
        "        layers = []\n",
        "        in_channels, out_channels = c_in, c_hidden\n",
        "        # Interleave graph layers with ReLU and Dropout\n",
        "        for l_idx in range(num_layers - 1):\n",
        "            layers += [\n",
        "                gnn_layer(in_channels=in_channels,\n",
        "                          out_channels=out_channels,\n",
        "                          **kwargs),\n",
        "                nn.Dropout(dp_rate),\n",
        "                nn.ReLU(inplace=True),\n",
        "            ]\n",
        "            # if 'heads' in kwargs and 'GAT' in layer_name:\n",
        "            #     # For GAT, we need to update the input dimensionality\n",
        "            #     if kwargs.get('concat', True):\n",
        "            #         in_channels = kwargs['heads'] * c_hidden\n",
        "            # else:\n",
        "            #     in_channels = c_hidden\n",
        "            in_channels = c_hidden\n",
        "        layers += [gnn_layer(in_channels=in_channels,\n",
        "                             out_channels=c_out,\n",
        "                             **kwargs)]\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "        \"\"\"\n",
        "        for l in self.layers:\n",
        "            # NOTE: For graph layers, we need to add the \"edge_index\" tensor as\n",
        "            # additional input. All PyTorch Geometric graph layer inherit the\n",
        "            # class \"MessagePassing\", hence we can simply check the class type.\n",
        "            if isinstance(l, geom_nn.MessagePassing):\n",
        "                x = l(x, edge_index)\n",
        "            else:\n",
        "                x = l(x)\n",
        "        return x"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define GNN sub-model:\n",
        "\n",
        "(TODO: Maybe use a predefined model? [Models available in Pytorch Geometric.](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#models))\n",
        "\n",
        "* GatedGraphConv\n",
        "* GIN\n",
        "* Aggregation functions in general (AttentionalAggregation seems to be the most promising one)\n",
        "* DepthSumPooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GnnSubModel(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 c_hidden: int,\n",
        "                 c_out: int,\n",
        "                 num_layers: int = 2,\n",
        "                 layer_name: Literal['GCN', 'GAT', 'GraphConv'] = 'GCN',\n",
        "                 dp_rate: float = 0.1,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        # Set our init args as class attributes\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        self.save_hyperparameters()\n",
        "        # Define PyTorch model\n",
        "        # NOTE: `num_node_features` definition is near ProtacDataset definition\n",
        "        self.graph_encoder = GNNModel(num_node_features, c_hidden, c_out,\n",
        "                                      num_layers, layer_name, dp_rate, **kwargs)\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        # Get the graph input\n",
        "        x = x_in['smiles_graph'].x.float()\n",
        "        edge_index = x_in['smiles_graph'].edge_index\n",
        "        batch_idx = x_in['smiles_graph'].batch\n",
        "        # Run the GNN sub-model\n",
        "        x = self.graph_encoder(x, edge_index)\n",
        "        smiles_emb = geom_nn.global_add_pool(x, batch_idx)\n",
        "        return smiles_emb\n",
        "\n",
        "\n",
        "def generate_gnn_submodel(c_hidden: int,\n",
        "                          c_out: int,\n",
        "                          num_layers: int = 2,\n",
        "                          layer_name: Literal['GCN', 'GAT', 'GraphConv'] = 'GCN',\n",
        "                          dp_rate: float = 0.1,\n",
        "                          dp_rate_linear: float = 0.5,\n",
        "                          checkpoint_path: str | None = None,\n",
        "                          **kwargs):\n",
        "    model = GnnSubModel(c_hidden, c_out, num_layers, layer_name, dp_rate,\n",
        "                        dp_rate_linear, **kwargs)\n",
        "    if checkpoint_path is not None:\n",
        "        model.load_state_dict(torch.load(checkpoint_path))\n",
        "    return model"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Optuna objective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gnn_objective(trial,\n",
        "                  num_epochs:int = 10,\n",
        "                  task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                  loss_func: Callable | object = nn.HuberLoss(),\n",
        "                  num_gpus: int = 0):\n",
        "    config = {\n",
        "        # SMILES encoder\n",
        "        'c_hidden': trial.suggest_categorical('c_hidden', [64, 128, 256, 512, 768]),\n",
        "        'c_out': trial.suggest_categorical('c_out', [64, 128, 256, 512, 768]),\n",
        "        'num_layers': trial.suggest_int('num_layers', 3, 11),\n",
        "        'layer_name': trial.suggest_categorical('layer_name', ['GCN', 'GAT', 'GraphConv']),\n",
        "        'dp_rate': trial.suggest_float('dp_rate', 0.1, 0.8),\n",
        "        'dp_rate_linear': trial.suggest_float('dp_rate_linear', 0.1, 0.8),\n",
        "        # Extra features branch\n",
        "        'use_extra_features': True, # trial.suggest_categorical('use_extra_features', [True, False]),\n",
        "        'layer_1_size_extra': trial.suggest_categorical('layer_1_size_extra', [8, 16, 32, 64, 128, 256, 512]),\n",
        "        'layer_2_size_extra': trial.suggest_categorical('layer_2_size_extra', [8, 16, 32, 64, 128, 256, 512]),\n",
        "        'dropout': trial.suggest_float('dropout', 0.1, 0.8),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n",
        "        # TODO: add code to divide the batch size in the training function according to the accumulate grad config\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
        "    }\n",
        "    # Namings for reporting\n",
        "    model_name = 'gnn_model'\n",
        "    eventid = f'{trial.datetime_start.strftime(\"%Y%m%d-%H-%M-%S-\")}{uuid4()}'\n",
        "    trial_name = f'{config[\"layer_name\"]}-{trial.number}-{eventid}'    \n",
        "    lightning_dir = os.path.join(checkpoint_dir, 'lightning')\n",
        "    model_checkpoint_dir = os.path.join(lightning_dir, 'models')\n",
        "    model_checkpoint = f'{model_name}-{trial_name}'\n",
        "    tensorboard_dir = os.path.join(lightning_dir, 'tensorboard', f'{model_name}_{task}')\n",
        "    reporting_config = {\n",
        "        'trial_name': trial_name,\n",
        "        'lightning_dir': lightning_dir,\n",
        "        'model_name': model_name,\n",
        "        'model_checkpoint_dir': model_checkpoint_dir,\n",
        "        'model_checkpoint': model_checkpoint,\n",
        "        'tensorboard_dir': tensorboard_dir,\n",
        "    }\n",
        "    # Setup sub-model arguments\n",
        "    generator_args = {\n",
        "        'c_hidden': config['c_hidden'],\n",
        "        'c_out': config['c_out'],\n",
        "        'num_layers': config['num_layers'],\n",
        "        'layer_name': config['layer_name'],\n",
        "        'dp_rate': config['dp_rate'],\n",
        "        'dp_rate_linear': config['dp_rate_linear'],\n",
        "    }\n",
        "    if config['layer_name'] == 'GAT':\n",
        "        generator_args.update({\n",
        "            'heads': 8,\n",
        "            'concat': False,\n",
        "        })\n",
        "    smiles_embedding_size = config['c_out']\n",
        "    # Retrieve specific datasets\n",
        "    dataset_name = f'_graph'\n",
        "    trial.set_user_attr('dataset_name', dataset_name)\n",
        "    protac_ds_kwargs = {\n",
        "        'precompute_smiles_as_graphs': True,\n",
        "    }\n",
        "    ds = get_datasets(task,\n",
        "                                 use_upsampled,\n",
        "                                 dataset_name=dataset_name,\n",
        "                                 regenerate_datasets=False,\n",
        "                                 **protac_ds_kwargs)\n",
        "    train_dataset, test_dataset = ds\n",
        "    # Train model via its generic function\n",
        "    return train_model(config=config,\n",
        "                       reporting_config=reporting_config,\n",
        "                       smiles_encoder_generator=generate_gnn_submodel,\n",
        "                       smiles_encoder_generator_args=generator_args,\n",
        "                       smiles_embedding_size=smiles_embedding_size,\n",
        "                       train_dataset=train_dataset,\n",
        "                       test_dataset=test_dataset,\n",
        "                       num_epochs=num_epochs,\n",
        "                       task=task,\n",
        "                       loss_func=loss_func,\n",
        "                       num_gpus=num_gpus,\n",
        "                       use_raytune=False,\n",
        "                       trial=trial)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run experiments:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define experiments design points\n",
        "tasks = [\n",
        "    'predict_active_inactive',\n",
        "    # 'predict_pDC50_and_Dmax',\n",
        "    # 'predict_pDC50',\n",
        "    ]\n",
        "upsampled = [False] # [True, False]\n",
        "experiments = (tasks, upsampled)\n",
        "# Get all experiments combinations\n",
        "n_experiments = 0\n",
        "for subset in itertools.product(*experiments):\n",
        "    task, use_upsampled = subset  \n",
        "    if use_upsampled and task != 'predict_active_inactive':\n",
        "        continue\n",
        "    n_experiments += 1\n",
        "# Set fixed parameters\n",
        "num_epochs = 10\n",
        "num_samples = 20\n",
        "n_gpus = 1 if torch.cuda.is_available() else 0\n",
        "# loss_func = mean_absolute_error\n",
        "# loss_func = mean_squared_error\n",
        "loss_func = nn.HuberLoss(reduction='mean', delta=0.8) # Default 1.0\n",
        "# Define specific results dictionary in the global one\n",
        "experiments_results['results_gnn'] = {}\n",
        "# Run experiments\n",
        "pl.utilities.memory.garbage_collection_cuda()\n",
        "i = 0\n",
        "best_ckpt = []\n",
        "for experiment_id in itertools.product(*experiments):\n",
        "    task, use_upsampled = experiment_id\n",
        "    if use_upsampled and task != 'predict_active_inactive':\n",
        "        continue\n",
        "    print(f'-' * 80)\n",
        "    print(f'Experiment n.{i + 1} ({i / n_experiments * 100.0:.2f}% complete):')\n",
        "    print(f'\\ttask: {task}')\n",
        "    print(f'\\tuse_upsampled: {use_upsampled}')\n",
        "    print(f'-' * 80)\n",
        "    # Run Optuna study\n",
        "    direction = 'maximize' if task == 'predict_active_inactive' else 'minimize'\n",
        "    optuna_pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
        "    optuna_sampler = optuna.samplers.TPESampler(seed=42)\n",
        "    study = optuna.create_study(direction=direction,\n",
        "                                pruner=optuna_pruner,\n",
        "                                sampler=optuna_sampler)\n",
        "    study.optimize(lambda trial: gnn_objective(trial,\n",
        "                                               task=task,\n",
        "                                               num_epochs=num_epochs,\n",
        "                                               loss_func=loss_func,\n",
        "                                               num_gpus=n_gpus),\n",
        "                   n_trials=num_samples,\n",
        "                   timeout=600)\n",
        "    trial = study.best_trial\n",
        "    experiments_results['results_gnn'][experiment_id] = {}\n",
        "    experiments_results['results_gnn'][experiment_id]['trial'] = trial\n",
        "    experiments_results['results_gnn'][experiment_id]['task'] = task\n",
        "    experiments_results['results_gnn'][experiment_id]['use_upsampled'] = use_upsampled\n",
        "    # Reporting\n",
        "    print('-' * 80)\n",
        "    print(f'Experiment n.{i + 1} done ({(i + 1) / n_experiments * 100.0:.2f}% complete)')\n",
        "    print('Number of finished trials: {}'.format(len(study.trials)))\n",
        "    print(f'Best trial score: {trial.value}:')\n",
        "    print_dict('Experiment:', experiments_results['results_gnn'][experiment_id])\n",
        "    print_dict('Params:', trial.params)\n",
        "    print_dict('Attributes:', trial.user_attrs)\n",
        "    # Remove non-optimal checkpoints\n",
        "    model_name = trial.user_attrs['model_name']\n",
        "    checkpoint_root_dir = trial.user_attrs['model_checkpoint_dir']\n",
        "    best_ckpt.append(trial.user_attrs['trial_name'])\n",
        "    del_non_optimal_ckpt(checkpoint_root_dir, best_ckpt, model_name)\n",
        "    # Plotting training curves\n",
        "    trainer_logs = trial.user_attrs['trainer_log_dir']\n",
        "    descr = f' for GNN ({trial.params[\"layer_name\"]})'\n",
        "    plot_training_curves(trainer_logs, experiment=descr)\n",
        "    i += 1\n",
        "save_results(experiments_results['results_gnn'], result_name='results_gnn')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confusion_matrices = {}\n",
        "plot_dummy = True\n",
        "\n",
        "for experiment_id, design_points in experiments_results['results_gnn'].items():\n",
        "    trial = design_points['trial']\n",
        "    task = design_points['task']\n",
        "    # Model-specific description\n",
        "    layer_name = trial.params['layer_name']\n",
        "    descr = f'GNN ({layer_name})'\n",
        "    evaluate_experiment(descr, experiment_id, trial, task, confusion_matrices, plot_dummy)\n",
        "    plot_dummy = False\n",
        "plt.grid('both', alpha=0.7)\n",
        "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), ncol=1, fancybox=True) #, shadow=True)\n",
        "plt.show()\n",
        "\n",
        "# Plot confusion matrixes:\n",
        "for experiment, (disp, descr) in confusion_matrices.items():\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f'{descr}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %tensorboard --logdir {checkpoint_dir}/lightning/tensorboard/"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### GNN Model as standalone (DEPRECATED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphGNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 c_in: int,\n",
        "                 c_hidden: int,\n",
        "                 c_out: int,\n",
        "                 dp_rate_linear: float = 0.5,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            c_in - Dimension of input features\n",
        "            c_hidden - Dimension of hidden features\n",
        "            c_out - Dimension of output features (usually number of classes)\n",
        "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
        "            kwargs - Additional arguments for the GNNModel object\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.GNN = GNNModel(c_in=c_in, c_hidden=c_hidden, c_out=c_hidden,\n",
        "                            **kwargs)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dp_rate_linear),\n",
        "            nn.Linear(c_hidden, c_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, batch_idx):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "            x - Input features per node\n",
        "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
        "            batch_idx - Index of batch element for each node\n",
        "        \"\"\"\n",
        "        x = self.GNN(x, edge_index)\n",
        "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphLevelGNN(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, binary_classification=True, **model_kwargs):\n",
        "        super().__init__()\n",
        "        # Saving hyperparameters\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.model = GraphGNNModel(**model_kwargs)\n",
        "        if not binary_classification:\n",
        "            self.loss_module = F.mse_loss\n",
        "        else:\n",
        "            self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "\n",
        "\n",
        "    def forward(self, data, y, mode='train'):\n",
        "        x, edge_index, batch_idx = data.x.float(), data.edge_index, data.batch\n",
        "        x = self.model(x, edge_index, batch_idx)\n",
        "        x = x.squeeze(dim=-1)\n",
        "        y = y.squeeze(dim=-1)\n",
        "\n",
        "        if self.hparams.c_out == 1:\n",
        "            preds = (x > 0).float()\n",
        "            y = y.float()\n",
        "        else:\n",
        "            preds = x.argmax(dim=-1)\n",
        "        loss = self.loss_module(x, y)\n",
        "        \n",
        "        if self.binary_classification:\n",
        "            acc = (preds == y).sum().float() / preds.shape[0]\n",
        "        else:\n",
        "            acc = ((preds >= 50) == (y >= 50)).sum().float() / preds.shape[0]\n",
        "        return loss, preds, acc\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # optimizer = torch.optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=1e-3) # High lr because of small dataset and small model\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss, _, acc = self.forward(batch['smiles_graph'], batch['labels'], mode='train')\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss, _, acc = self.forward(batch['smiles_graph'], batch['labels'], mode='val')\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        loss, _, acc = self.forward(batch['smiles_graph'], batch['labels'], mode='test')\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BINARY_CLASSIFICATION = False\n",
        "\n",
        "train_dataset = ProtacDataset(train_df,\n",
        "                              include_smiles_as_graphs=True,\n",
        "                              task='predict_pDC50')\n",
        "test_dataset = ProtacDataset(val_df,\n",
        "                             include_smiles_as_graphs=True,\n",
        "                             task='predict_pDC50')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph_train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=custom_collate)\n",
        "graph_val_loader = DataLoader(test_dataset, batch_size=128, collate_fn=custom_collate)\n",
        "graph_test_loader = DataLoader(test_dataset, batch_size=128, collate_fn=custom_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECKPOINT_PATH = '.'\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "def train_graph_classifier(model_name, **model_kwargs):\n",
        "    pl.seed_everything(42)\n",
        "\n",
        "    # Create a PyTorch Lightning trainer with the generation callback\n",
        "    root_dir = os.path.join(checkpoint_dir, 'GraphLevel' + model_name)\n",
        "    os.makedirs(root_dir, exist_ok=True)\n",
        "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
        "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc')],\n",
        "                         accelerator='gpu' if str(device).startswith('cuda') else 'cpu',\n",
        "                         devices=1,\n",
        "                         max_epochs=3, # 500,\n",
        "                         log_every_n_steps=8,\n",
        "                         logger=CSVLogger(save_dir='logs/'),\n",
        "                         enable_progress_bar=True)\n",
        "    # trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
        "\n",
        "    # Check whether pretrained model exists. If yes, load it and skip training\n",
        "    pretrained_filename = os.path.join(checkpoint_dir, f'GraphLevel{model_name}.ckpt')\n",
        "    if os.path.isfile(pretrained_filename):\n",
        "        print('Found pretrained model, loading...')\n",
        "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
        "    else:\n",
        "        pl.seed_everything(42)\n",
        "        model = GraphLevelGNN(c_in=num_node_features,\n",
        "                              c_out=1, # if tu_dataset.num_classes==2 else tu_dataset.num_classes,\n",
        "                              binary_classification=BINARY_CLASSIFICATION,\n",
        "                              **model_kwargs)\n",
        "        trainer.fit(model, graph_train_loader, graph_val_loader)\n",
        "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
        "    # Test best model on validation and test set\n",
        "    train_result = trainer.test(model, graph_train_loader, verbose=False)\n",
        "    test_result = trainer.test(model, graph_test_loader, verbose=False)\n",
        "    result = {'test': test_result[0]['test_acc'], 'train': train_result[0]['test_acc']}\n",
        "    return model, result, trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!PYTORCH_NO_CUDA_MEMORY_CACHING=1\n",
        "!CUDA_LAUNCH_BLOCKING=1\n",
        "model, result, trainer = train_graph_classifier(model_name='GraphConv',\n",
        "                                                c_hidden=128,\n",
        "                                                layer_name='GraphConv',\n",
        "                                                num_layers=3,\n",
        "                                                dp_rate_linear=0.5,\n",
        "                                                dp_rate=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"Train performance: {100.0*result['train']:4.2f}%\")\n",
        "print(f\"Test performance:  {100.0*result['test']:4.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
        "del metrics['step']\n",
        "metrics.set_index('epoch', inplace=True)\n",
        "display(metrics.dropna(axis=1, how='all').head())\n",
        "g = sns.relplot(data=metrics, kind='line')\n",
        "g = plt.grid(alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "y = []\n",
        "# Make predictions and plot\n",
        "with torch.no_grad():\n",
        "    _ = model.eval()\n",
        "    for batch in graph_test_loader:\n",
        "        _, preds, _ = model(batch['smiles'], batch['labels'])\n",
        "        predictions.extend(preds.detach().tolist())\n",
        "        y.extend(batch['labels'].detach().tolist())\n",
        "predictions = np.array(predictions).flatten()\n",
        "y = np.array(y).flatten()\n",
        "sorted_idx = np.argsort(y)\n",
        "\n",
        "# g = plt.scatter(np.arange(len(y)), predictions[sorted_idx], label='predictions', marker='d')\n",
        "# g = plt.scatter(np.arange(len(y)), y[sorted_idx], label='labels', marker='x')\n",
        "g = plt.plot(np.arange(len(y)), predictions[sorted_idx], label='predictions')\n",
        "g = plt.plot(np.arange(len(y)), y[sorted_idx], label='labels')\n",
        "g = plt.legend()\n",
        "g = plt.grid(alpha=0.8)\n",
        "g = plt.xlabel('Test ID (sorted by degradation perc.)')\n",
        "g = plt.ylabel('Degradation (%)')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SSL via Dive-Into-Graphs (DIG)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The intuition behind Graph Contrastive Learning (CL) (from this [poster](https://yyou1996.github.io/files/neurips2020_graphcl_poster.pdf))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Following [this guide](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html) for constructing a Pytorch Geometric Dataset.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import InMemoryDataset, download_url\n",
        "import shutil\n",
        "\n",
        "class ProtacGeomDataset(InMemoryDataset):\n",
        "    def __init__(self, root=None, transform=None, pre_transform=None,\n",
        "                 pre_filter=None,\n",
        "                 protac_db_csv='protac-db_leftovers.csv',\n",
        "                 use_for_ssl=True,\n",
        "                 binary_classification=False):\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [self.protac_db_csv]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        protac_db_file = os.path.splitext(os.path.join(self.raw_dir, self.protac_db_csv))[0]\n",
        "        protac_pt_file = protac_db_file + ('_bin' if self.binary_classification else '') + '.pt'\n",
        "        return [protac_pt_file]\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        src = os.path.join(self.root, self.protac_db_csv)\n",
        "        dst = os.path.join(self.raw_dir, self.protac_db_csv)\n",
        "        shutil.copy(src, dst)\n",
        "        # TODO: Implement this method when the project goes opensource\n",
        "        # download_url(url, self.raw_dir)\n",
        "\n",
        "    def process(self):\n",
        "        # Read data into huge `Data` list.\n",
        "        df_file = os.path.join(self.raw_dir, self.protac_db_csv)\n",
        "        dataframe = pd.read_csv(df_file)\n",
        "        dataframe = dataframe.dropna(subset=['Smiles_nostereo'])\n",
        "        if self.use_for_ssl:\n",
        "            dataframe = dataframe.drop_duplicates(subset=['Smiles_nostereo'])\n",
        "        smiles = dataframe['Smiles_nostereo']\n",
        "        data_list = [from_smiles(s) for s in smiles]\n",
        "        # Convert x features to float\n",
        "        for d in data_list:\n",
        "            d.x = d.x.to(torch.float32)\n",
        "        # Store labels for each graph\n",
        "        if not self.use_for_ssl:\n",
        "            if self.binary_classification:\n",
        "                y_data = dataframe['active'].astype(np.compat.long)\n",
        "            else:\n",
        "                y_data = (dataframe['degradation'].astype(np.float32) * 0.01).to_numpy()[..., None]\n",
        "            for d, y in zip(data_list, y_data):\n",
        "                d.y = y\n",
        "        # Filter entries\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "        # Apply pre-transformation\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "        # Finally save the Pytorch Geometric Data entries\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save pandas to csv\n",
        "train_bin_df.to_csv(os.path.join(data_dir, 'protac', 'protac-db_curated_train_bin.csv'), index=False)\n",
        "train_df.to_csv(os.path.join(data_dir, 'protac', 'protac-db_curated_train.csv'), index=False)\n",
        "train_upsampled_bin_df.to_csv(os.path.join(data_dir, 'protac', 'protac-db_curated_train_upsampled_bin.csv'), index=False)\n",
        "val_bin_df.to_csv(os.path.join(data_dir, 'protac', 'protac-db_curated_test_bin.csv'), index=False)\n",
        "val_df.to_csv(os.path.join(data_dir, 'protac', 'protac-db_curated_test.csv'), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset_bin = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "                                      protac_db_csv='protac-db_curated_train_bin.csv',\n",
        "                                      use_for_ssl=False,\n",
        "                                      binary_classification=True)\n",
        "test_dataset_bin = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "                                     protac_db_csv='protac-db_curated_test_bin.csv',\n",
        "                                     use_for_ssl=False,\n",
        "                                     binary_classification=True)\n",
        "ssl_dataset_bin = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "                                    protac_db_csv='protac-db_ssl.csv',\n",
        "                                    use_for_ssl=True,\n",
        "                                    binary_classification=True)\n",
        "ssl_dataset = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "                                protac_db_csv='protac-db_ssl.csv',\n",
        "                                use_for_ssl=True,\n",
        "                                binary_classification=False)\n",
        "# TODO: Only work on binary classification for now\n",
        "# train_dataset = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "#                                   protac_db_csv='protac-db_curated_train.csv',\n",
        "#                                   use_for_ssl=False,\n",
        "#                                   binary_classification=False)\n",
        "# test_dataset = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "#                                  protac_db_csv='protac-db_curated_test.csv',\n",
        "#                                  use_for_ssl=False,\n",
        "#                                  binary_classification=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following SSL code comes from [this guide](https://diveintographs.readthedocs.io/en/latest/tutorials/sslgraph.html#id10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dig.sslgraph.utils import Encoder\n",
        "from dig.sslgraph.method import GraphCL, GRACE\n",
        "from dig.sslgraph.evaluation import GraphSemisupervised, GraphUnsupervised\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "feat_dim = ssl_dataset[0].x.shape[1]\n",
        "gnn_type = 'resgcn' # Possible values: resgcn | gcn | gin\n",
        "n_layers = 4\n",
        "embed_dim = 128\n",
        "# Define SMILES encoder\n",
        "encoder = Encoder(feat_dim, embed_dim, n_layers=n_layers, gnn=gnn_type)\n",
        "# Define prediction head as a linear layer\n",
        "# NOTE: Unless using 'resgcn', the other predefined GNNs return an output of\n",
        "# shape: (batch_size, embedded_size * n_layers)\n",
        "embed_dim = embed_dim if gnn_type == 'resgcn' else embed_dim * n_layers\n",
        "prediction_head = nn.Linear(embed_dim, 2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[List](https://diveintographs.readthedocs.io/en/latest/sslgraph/method.html#dig.sslgraph.method.GraphCL) of Graph Constrastive Learning (CL) techniques.\n",
        "\n",
        "A [poster](https://yyou1996.github.io/files/neurips2020_graphcl_poster.pdf) with the intuitions behind Graph CL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# graphcl = GraphCL(embed_dim, aug_1='subgraph', aug_2='dropN')\n",
        "graphcl = GRACE(embed_dim, dropE_rate_1=0.5, dropE_rate_2=0.5, maskN_rate_1=0.5, maskN_rate_2=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Define the evaluator, i.e., trainer, and its configuration parameters\n",
        "# evaluator = GraphUnsupervised(train_dataset, log_interval=10, device=device,\n",
        "#                               p_optim='Adam',\n",
        "#                               p_lr=1e-3,\n",
        "#                               p_weight_decay=0.9,\n",
        "#                               p_epoch=10)\n",
        "# evaluator.evaluate(learning_model=graphcl,\n",
        "#                    encoder=encoder)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[List](https://diveintographs.readthedocs.io/en/latest/sslgraph/evaluation.html#dig-sslgraph-evaluation) of Graph CL trainers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluator = GraphSemisupervised(train_dataset_bin, ssl_dataset_bin, label_rate=0.3,\n",
        "                                n_folds=10, device=device)\n",
        "evaluator.setup_train_config(batch_size=256,\n",
        "                             p_lr=1e-5,\n",
        "                             p_epoch=5,\n",
        "                             f_lr=1e-5,\n",
        "                             f_epoch=5)\n",
        "test_acc, _ = evaluator.evaluate(learning_model=graphcl,\n",
        "                                           encoder=encoder,\n",
        "                                           pred_head=prediction_head,\n",
        "                                           fold_seed=42)\n",
        "print(f'Test accuracy: {test_acc:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = nn.Sequential(encoder, prediction_head, nn.Softmax(dim=1))\n",
        "\n",
        "predictions = []\n",
        "targets = []\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for batch in test_dataset_bin:\n",
        "        model_pred = model(batch.to(device)).argmax(dim=1).detach().tolist()\n",
        "        predictions.extend(model_pred)\n",
        "        targets.extend(batch.y.detach().tolist())\n",
        "predictions = np.array(predictions).flatten()\n",
        "targets = np.array(targets).flatten()\n",
        "sorted_idx = np.argsort(targets)\n",
        "# Get accuracy\n",
        "accuracy = Accuracy(task='binary')\n",
        "acc = accuracy(torch.Tensor(predictions), torch.Tensor(targets))\n",
        "# Plot predicitons (sorted)\n",
        "plt.plot(predictions[sorted_idx], label='Predicted degradation activity')\n",
        "plt.plot(targets[sorted_idx], label='Reference degradation activity')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.8)\n",
        "plt.xlabel('Test ID (sorted by degradation perc.)')\n",
        "plt.ylabel('Degradation')\n",
        "plt.title(f'Predicting PROTAC activation (Accuracy: {acc:.2f})')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define Optuna objective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feat_dim = ssl_dataset[0].x.shape[1]\n",
        "accuracy = Accuracy(task='binary')\n",
        "\n",
        "def run_objective_body(**kwargs):\n",
        "    batch_size = kwargs['batch_size']\n",
        "    label_rate = kwargs['label_rate']\n",
        "    p_lr = kwargs['p_lr']\n",
        "    p_epoch = kwargs['p_epoch']\n",
        "    f_lr = kwargs['f_lr']\n",
        "    f_epoch = kwargs['f_epoch']\n",
        "    gnn_type = kwargs['gnn_type']\n",
        "    n_layers = kwargs['n_layers']\n",
        "    embed_dim = kwargs['embed_dim']\n",
        "    # Define SMILES encoder\n",
        "    encoder = Encoder(feat_dim, embed_dim, n_layers=n_layers, gnn=gnn_type)\n",
        "    # Define prediction head as a linear layer\n",
        "    # NOTE: Unless using 'resgcn', the other predefined GNNs return an output of\n",
        "    # shape: (batch_size, embedded_size * n_layers)\n",
        "    embed_dim = embed_dim if gnn_type == 'resgcn' else embed_dim * n_layers\n",
        "    prediction_head = nn.Linear(embed_dim, 2)\n",
        "    # Define Contrastive Learning framework\n",
        "    if kwargs['cl_type'] == 'graphcl':\n",
        "        graphcl = GraphCL(embed_dim, aug_1='subgraph', aug_2='dropN')\n",
        "    elif kwargs['cl_type'] == 'grace':\n",
        "        graphcl = GRACE(embed_dim, dropE_rate_1=0.5, dropE_rate_2=0.5, maskN_rate_1=0.5, maskN_rate_2=0.5)\n",
        "    # Define trainer\n",
        "    evaluator = GraphSemisupervised(train_dataset_bin, ssl_dataset_bin,\n",
        "                                    label_rate=label_rate,\n",
        "                                    device=device)\n",
        "    evaluator.setup_train_config(batch_size=batch_size,\n",
        "                                 p_lr=p_lr,\n",
        "                                 p_epoch=p_epoch,\n",
        "                                 f_lr=f_lr,\n",
        "                                 f_epoch=f_epoch)\n",
        "    train_acc, _ = evaluator.evaluate(learning_model=graphcl,\n",
        "                                      encoder=encoder,\n",
        "                                      pred_head=prediction_head)\n",
        "    # Test model\n",
        "    model = nn.Sequential(encoder, prediction_head, nn.Softmax(dim=1))\n",
        "    predictions = []\n",
        "    targets = []\n",
        "    # Make predictions\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for batch in test_dataset_bin:\n",
        "            model_pred = model(batch.to(device)).argmax(dim=1).detach().tolist()\n",
        "            predictions.extend(model_pred)\n",
        "            targets.extend(batch.y.detach().tolist())\n",
        "    predictions = np.array(predictions).flatten()\n",
        "    targets = np.array(targets).flatten()\n",
        "    # Get test accuracy\n",
        "    test_acc = accuracy(torch.Tensor(predictions), torch.Tensor(targets))\n",
        "    return train_acc, test_acc, predictions, targets\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'label_rate': trial.suggest_float('label_rate', 0.3, 1.0),\n",
        "        'p_lr': trial.suggest_float('p_lr', 1e-6, 1e-3, log=True),\n",
        "        'p_epoch': trial.suggest_int('p_epoch', 10, 31),\n",
        "        'f_lr': trial.suggest_float('f_lr', 1e-6, 1e-3, log=True),\n",
        "        'f_epoch': trial.suggest_int('f_epoch', 10, 31),\n",
        "        'gnn_type': trial.suggest_categorical('gnn_type', ['resgcn', 'gcn', 'gin']),\n",
        "        'n_layers': trial.suggest_int('n_layers', 3, 10),\n",
        "        'embed_dim': trial.suggest_categorical('embed_dim', [64 + 128 * i for i in range(6)]),\n",
        "        'batch_size': trial.suggest_categorical('batch_size', [64, 128, 256]),\n",
        "        'cl_framework': trial.suggest_categorical('cl_framework', ['graphcl', 'grace']),\n",
        "    }\n",
        "    train_acc, test_acc, predictions, targets = run_objective_body(**params)\n",
        "    # Log parameters\n",
        "    trial.set_user_attr('train_acc', train_acc)\n",
        "    trial.set_user_attr('test_acc', test_acc)\n",
        "    print(f'Training accuracy: {train_acc:.2f}')\n",
        "    print(f'Test accuracy: {test_acc:.2f}')\n",
        "    return test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "study = optuna.create_study(direction='maximize',\n",
        "                            pruner=optuna.pruners.MedianPruner(n_warmup_steps=5),\n",
        "                            sampler=optuna.samplers.TPESampler(seed=42))\n",
        "study.optimize(objective, n_trials=10, timeout=600)\n",
        "print('-' * 80)\n",
        "print('Number of finished trials: {}'.format(len(study.trials)))\n",
        "print('Best trial:')\n",
        "print(f'\\tValue: {study.best_trial.value}')\n",
        "print('\\tParams: ')\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f'\\t\\t* {key}: {value}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ret = run_objective_body(**study.best_trial.params)\n",
        "train_acc, test_acc, predictions, targets = ret\n",
        "sorted_idx = np.argsort(targets)\n",
        "# Get accuracy\n",
        "accuracy = Accuracy(task='binary')\n",
        "acc = accuracy(torch.Tensor(predictions), torch.Tensor(targets))\n",
        "# Plot predicitons (sorted)\n",
        "plt.plot(predictions[sorted_idx], label='Predicted degradation activity')\n",
        "plt.plot(targets[sorted_idx], label='Reference degradation activity')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.8)\n",
        "plt.xlabel('Test ID (sorted by degradation perc.)')\n",
        "plt.ylabel('Degradation')\n",
        "plt.title(f'Predicting PROTAC activation (Accuracy: {test_acc:.2f})')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### GraphCL"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Had8IXd_BNzX"
      },
      "source": [
        "Define a custom Pytorch Geometric Dataset for SSL.\n",
        "\n",
        "Following [this guide](https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_dataset.html) for constructing a Pytorch Geometric Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZ2B0uRYBNzY"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.data import InMemoryDataset, download_url\n",
        "\n",
        "class ProtacGeomDataset(InMemoryDataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 root: str = None,\n",
        "                 transform: Callable | None = None,\n",
        "                 pre_transform: Callable | None = None,\n",
        "                 pre_filter: Callable | None = None,\n",
        "                 task: Literal['predict_active_inactive', 'predict_pDC50_and_Dmax'] = 'predict_active_inactive',\n",
        "                 protac_df: pd.DataFrame | None = None,\n",
        "                 protac_db_csv: str = 'protac-db_ssl.csv',\n",
        "                 use_for_ssl: bool = True):\n",
        "        \"\"\"Protac Pytorch Geometric dataset for SSL.\n",
        "        \n",
        "            Args:\n",
        "            root (string): Root directory where the dataset should be saved.\n",
        "            transform (callable, optional): A function/transform that takes in\n",
        "                an :obj:`torch_geometric.data.Data` object and returns a\n",
        "                transformed version. The data object will be transformed before\n",
        "                every access. (default: :obj:`None`)\n",
        "            pre_transform (callable, optional): A function/transform that takes\n",
        "                in an :obj:`torch_geometric.data.Data` object and returns a\n",
        "                transformed version. The data object will be transformed before\n",
        "                being saved to disk. (default: :obj:`None`)\n",
        "            pre_filter (callable, optional): A function that takes in an\n",
        "                :obj:`torch_geometric.data.Data` object and returns a boolean\n",
        "                value, indicating whether the data object should be included in\n",
        "                the final dataset. (default: :obj:`None`)\n",
        "            protac_db_csv (str): Path to the protac database file in csv format.\n",
        "                The file must contain at least the following columns: 'SMILES',\n",
        "                'active'.\n",
        "            use_for_ssl (bool): Whether to use the dataset for self-supervised\n",
        "                learning. If False, each entry will have its `y` element\n",
        "                assigned. (default: :obj:`True`)\n",
        "        \"\"\"\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return [self.protac_db_csv]\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        protac_db_file = os.path.splitext(os.path.join(self.raw_dir, self.protac_db_csv))[0]\n",
        "        protac_pt_file = protac_db_file + ('_bin' if self.task == 'predict_active_inactive' else '') + '.pt'\n",
        "        return [protac_pt_file]\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        src = os.path.join(self.root, self.protac_db_csv)\n",
        "        dst = os.path.join(self.raw_dir, self.protac_db_csv)\n",
        "        shutil.copy(src, dst)\n",
        "        # TODO: Implement this method when the project goes opensource\n",
        "        # download_url(url, self.raw_dir)\n",
        "\n",
        "    def process(self):\n",
        "        if self.protac_df is not None:\n",
        "            df_file = os.path.join(self.raw_dir, self.protac_db_csv)\n",
        "            dataframe = pd.read_csv(df_file)\n",
        "        else:\n",
        "            dataframe = self.protac_df.copy()\n",
        "            dataframe = dataframe.dropna(subset=['Smiles_nostereo'])\n",
        "        if self.use_for_ssl:\n",
        "            dataframe = dataframe.drop_duplicates(subset=['Smiles_nostereo'])\n",
        "        # Read data into huge list of `Data` type elements.\n",
        "        smiles = dataframe['Smiles_nostereo']\n",
        "        data_list = [from_smiles(s) for s in smiles]\n",
        "        # Convert x features to float\n",
        "        for d in data_list:\n",
        "            d.x = d.x.to(torch.float32)\n",
        "        # Store labels for each graph\n",
        "        if not self.use_for_ssl:\n",
        "            if self.task == 'predict_active_inactive':\n",
        "                y_data = dataframe['active'].astype(np.compat.long)\n",
        "            elif self.task == 'predict_pDC50':\n",
        "                y_data = dataframe.pDC50.to_numpy()[..., None]\n",
        "            elif self.task == 'predict_pDC50_and_Dmax':\n",
        "                Dmax = dataframe.Dmax.to_numpy()\n",
        "                pDC50 = dataframe.pDC50.to_numpy()\n",
        "                y_data = np.array([Dmax, pDC50])\n",
        "            else:\n",
        "                raise ValueError(f'Task \"{self.task}\" not recognized. Available: \"predict_pDC50\" \\| \"predict_active_inactive\" \\| \"predict_pDC50_and_Dmax\"')\n",
        "            for d, y in zip(data_list, y_data):\n",
        "                d.y = y\n",
        "        # Filter entries\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "        # Apply pre-transformation\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(data) for data in data_list]\n",
        "        # Finally save the Pytorch Geometric Data entries\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_train_test_geom_datasets(task, use_for_ssl=False, dataset_name='', use_upsampled=False):\n",
        "    # Get naming convention for the datasets\n",
        "    if task == 'predict_pDC50_and_Dmax':\n",
        "        train_ds = os.path.join(data_dir, 'protac', f'train_pDC50_Dmax_geom_dataset{dataset_name}.pt')\n",
        "        test_ds = os.path.join(data_dir, 'protac', f'test_pDC50_Dmax_geom_dataset{dataset_name}.pt')\n",
        "    if task == 'predict_pDC50':\n",
        "        train_ds = os.path.join(data_dir, 'protac', f'train_pDC50_geom_dataset{dataset_name}.pt')\n",
        "        test_ds = os.path.join(data_dir, 'protac', f'test_pDC50_geom_dataset{dataset_name}.pt')\n",
        "    elif task == 'predict_active_inactive':\n",
        "        test_ds = os.path.join(data_dir, 'protac', f'test_bin_geom_dataset{dataset_name}.pt')\n",
        "        if use_upsampled:\n",
        "            train_ds = os.path.join(data_dir, 'protac', f'train_upsampled_bin_geom_dataset{dataset_name}.pt')\n",
        "        else:\n",
        "            train_ds = os.path.join(data_dir, 'protac', f'train_bin_geom_dataset{dataset_name}.pt')\n",
        "    # Get specific dataframes acconding to the task\n",
        "    if task == 'predict_active_inactive':\n",
        "        train_df_tmp = train_upsampled_bin_df if use_upsampled else train_bin_df\n",
        "        val_df_tmp = val_bin_df\n",
        "    else:\n",
        "        train_df_tmp = train_df\n",
        "        val_df_tmp = val_df\n",
        "    # Generate and save Pytorch Geometric specific datasets\n",
        "    train_geom_dataset = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "                                           protac_df=train_df_tmp,\n",
        "                                           task=task,\n",
        "                                           use_for_ssl=use_for_ssl)\n",
        "    test_geom_dataset = ProtacGeomDataset(os.path.join(data_dir, 'protac'),\n",
        "                                          protac_df=val_df_tmp,\n",
        "                                          task=task,\n",
        "                                          use_for_ssl=use_for_ssl)\n",
        "    torch.save(train_geom_dataset, train_ds)\n",
        "    torch.save(test_geom_dataset, test_ds)\n",
        "    return train_geom_dataset, test_geom_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdna_J26DfxL"
      },
      "outputs": [],
      "source": [
        "from dig.sslgraph.utils import Encoder\n",
        "from dig.sslgraph.method import GraphCL, GRACE\n",
        "from dig.sslgraph.evaluation import GraphSemisupervised, GraphUnsupervised\n",
        "from dig.sslgraph.method import Contrastive\n",
        "\n",
        "class SSLTrainer(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 feat_dim:int=datasets['ssl'][0].x.shape[1],\n",
        "                 gnn_type:str='resgcn', # Possible values: resgcn | gcn | gin\n",
        "                 n_layers:int=4,\n",
        "                 embed_dim:int=768,\n",
        "                 binary_classification:bool=True,\n",
        "                 batch_size:int=64,\n",
        "                 learning_rate:float=1e-3,\n",
        "                 dropE_rate_1=0.5,\n",
        "                 dropE_rate_2=0.5,\n",
        "                 maskN_rate_1=0.5,\n",
        "                 maskN_rate_2=0.5,\n",
        "                 train_dataset=datasets['ssl'],\n",
        "                 test_dataset=datasets['test_ssl'],\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        # Save the arguments passed to init\n",
        "        self.save_hyperparameters()\n",
        "        # Set our init args as class attributes\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        # Define PyTorch models\n",
        "        self.encoder = Encoder(feat_dim, embed_dim, n_layers=n_layers,\n",
        "                               gnn=gnn_type)\n",
        "        self.out_dim = 2 if binary_classification else 2\n",
        "        if gnn_type == 'resgcn':\n",
        "            self.embed_dim = embed_dim\n",
        "        else:\n",
        "            self.embed_dim = embed_dim * n_layers\n",
        "        self.head = nn.Linear(embed_dim, self.out_dim)\n",
        "        # Loss and evaluation metrics\n",
        "        self.val_acc = Accuracy('binary')\n",
        "        self.test_acc = Accuracy('binary')\n",
        "        self.val_mse = MeanSquaredError()\n",
        "        self.test_mse = MeanSquaredError()\n",
        "\n",
        "        # # Constrastive Learning model\n",
        "        # self.graphcl = GRACE(embed_dim, dropE_rate_1=0.5, dropE_rate_2=0.5,\n",
        "        #                      maskN_rate_1=0.5, maskN_rate_2=0.5)\n",
        "        self.graphcl = GraphCL(embed_dim, aug_1='subgraph', aug_2='dropN')\n",
        "        # Override the train() method in graphcl and allow Lightning to take\n",
        "        # care of the entire training\n",
        "        def void(self):\n",
        "            pass\n",
        "        self.graphcl.train = void\n",
        "        # Get projection head dimensions\n",
        "        if self.graphcl.z_n_dim is None:\n",
        "            self.graphcl.proj_out_dim = self.graphcl.z_dim\n",
        "        else:\n",
        "            self.graphcl.proj_out_dim = self.graphcl.z_n_dim\n",
        "        # Get graph-level project head\n",
        "        if self.graphcl.graph_level and self.graphcl.proj is not None:\n",
        "            self.graphcl.proj_head_g = self.graphcl._get_proj(self.graphcl.proj,\n",
        "                                                              self.graphcl.z_dim)\n",
        "        elif self.graphcl.graph_level:\n",
        "            self.graphcl.proj_head_g = lambda x: x\n",
        "        else:\n",
        "            self.graphcl.proj_head_g = None\n",
        "        # Get node-level project head\n",
        "        if self.graphcl.node_level and self.graphcl.proj_n is not None:\n",
        "            self.graphcl.proj_head_n = self.graphcl._get_proj(self.graphcl.proj_n,\n",
        "                                                              self.graphcl.z_n_dim)\n",
        "        elif self.graphcl.node_level:\n",
        "            self.graphcl.proj_head_n = lambda x: x\n",
        "        else:\n",
        "            self.graphcl.proj_head_n = None\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        x = self.encoder(x_in)\n",
        "        return self.head(x)\n",
        "\n",
        "    def training_step(self, data, batch_idx):\n",
        "        # output of each encoder should be Tensor for graph-level embedding\n",
        "        if isinstance(self.encoder, list):\n",
        "            assert len(self.encoder) == len(self.graphcl.views_fn)\n",
        "            encoders = self.encoder\n",
        "            [enc.train() for enc in encoders]\n",
        "        else:\n",
        "            self.encoder.train()\n",
        "            encoders = [self.encoder] * len(self.graphcl.views_fn)\n",
        "        # Update projection heads, if possible\n",
        "        try:\n",
        "            if self.graphcl.node_level and self.graphcl.graph_level:\n",
        "                self.graphcl.proj_head_g.train()\n",
        "                self.graphcl.proj_head_n.train()\n",
        "            elif self.graphcl.graph_level:\n",
        "                self.graphcl.proj_head_g.train()\n",
        "            else:\n",
        "                self.graphcl.proj_head_n.train()\n",
        "        except:\n",
        "            pass\n",
        "        # Assemble graph views\n",
        "        if None in self.graphcl.views_fn:\n",
        "            views = []\n",
        "            for v_fn in self.graphcl.views_fn:\n",
        "                # For view fn that returns multiple views\n",
        "                if v_fn is not None:\n",
        "                    views += [*v_fn(data)]\n",
        "            assert len(views) == len(encoders)\n",
        "        else:\n",
        "            views = [v_fn(data) for v_fn in self.graphcl.views_fn]\n",
        "        # Get embeddings per views\n",
        "        zs_n, zs_g = [], []\n",
        "        for view, enc in zip(views, encoders):\n",
        "            # Run encoder\n",
        "            if self.graphcl.node_level and self.graphcl.graph_level:\n",
        "                z_g, z_n = self.graphcl._get_embed(enc, view)\n",
        "                zs_n.append(self.graphcl.proj_head_n(z_n))\n",
        "                zs_g.append(self.graphcl.proj_head_g(z_g))\n",
        "            elif self.graphcl.graph_level:\n",
        "                z_g = self.graphcl._get_embed(enc, view)\n",
        "                zs_g.append(self.graphcl.proj_head_g(z_g))\n",
        "            else:\n",
        "                z_n = self.graphcl._get_embed(enc, view)\n",
        "                zs_n.append(self.graphcl.proj_head_n(z_n))\n",
        "        # Get loss\n",
        "        if self.graphcl.node_level and self.graphcl.graph_level:\n",
        "            loss = self.graphcl.loss_fn(zs_g, zs_n=zs_n, batch=data.batch,\n",
        "                                        neg_by_crpt=self.graphcl.neg_by_crpt,\n",
        "                                        tau=self.graphcl.tau)\n",
        "        elif self.graphcl.graph_level:\n",
        "            loss = self.graphcl.loss_fn(zs_g,\n",
        "                                        neg_by_crpt=self.graphcl.neg_by_crpt,\n",
        "                                        tau=self.graphcl.tau)\n",
        "        else:\n",
        "            loss = self.graphcl.loss_fn(zs_g=None, zs_n=zs_n, batch=data.batch,\n",
        "                                        neg_by_crpt=self.graphcl.neg_by_crpt,\n",
        "                                        tau=self.graphcl.tau)\n",
        "        # Reporting and return\n",
        "        self.log(f'train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x = self.encoder(batch)\n",
        "        y_hat = self.head(x)\n",
        "        if self.binary_classification:\n",
        "            y_hat = nn.functional.softmax(y_hat, dim=1).argmax(dim=1)\n",
        "            acc = self.val_acc(y_hat, batch.y)\n",
        "            self.log(f'val_acc', acc, prog_bar=True)\n",
        "            return acc\n",
        "        else:\n",
        "            y_hat = torch.Tensor(y_hat)\n",
        "            y = torch.Tensor(batch.y)\n",
        "            mse = self.val_mse(y_hat, y)\n",
        "            self.log(f'val_mse', mse, prog_bar=True)\n",
        "            return mse\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x = self.encoder(batch)\n",
        "        y_hat = self.head(x)\n",
        "        if self.binary_classification:\n",
        "            y_hat = nn.functional.softmax(y_hat, dim=1).argmax(dim=1)\n",
        "            acc = self.test_acc(y_hat, batch.y)\n",
        "            self.log(f'test_acc', acc, prog_bar=True)\n",
        "            return acc\n",
        "        else:\n",
        "            y_hat = torch.Tensor(y_hat)\n",
        "            y = torch.Tensor(batch.y)\n",
        "            mse = self.test_mse(y_hat, y)\n",
        "            self.log(f'test_mse', mse, prog_bar=True)\n",
        "            return mse\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=custom_collate)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=custom_collate)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=custom_collate)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=custom_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgIzd92ADfxM"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from dig.sslgraph.method.contrastive.views_fn import NodeAttrMask, EdgePerturbation, Sequential\n",
        "\n",
        "dropE_rate_1 = 0.5\n",
        "dropE_rate_2 = 0.5\n",
        "maskN_rate_1 = 0.5\n",
        "maskN_rate_2 = 0.5\n",
        "model = SSLTrainer(embed_dim=32, batch_size=128, binary_classification=False)\n",
        "\n",
        "callbacks = [\n",
        "    TQDMProgressBar(refresh_rate=20),\n",
        "    # EarlyStopping(monitor='val_loss', mode='min'),\n",
        "    # ModelCheckpoint(save_weights_only=True, mode='min', monitor='val_loss'),\n",
        "]\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=2,\n",
        "                     gradient_clip_val=1.0,\n",
        "                     gradient_clip_algorithm='norm',\n",
        "                     accelerator='auto',\n",
        "                     devices=1 if torch.cuda.is_available() else 1,\n",
        "                     log_every_n_steps=8,\n",
        "                     callbacks=callbacks,\n",
        "                     logger=CSVLogger(save_dir='logs/'),\n",
        "                     deterministic=True)\n",
        "trainer.fit(model)#### Pythorch Lightning\n",
        "from dig.sslgraph.utils import Encoder\n",
        "from dig.sslgraph.method import GraphCL, GRACE\n",
        "from dig.sslgraph.evaluation import GraphSemisupervised, GraphUnsupervised\n",
        "from dig.sslgraph.method import Contrastive\n",
        "\n",
        "class SSLTrainer(pl.LightningModule):\n",
        "\n",
        "    def __init__(self,\n",
        "                 feat_dim:int=ssl_dataset[0].x.shape[1],\n",
        "                 gnn_type:str='resgcn', # Possible values: resgcn | gcn | gin\n",
        "                 n_layers:int=4,\n",
        "                 embed_dim:int=768,\n",
        "                 binary_classification:bool=True,\n",
        "                 batch_size:int=64,\n",
        "                 learning_rate:float=1e-3,\n",
        "                 dropE_rate_1=0.5,\n",
        "                 dropE_rate_2=0.5,\n",
        "                 maskN_rate_1=0.5,\n",
        "                 maskN_rate_2=0.5,\n",
        "                 **kwargs):\n",
        "        super().__init__()\n",
        "        # Save the arguments passed to init\n",
        "        self.save_hyperparameters()\n",
        "        # Set our init args as class attributes\n",
        "        self.__dict__.update(locals()) # Add arguments as attributes\n",
        "        # Define PyTorch models\n",
        "        self.encoder = Encoder(feat_dim, embed_dim, n_layers=n_layers,\n",
        "                               gnn=gnn_type)\n",
        "        self.out_dim = 2 if binary_classification else 1\n",
        "        if gnn_type == 'resgcn':\n",
        "            self.embed_dim = embed_dim\n",
        "        else:\n",
        "            self.embed_dim = embed_dim * n_layers\n",
        "        self.head = nn.Linear(embed_dim, self.out_dim)\n",
        "        # Loss and evaluation metrics\n",
        "        self.val_acc = Accuracy('binary')\n",
        "        self.test_acc = Accuracy('binary')\n",
        "        self.val_mse = MeanSquaredError()\n",
        "        self.test_mse = MeanSquaredError()\n",
        "\n",
        "        # # Constrastive Learning model\n",
        "        # self.graphcl = GRACE(embed_dim, dropE_rate_1=0.5, dropE_rate_2=0.5,\n",
        "        #                      maskN_rate_1=0.5, maskN_rate_2=0.5)\n",
        "        self.graphcl = GraphCL(embed_dim, aug_1='subgraph', aug_2='dropN')\n",
        "        # Override the train() method in graphcl and allow Lightning to take\n",
        "        # care of the entire training\n",
        "        def void(self):\n",
        "            pass\n",
        "        self.graphcl.train = void\n",
        "        # Get projection head dimensions\n",
        "        if self.graphcl.z_n_dim is None:\n",
        "            self.graphcl.proj_out_dim = self.graphcl.z_dim\n",
        "        else:\n",
        "            self.graphcl.proj_out_dim = self.graphcl.z_n_dim\n",
        "        # Get graph-level project head\n",
        "        if self.graphcl.graph_level and self.graphcl.proj is not None:\n",
        "            self.graphcl.proj_head_g = self.graphcl._get_proj(self.graphcl.proj,\n",
        "                                                              self.graphcl.z_dim)\n",
        "        elif self.graphcl.graph_level:\n",
        "            self.graphcl.proj_head_g = lambda x: x\n",
        "        else:\n",
        "            self.graphcl.proj_head_g = None\n",
        "        # Get node-level project head\n",
        "        if self.graphcl.node_level and self.graphcl.proj_n is not None:\n",
        "            self.graphcl.proj_head_n = self.graphcl._get_proj(self.graphcl.proj_n,\n",
        "                                                              self.graphcl.z_n_dim)\n",
        "        elif self.graphcl.node_level:\n",
        "            self.graphcl.proj_head_n = lambda x: x\n",
        "        else:\n",
        "            self.graphcl.proj_head_n = None\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        x = self.encoder(x_in)\n",
        "        return self.head(x)\n",
        "\n",
        "    def training_step(self, data, batch_idx):\n",
        "        # output of each encoder should be Tensor for graph-level embedding\n",
        "        if isinstance(self.encoder, list):\n",
        "            assert len(self.encoder) == len(self.graphcl.views_fn)\n",
        "            encoders = self.encoder\n",
        "            [enc.train() for enc in encoders]\n",
        "        else:\n",
        "            self.encoder.train()\n",
        "            encoders = [self.encoder] * len(self.graphcl.views_fn)\n",
        "        # Update projection heads, if possible\n",
        "        try:\n",
        "            if self.graphcl.node_level and self.graphcl.graph_level:\n",
        "                self.graphcl.proj_head_g.train()\n",
        "                self.graphcl.proj_head_n.train()\n",
        "            elif self.graphcl.graph_level:\n",
        "                self.graphcl.proj_head_g.train()\n",
        "            else:\n",
        "                self.graphcl.proj_head_n.train()\n",
        "        except:\n",
        "            pass\n",
        "        # Assemble graph views\n",
        "        if None in self.graphcl.views_fn:\n",
        "            views = []\n",
        "            for v_fn in self.graphcl.views_fn:\n",
        "                # For view fn that returns multiple views\n",
        "                if v_fn is not None:\n",
        "                    views += [*v_fn(data)]\n",
        "            assert len(views) == len(encoders)\n",
        "        else:\n",
        "            views = [v_fn(data) for v_fn in self.graphcl.views_fn]\n",
        "        # Get embeddings per views\n",
        "        zs_n, zs_g = [], []\n",
        "        for view, enc in zip(views, encoders):\n",
        "            # Run encoder\n",
        "            if self.graphcl.node_level and self.graphcl.graph_level:\n",
        "                z_g, z_n = self.graphcl._get_embed(enc, view)\n",
        "                zs_n.append(self.graphcl.proj_head_n(z_n))\n",
        "                zs_g.append(self.graphcl.proj_head_g(z_g))\n",
        "            elif self.graphcl.graph_level:\n",
        "                z_g = self.graphcl._get_embed(enc, view)\n",
        "                zs_g.append(self.graphcl.proj_head_g(z_g))\n",
        "            else:\n",
        "                z_n = self.graphcl._get_embed(enc, view)\n",
        "                zs_n.append(self.graphcl.proj_head_n(z_n))\n",
        "        # Get loss\n",
        "        if self.graphcl.node_level and self.graphcl.graph_level:\n",
        "            loss = self.graphcl.loss_fn(zs_g, zs_n=zs_n, batch=data.batch,\n",
        "                                        neg_by_crpt=self.graphcl.neg_by_crpt,\n",
        "                                        tau=self.graphcl.tau)\n",
        "        elif self.graphcl.graph_level:\n",
        "            loss = self.graphcl.loss_fn(zs_g,\n",
        "                                        neg_by_crpt=self.graphcl.neg_by_crpt,\n",
        "                                        tau=self.graphcl.tau)\n",
        "        else:\n",
        "            loss = self.graphcl.loss_fn(zs_g=None, zs_n=zs_n, batch=data.batch,\n",
        "                                        neg_by_crpt=self.graphcl.neg_by_crpt,\n",
        "                                        tau=self.graphcl.tau)\n",
        "        # Reporting and return\n",
        "        self.log(f'train_loss', loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x = self.encoder(batch)\n",
        "        y_hat = self.head(x)\n",
        "        # print(f'[validation] y_hat/y: {y_hat} / {batch.y}')\n",
        "        if self.binary_classification:\n",
        "            y_hat = nn.functional.softmax(y_hat, dim=1).argmax(dim=1)\n",
        "            acc = self.val_acc(y_hat, batch.y)\n",
        "            self.log(f'val_acc', acc, prog_bar=True)\n",
        "            return acc\n",
        "        else:\n",
        "            y_hat = torch.Tensor(y_hat)\n",
        "            y = torch.Tensor(batch.y)\n",
        "            mse = self.val_mse(y_hat, y)\n",
        "            self.log(f'val_mse', mse, prog_bar=True)\n",
        "            return mse\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x = self.encoder(batch)\n",
        "        y_hat = self.head(x)\n",
        "        # print(f'[test] y_hat/y: {y_hat} / {batch.y}')\n",
        "        if self.binary_classification:\n",
        "            y_hat = nn.functional.softmax(y_hat, dim=1).argmax(dim=1)\n",
        "            acc = self.test_acc(y_hat, batch.y)\n",
        "            self.log(f'test_acc', acc, prog_bar=True)\n",
        "            return acc\n",
        "        else:\n",
        "            y_hat = torch.Tensor(y_hat)\n",
        "            y = torch.Tensor(batch.y)\n",
        "            mse = self.test_mse(y_hat, y)\n",
        "            self.log(f'test_mse', mse, prog_bar=True)\n",
        "            return mse\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
        "        return optimizer\n",
        "\n",
        "    ####################\n",
        "    # DATA RELATED HOOKS\n",
        "    ####################\n",
        "\n",
        "    # def prepare_data(self):\n",
        "    #     # download\n",
        "    #     MNIST(self.data_dir, train=True, download=True)\n",
        "    #     MNIST(self.data_dir, train=False, download=True)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        if self.binary_classification:\n",
        "            return torch_geometric.loader.DataLoader(ssl_dataset_bin, batch_size=self.batch_size, shuffle=True)\n",
        "        else:\n",
        "            return torch_geometric.loader.DataLoader(ssl_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        if self.binary_classification:\n",
        "            return torch_geometric.loader.DataLoader(train_dataset_bin, batch_size=self.batch_size)\n",
        "        else:\n",
        "            return torch_geometric.loader.DataLoader(train_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        if self.binary_classification:\n",
        "            return torch_geometric.loader.DataLoader(test_dataset_bin, batch_size=self.batch_size)\n",
        "        else:\n",
        "            return torch_geometric.loader.DataLoader(test_dataset, batch_size=self.batch_size)\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from dig.sslgraph.method.contrastive.views_fn import NodeAttrMask, EdgePerturbation, Sequential\n",
        "\n",
        "dropE_rate_1 = 0.5\n",
        "dropE_rate_2 = 0.5\n",
        "maskN_rate_1 = 0.5\n",
        "maskN_rate_2 = 0.5\n",
        "model = SSLTrainer(embed_dim=256, batch_size=128, binary_classification=True)\n",
        "\n",
        "callbacks = [\n",
        "    TQDMProgressBar(refresh_rate=20),\n",
        "    # EarlyStopping(monitor='val_loss', mode='min'),\n",
        "    # ModelCheckpoint(save_weights_only=True, mode='min', monitor='val_loss'),\n",
        "]\n",
        "torch.use_deterministic_algorithms(False)\n",
        "\n",
        "# NOTE: The DIG library is not suitable to be automated by Pytorch Lightning\n",
        "trainer = pl.Trainer(max_epochs=5,\n",
        "                     gradient_clip_val=1.0,\n",
        "                     gradient_clip_algorithm='norm',\n",
        "                     enable_progress_bar=True,\n",
        "                     accelerator='cpu', # 'gpu' if torch.cuda.is_available() > 0 else 'auto',\n",
        "                     precision='32', # '16-mixed' if torch.cuda.is_available() > 0 else '32',\n",
        "                     log_every_n_steps=8,\n",
        "                     callbacks=callbacks,\n",
        "                     logger=CSVLogger(save_dir='logs/'))\n",
        "trainer.fit(model)\n",
        "metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n",
        "del metrics['step']\n",
        "metrics.set_index('epoch', inplace=True)\n",
        "display(metrics.dropna(axis=1, how='all').head())\n",
        "sns.relplot(data=metrics, kind='line')\n",
        "plt.grid(alpha=0.7)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eW7nQAa4PG76",
        "e2CHUiuNQIsS"
      ],
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "a2d6f14e3ffc5197ea2787f783542d7cdf9fdc938890b65e956d7aa4eed2e5a7"
    },
    "kernelspec": {
      "display_name": "Python 3.10.9 64-bit ('env-thesis': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false,
    "vscode": {
      "interpreter": {
        "hash": "ca09fa392acf7f4c9c27d29d2d1f288bcf246ad350262c369089ab5d60981f3e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
