# pytorch_lightning==2.0.2
seed_everything: 42
trainer:
  accelerator: gpu
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: '16-mixed'
  logger:
    # - class_path: CSVLogger
    #   init_args:
    #     save_dir: ./logs
    #     name: log
    #     version: null
    #     prefix: null
    - class_path: TensorBoardLogger
      init_args:
        save_dir: ./logs
        name: log
        version: null
        prefix: null
  callbacks:
    # - class_path: ModelCheckpoint
    #   init_args:
    #     monitor: val_acc
    #     mode: max
    #     save_top_k: 1
    #     save_weights_only: false
    #     dirpath: null
    #     filename: null
    # - class_path: EarlyStopping
    #   init_args:
    #     monitor: val_acc
    #     mode: max
    #     patience: 10
    #     check_finite: true
    - class_path: EarlyStopping
      init_args:
        monitor: val_loss
        mode: min
        patience: 10
        check_finite: true
  enable_checkpointing: null
  fast_dev_run: false
  max_epochs: 20
  min_epochs: null
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: null
  log_every_n_steps: 8
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 1
  gradient_clip_val: 1.0
  gradient_clip_algorithm: norm
  deterministic: null
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: null
model:
  # smiles_encoder:
  #   class_path: models.smiles_encoder.mlp.rdkit_fp_model.RDKitFingerprintEncoder
  #   init_args:
  #     fp_bits: 4096
  #     # NOTE: The embedding size will be the last element of the list below.
  #     hidden_channels: [512, 128, 64]
  #     dropout: 0.2
  smiles_encoder:
    class_path: models.smiles_encoder.gnn.torch_geom_architectures.GnnSubModel
    init_args:
      model_type: 'gat'
      hidden_channels: 128
      num_layers: 16
      out_channels: 64
      dropout: 0.1
  poi_seq_encoder:
    class_path: models.poi_encoder.poi_count_vectorizer.POISequenceEncoder
    init_args:
      input_size: 403
      embedding_size: 64 # 403
      use_linear_layer: true
  e3_ligase_encoder:
    class_path: models.e3_ligase_encoder.e3_ordinal_encoder.E3LigaseEncoder
    init_args:
      embedding_size: 64 # 1
      use_linear_layer: true
  cell_type_encoder:
    class_path: models.cell_type_encoder.cell_type_ordinal_encoder.CellTypeEncoder
    init_args:
      embedding_size: 64 # 1
      use_linear_layer: true
  head:
    class_path: torch.nn.Linear
    init_args:
      in_features: 64
      out_features: 1
    # class_path: torchvision.ops.MLP
    # init_args:
    #   # NOTE: The argument `in_channels` must be the sum of all the above
    #   # embedding sizes!
    #   in_channels: 256 # 661 # ${{ model.poi_seq_encoder.init_args.embedding_size + model.poi_seq_encoder.init_args.input_size }}
    #   hidden_channels: [32, 1]
    #   norm_layer: torch.nn.BatchNorm1d
    #   inplace: false
    #   dropout: 0.2
  join_branches: 'sum'
  # task: predict_active_inactive
  # freeze_smiles_encoder: false
  # learning_rate: 0.001
optimizer:
    class_path: torch.optim.AdamW
    init_args:
      lr: 1e-4
data:
  train_df_path: ./data/train/train_bin_upsampled.csv
  val_df_path: ./data/val/val_bin.csv
  test_df_path: ./data/test/test_bin.csv
  predict_df_path: ./data/test/test_bin.csv
  batch_size: 128
  protac_dataset_args:
    include_smiles_as_graphs: true

    # use_morgan_fp: true
    # morgan_bits: ${model.smiles_encoder.init_args.fp_bits}
    # morgan_atomic_radius: 6
    # use_maccs_fp: true

    # smiles_tokenizer: 'seyonec/ChemBERTa-zinc-base-v1'
    poi_seq_enc: models/poi_encoder.joblib
    e3_ligase_enc: models/e3_ligase_encoder.joblib
    cell_type_enc: models/cell_type_encoder.joblib
# ckpt_path: null
